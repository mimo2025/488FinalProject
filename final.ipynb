{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data and Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ulugsali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ulugsali/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/var/folders/ht/0hqtmhlj4mzdft95rl_k0_pr0000gn/T/ipykernel_15689/3121878266.py:19: DtypeWarning: Columns (23,26,29,99,135,139,150,151,159,163,166,171,174,175,178,179,183,186,187,191,194,195,199,206,207,210,211,214,219,222,226,234,235,238,239,242,246,247,250,255,262,278,282,283,286,291,299,302,303,306,314,323,326,330,338,342,346,358,359,362,363,366,370,371,374,375,378,379,382,383,386,391,394,398,399,402,419,422,426,430,431,434,445,449,450,453,454,457,461,465,469,473,477,481,485,489,493,497,498,501,522,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Dataset 1:\n",
      "                                                text\n",
      "0                         maybe simpson real cartoon\n",
      "1                             think designer purpose\n",
      "2           waiting model back flip like one simpson\n",
      "3  collab balenciaga yall look thing simpson put ...\n",
      "4                                      video created\n",
      "\n",
      "Preprocessed Dataset 2:\n",
      "                                                text\n",
      "0                    simpson v balenciaga fyp foryou\n",
      "1  responder estatudoaquitudoo simpson x model th...\n",
      "2  balenciaga x simpson balenciaga thesimpsons ca...\n",
      "3  somebody think shoe balenciaga mudpit pfw fash...\n",
      "4          balenciaga balenciaga balenciagacancelled\n",
      "Number of rows in Dataset 1: 21136\n",
      "Number of rows in Dataset 2: 2285\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def load_and_filter_data(file_path, text_column):\n",
    "    \"\"\"\n",
    "    Load the dataset from a CSV file and filter rows where the text column contains text.\n",
    "    \n",
    "    Args:\n",
    "    file_path (str): Path to the CSV file.\n",
    "    text_column (str): Name of the column containing text comments.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Filtered DataFrame with non-empty text comments.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(file_path)\n",
    "    filtered_data = data[data[text_column].notna() & (data[text_column] != '')]\n",
    "    return filtered_data[['text']]  # Return only the text column\n",
    "\n",
    "def preprocess_text(texts):\n",
    "    \"\"\"\n",
    "    Preprocess the text data.\n",
    "    \n",
    "    Args:\n",
    "    texts (pd.Series): Series containing text data.\n",
    "    \n",
    "    Returns:\n",
    "    pd.Series: Preprocessed text data.\n",
    "    \"\"\"\n",
    "    # Convert to lowercase and remove digits and non-alphabetic characters\n",
    "    texts = texts.str.lower().str.replace(r'\\d+', '', regex=True).str.replace(r'[^a-zA-Z\\s]', '', regex=True)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    texts = texts.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split() if word not in stop_words]))\n",
    "    \n",
    "    return texts\n",
    "\n",
    "# Paths to your dataset files\n",
    "file_path1 = 'dataset_tiktok-comments-scraper_2024-04-28_23-16-10-409.csv'\n",
    "file_path2 = 'dataset_free-tiktok-scraper_2024-04-28_21-22-00-488.csv'\n",
    "\n",
    "# Load and filter datasets\n",
    "dataset1 = load_and_filter_data(file_path1, 'text')\n",
    "dataset2 = load_and_filter_data(file_path2, 'text')\n",
    "\n",
    "# Preprocess datasets\n",
    "dataset1['text'] = preprocess_text(dataset1['text'])\n",
    "dataset2['text'] = preprocess_text(dataset2['text'])\n",
    "\n",
    "# Display the first few rows of the preprocessed datasets\n",
    "print(\"Preprocessed Dataset 1:\")\n",
    "print(dataset1.head())\n",
    "print(\"\\nPreprocessed Dataset 2:\")\n",
    "print(dataset2.head())\n",
    "\n",
    "# Print dataset shapes\n",
    "print(\"Number of rows in Dataset 1:\", dataset1.shape[0])\n",
    "print(\"Number of rows in Dataset 2:\", dataset2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: openai in /usr/local/lib/python3.9/site-packages (1.12.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.24.0-py3-none-any.whl (312 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.9/site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.9/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.9/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.9/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.9/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.12.0\n",
      "    Uninstalling openai-1.12.0:\n",
      "      Successfully uninstalled openai-1.12.0\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed openai-1.24.0\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>maybe simpson real cartoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>think designer purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>waiting model back flip like one simpson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>collab balenciaga yall look thing simpson put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>video created</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nobody nitice queen purse ground</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comment english</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>actually plan create like plan u believe simps...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ill never understand fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>simpson better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>collab balenciaga simpson there whole vid youtube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jessie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fashion show logic like stranger outfit better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>grace xx last oneeee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>smither wearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>simpson slayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>shadow dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>save sound take video bouncycastle smelly part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>fashion getting fun againnnnnnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gon walkin hurricane next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>great grandfather army cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>walking school bus morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>catwalk brief quasimodo vibe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>walking school every morning knowing write tes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>oh yeah really digging end day chic look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>trench fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>latest season american horror story look good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ashley danielle savannah currier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0                          maybe simpson real cartoon\n",
       "1                              think designer purpose\n",
       "2            waiting model back flip like one simpson\n",
       "3   collab balenciaga yall look thing simpson put ...\n",
       "4                                       video created\n",
       "5                    nobody nitice queen purse ground\n",
       "6                                     comment english\n",
       "7                                                 yes\n",
       "8                                                 oop\n",
       "9   actually plan create like plan u believe simps...\n",
       "10                       ill never understand fashion\n",
       "11                                     simpson better\n",
       "12  collab balenciaga simpson there whole vid youtube\n",
       "13                                             jessie\n",
       "14  fashion show logic like stranger outfit better...\n",
       "15                               grace xx last oneeee\n",
       "16                                    smither wearing\n",
       "17                                     simpson slayed\n",
       "18                                      shadow dragon\n",
       "19  save sound take video bouncycastle smelly part...\n",
       "20                    fashion getting fun againnnnnnn\n",
       "21                          gon walkin hurricane next\n",
       "22                        great grandfather army cool\n",
       "23                         walking school bus morning\n",
       "24                       catwalk brief quasimodo vibe\n",
       "25  walking school every morning knowing write tes...\n",
       "26           oh yeah really digging end day chic look\n",
       "27                                          trench fr\n",
       "28      latest season american horror story look good\n",
       "29                   ashley danielle savannah currier"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset = pd.read_csv('Merged_Cleaned_Dataset.csv')\n",
    "merged_dataset.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response JSON: {'id': 'cmpl-9JYeRoShZO3kXscRXdtbQrBPGaNb8', 'object': 'text_completion', 'created': 1714448459, 'model': 'davinci-002', 'choices': [{'text': \" and 'maybe simpson real cartoon' and 'maybe simpson real cartoon' and 'maybe simpson real cartoon' and 'maybe simpson real cartoon' and 'maybe simpson real cartoon' and 'maybe simpson real cartoon' and 'maybe simpson real cartoon' and 'maybe simp\", 'index': 0, 'logprobs': {'tokens': [' and', \" '\", 'maybe', ' simp', 'son', ' real', ' cartoon', \"'\", ' and', \" '\", 'maybe', ' simp', 'son', ' real', ' cartoon', \"'\", ' and', \" '\", 'maybe', ' simp', 'son', ' real', ' cartoon', \"'\", ' and', \" '\", 'maybe', ' simp', 'son', ' real', ' cartoon', \"'\", ' and', \" '\", 'maybe', ' simp', 'son', ' real', ' cartoon', \"'\", ' and', \" '\", 'maybe', ' simp', 'son', ' real', ' cartoon', \"'\", ' and', \" '\", 'maybe', ' simp', 'son', ' real', ' cartoon', \"'\", ' and', \" '\", 'maybe', ' simp'], 'token_logprobs': [-2.2934031, -0.44233558, -1.721588, -0.9156443, -0.004292915, -0.91295165, -0.6456146, -1.3617557, -0.85072535, -0.1608337, -0.3083466, -0.038838524, -0.0022263834, -0.083386704, -0.048109643, -0.49975872, -0.2722637, -0.09226285, -0.07798371, -0.013562399, -0.001231896, -0.066564344, -0.02643801, -0.2359592, -0.110864446, -0.040947925, -0.04987585, -0.014206168, -0.0003551271, -0.049829345, -0.018812664, -0.15635373, -0.08657614, -0.032952953, -0.02696021, -0.014028928, -0.00081248593, -0.034425747, -0.01486433, -0.12007985, -0.06884517, -0.024244659, -0.016037885, -0.013598492, -0.00082666025, -0.030247122, -0.023642581, -0.10500668, -0.061996143, -0.020955, -0.015499285, -0.011525328, -0.00032271104, -0.020127797, -0.013128696, -0.08961051, -0.054183304, -0.0199468, -0.014898278, -0.011167946], 'top_logprobs': [{' and': -2.2934031, ' (': -2.321116, \" '\": -2.8073812, ' or': -2.9141278, ' is': -3.774445}, {\" '\": -0.44233558, ' then': -3.5987592, '/or': -3.6109357, ' the': -3.9194827, ' also': -4.1807714}, {'maybe': -1.721588, 's': -2.9124498, 'the': -3.715499, 'product': -3.9617043, 'simp': -4.065366}, {' simp': -0.9156443, ' cartoon': -4.494966, ' the': -4.5577617, ' real': -4.616695, ' a': -4.86089}, {'son': -0.004292915, 'sons': -6.143623, 'sonian': -7.637114, 'so': -7.684402, 'on': -9.010627}, {' real': -0.91295165, ' cartoon': -2.7800152, ' fake': -4.162616, \"'s\": -4.1960945, ' is': -4.789792}, {' cartoon': -0.6456146, ' life': -3.5586338, \"'\": -4.100893, ' movie': -4.745652, ' product': -4.754924}, {\"'\": -1.3617557, \"'.\": -2.2207084, \"'.\\n\\n\": -2.5719123, \"'\\n\\n\": -2.7805696, ' and': -3.2482696}, {' and': -0.85072535, ' (': -3.4286501, ' or': -3.4497263, \" '\": -3.7797816, ' is': -3.913252}, {\" '\": -0.1608337, ' \"': -4.5022016, ' also': -4.9222865, '\\n\\n': -5.0565076, ' maybe': -5.11291}, {'maybe': -0.3083466, 's': -3.335303, 'simp': -3.5884054, 'product': -4.0040436, 'real': -4.236516}, {' simp': -0.038838524, ' Simpson': -5.4701777, ' sim': -5.971904, ' real': -6.264843, ' cartoon': -6.9740067}, {'son': -0.0022263834, 'sons': -6.1709123, 'so': -9.413174, 'sonian': -11.634243, 'ion': -11.744483}, {' real': -0.083386704, ' cartoon': -4.054729, \"'s\": -6.1814237, \"'\": -6.2011065, '\\n\\n': -6.4097915}, {' cartoon': -0.048109643, \"'\": -6.16252, '\\n\\n': -6.630544, ' cart': -6.743096, ' cartoons': -6.7823424}, {\"'\": -0.49975872, \"'\\n\\n\": -2.0810566, \"'.\": -2.34661, \"'.\\n\\n\": -2.5066795, \"',\": -4.0185986}, {' and': -0.2722637, ' or': -4.203929, ' (': -4.4301186, ' ': -4.575429, \" '\": -4.7611427}, {\" '\": -0.09226285, '\\n\\n': -4.872535, ' \"': -5.2986617, ' maybe': -5.882773, ' also': -5.8931966}, {'maybe': -0.07798371, 'may': -4.9225407, 'simp': -5.17148, 's': -5.203516, 'real': -5.7815104}, {' simp': -0.013562399, ' Simpson': -6.3783836, ' sim': -6.4445286, '\\n\\n': -7.824565, ' real': -7.8492594}, {'son': -0.001231896, 'sons': -7.3832183, 'so': -7.7927413, 's': -10.244169, '<|endoftext|>': -10.5714035}, {' real': -0.066564344, ' cartoon': -3.576103, '\\n\\n': -5.8771477, \"'\": -6.901922, \" '\": -7.0418224}, {' cartoon': -0.02643801, '\\n\\n': -5.874699, ' cart': -6.8980527, ' c': -7.1966662, '...\\n\\n': -7.2747045}, {\"'\": -0.2359592, \"'\\n\\n\": -2.6571047, \"'.\": -2.9987795, \"'.\\n\\n\": -3.175192, \"',\": -4.546646}, {' and': -0.110864446, ' or': -5.2495956, \" '\": -5.4247704, ' (': -5.4519215, '<|endoftext|>': -5.6457253}, {\" '\": -0.040947925, '\\n\\n': -5.4854603, ' \"': -5.918831, ' the': -6.792183, \" ''\": -6.8187933}, {'maybe': -0.04987585, 'may': -5.242926, 'simp': -5.309114, 's': -5.666205, ' maybe': -5.8937125}, {' simp': -0.014206168, ' sim': -6.385641, ' Simpson': -6.7255898, '\\n\\n': -7.0929804, ' real': -7.6397467}, {'son': -0.0003551271, 'sons': -9.074139, 'so': -9.102095, 'on': -10.92412, ' son': -11.038424}, {' real': -0.049829345, ' cartoon': -3.8146446, '\\n\\n': -5.8596897, \"'\": -6.972516, '...\\n\\n': -7.248968}, {' cartoon': -0.018812664, '\\n\\n': -6.058494, ' cart': -7.328838, '.': -7.505483, ' c': -7.5190215}, {\"'\": -0.15635373, \"'\\n\\n\": -2.9852226, \"'.\": -3.4368026, \"'.\\n\\n\": -3.5321424, \"',\": -5.0820913}, {' and': -0.08657614, '<|endoftext|>': -5.492412, ' (': -5.5354857, \" '\": -5.7231, ' or': -5.7651553}, {\" '\": -0.032952953, '\\n\\n': -5.4026713, ' \"': -6.2675014, \" ''\": -6.9712176, ' the': -7.0841556}, {'maybe': -0.02696021, 'may': -5.710128, ' maybe': -6.0491133, 'simp': -6.2707577, 'Maybe': -6.330244}, {' simp': -0.014028928, ' sim': -6.2286506, ' Simpson': -6.7669606, '\\n\\n': -6.911549, \"'\": -7.6471}, {'son': -0.00081248593, 'sons': -7.916195, 'so': -8.568715, 's': -9.7907505, 'sonian': -10.047952}, {' real': -0.034425747, ' cartoon': -4.0694656, '\\n\\n': -5.9553595, '<|endoftext|>': -7.42807, \" '\": -7.5041656}, {' cartoon': -0.01486433, '\\n\\n': -6.0327525, ' cart': -7.142756, '.': -7.620301, '<|endoftext|>': -7.6471353}, {\"'\": -0.12007985, \"'\\n\\n\": -3.1755226, \"'.\": -3.725599, \"'.\\n\\n\": -3.8025758, \"',\": -5.384528}, {' and': -0.06884517, '<|endoftext|>': -5.723555, \" '\": -5.7529044, ' (': -5.815578, ' or': -6.1089187}, {\" '\": -0.024244659, '\\n\\n': -5.6011224, ' \"': -6.9292197, \"'\": -7.180863, '<|endoftext|>': -7.3753343}, {'maybe': -0.016037885, 'may': -6.0111227, ' maybe': -6.2500315, 'Maybe': -6.7369146, 's': -7.1612425}, {' simp': -0.013598492, ' sim': -6.2987947, '\\n\\n': -6.7876434, ' Simpson': -6.8479815, \"'\": -7.579377}, {'son': -0.00082666025, 'sons': -8.028485, 'so': -8.748622, 's': -9.222167, '<|endoftext|>': -9.8847475}, {' real': -0.030247122, ' cartoon': -4.1996236, '\\n\\n': -6.1207337, ' re': -7.295773, '<|endoftext|>': -7.5592427}, {' cartoon': -0.023642581, '\\n\\n': -5.5363913, ' cart': -6.7097807, '<|endoftext|>': -7.228587, ' c': -7.3023863}, {\"'\": -0.10500668, \"'\\n\\n\": -3.2804751, \"'.\\n\\n\": -3.810308, \"'.\": -3.9110246, \"',\": -5.5367618}, {' and': -0.061996143, '<|endoftext|>': -5.7939105, \" '\": -5.8553424, ' (': -5.970124, ' as': -6.2944646}, {\" '\": -0.020955, '\\n\\n': -5.7301855, ' \"': -7.176853, \"'\": -7.318158, \" '\\n\\n\": -7.431432}, {'maybe': -0.015499285, 'may': -5.9676933, ' maybe': -6.308816, 'Maybe': -6.933216, 's': -7.2281036}, {' simp': -0.011525328, ' Simpson': -6.527936, '\\n\\n': -6.9222174, ' sim': -6.9367676, \"'\": -7.6756563}, {'son': -0.00032271104, 'so': -8.912608, 'sons': -9.642622, 's': -9.8090725, ' son': -10.667749}, {' real': -0.020127797, ' cartoon': -4.7671065, '\\n\\n': -6.3489213, ' re': -7.280271, \" '\": -7.835277}, {' cartoon': -0.013128696, '\\n\\n': -6.060183, ' cart': -7.164166, ' c': -7.4743524, '<|endoftext|>': -7.7135262}, {\"'\": -0.08961051, \"'\\n\\n\": -3.4165034, \"'.\\n\\n\": -3.9453483, \"'.\": -4.066941, \"',\": -5.6960835}, {' and': -0.054183304, '<|endoftext|>': -5.944549, \" '\": -6.045202, ' (': -6.064195, ' ': -6.423842}, {\" '\": -0.0199468, '\\n\\n': -5.653785, \" '\\n\\n\": -7.284765, \"'\": -7.3760886, ' \"': -7.3849683}, {'maybe': -0.014898278, 'may': -5.9145203, ' maybe': -6.2976227, 'Maybe': -6.9881134, 's': -7.3412914}, {' simp': -0.011167946, ' Simpson': -6.605473, ' sim': -6.910065, '\\n\\n': -6.9392905, \"'\": -7.653912}], 'text_offset': [269, 273, 275, 280, 285, 288, 293, 301, 302, 306, 308, 313, 318, 321, 326, 334, 335, 339, 341, 346, 351, 354, 359, 367, 368, 372, 374, 379, 384, 387, 392, 400, 401, 405, 407, 412, 417, 420, 425, 433, 434, 438, 440, 445, 450, 453, 458, 466, 467, 471, 473, 478, 483, 486, 491, 499, 500, 504, 506, 511]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 57, 'completion_tokens': 60, 'total_tokens': 117}}\n",
      "Response JSON: {'id': 'cmpl-9JYeS2tCptKg4ji2rY4h9baa1kzRa', 'object': 'text_completion', 'created': 1714448460, 'model': 'davinci-002', 'choices': [{'text': \" (p. 3). The text also states that 'the brand perception is the sum of all the elements of brand perception' (p. 3). The text also states that 'the brand perception is the sum of all the elements of brand perception' (p. 3). The text\", 'index': 0, 'logprobs': {'tokens': [' (', 'p', '.', ' ', '3', ').', ' The', ' text', ' also', ' states', ' that', \" '\", 'the', ' brand', ' perception', ' is', ' the', ' sum', ' of', ' all', ' the', ' elements', ' of', ' brand', ' perception', \"'\", ' (', 'p', '.', ' ', '3', ').', ' The', ' text', ' also', ' states', ' that', \" '\", 'the', ' brand', ' perception', ' is', ' the', ' sum', ' of', ' all', ' the', ' elements', ' of', ' brand', ' perception', \"'\", ' (', 'p', '.', ' ', '3', ').', ' The', ' text'], 'token_logprobs': [-2.009155, -3.2069368, -0.5002529, -0.57389945, -3.6922715, -1.3569847, -2.6241274, -3.3647397, -2.28275, -2.3066993, -0.56504554, -1.6347351, -2.4108298, -2.7184346, -1.9166985, -1.8702059, -1.7962427, -2.3544455, -0.20432937, -1.0258595, -0.97907025, -2.3926294, -1.1790662, -0.9535934, -0.7283279, -1.0511901, -0.18850055, -0.15585107, -0.012635724, -0.084183715, -0.3437851, -0.55962056, -2.296551, -1.7135415, -1.0690103, -0.6671382, -0.19270867, -0.5249819, -1.1840637, -0.591572, -0.43861005, -0.23145664, -0.15210724, -0.08720989, -0.00312436, -0.022070983, -0.012065135, -0.018303167, -0.014673577, -0.011071523, -0.020689258, -0.06235237, -0.020342162, -0.018494993, -0.009224834, -0.018760718, -0.046035513, -0.3221419, -0.9056623, -0.382131], 'top_logprobs': [{' (': -2.009155, ' and': -2.106428, \" '\": -3.2427995, ' -': -3.325652, ' by': -3.50821}, {'p': -3.2069368, '201': -4.064844, 'page': -4.065542, 'the': -4.0772934, 'product': -4.2058325}, {'.': -0.5002529, ' ': -2.8918602, '.p': -4.8332987, '2': -5.1581964, '1': -5.1714535}, {' ': -0.57389945, '2': -4.642397, '3': -4.682599, '4': -4.6889696, '1': -4.690036}, {'3': -3.6922715, '2': -3.750952, '4': -3.767934, '5': -3.8170846, '6': -3.9721806}, {').': -1.3569847, ')': -1.542111, ').\\n\\n': -1.9763609, ')\\n\\n': -2.020658, ').\\n': -2.8968358}, {' The': -2.6241274, ' This': -3.0337315, ' ': -3.6208124, ' In': -3.6524296, ' You': -3.9731998}, {' text': -3.3647397, ' brand': -3.4531338, ' author': -3.6397622, ' second': -4.04827, ' authors': -4.0695076}, {' also': -2.28275, ' is': -2.5954692, ' then': -3.0748136, ' continues': -3.1676862, ' states': -3.244933}, {' states': -2.3066993, ' mentions': -2.7232013, ' says': -3.0034194, ' suggests': -3.0366416, ' provides': -3.0986009}, {' that': -0.56504554, \" '\": -2.5071423, ':': -2.5120175, ',': -2.8707917, ' the': -3.1508906}, {\" '\": -1.6347351, ' the': -2.0744152, ' \"': -3.0896778, ':': -3.120205, ' these': -3.5222101}, {'the': -2.4108298, 'brand': -2.9327815, 'brands': -3.5635397, 'design': -3.5892813, 'a': -3.8054478}, {' brand': -2.7184346, ' most': -3.5860293, ' purpose': -4.0195427, ' product': -4.117594, ' consumer': -4.4409637}, {' perception': -1.9166985, ' is': -2.2245607, \"'s\": -2.6367111, ' has': -3.711072, ' purpose': -3.7515383}, {' is': -1.8702059, ' of': -2.0478287, \"'\": -3.2360077, ' model': -3.5213518, ' can': -3.573638}, {' the': -1.7962427, ' a': -2.2895193, ' not': -3.4348974, ' what': -3.5663767, ' based': -3.5930042}, {' sum': -2.3544455, ' way': -3.0497856, ' perception': -3.504756, ' most': -3.513091, ' result': -3.6981268}, {' of': -0.20432937, ' total': -1.9103326, ' perception': -5.639118, '-total': -5.698517, ' result': -6.0972834}, {' all': -1.0258595, ' the': -1.5806757, ' these': -3.3667445, ' how': -3.3688388, ' what': -3.5477567}, {' the': -0.97907025, ' of': -2.3897738, ' these': -2.6761222, ' brand': -3.3882346, ' perceptions': -3.4302955}, {' elements': -2.3926294, ' perceptions': -2.775625, ' brand': -2.9071586, ' experiences': -3.1930025, ' different': -3.2654493}, {' of': -1.1790662, ' that': -1.2492595, \"'\": -2.9761615, ' and': -3.6432796, ' in': -3.6699367}, {' brand': -0.9535934, ' the': -1.0603954, ' a': -2.804903, ' your': -3.3746748, ' perception': -4.051442}, {' perception': -0.7283279, ' identity': -2.9689236, ' experience': -3.0870914, \"'\": -3.2266483, ' that': -3.9185429}, {\"'\": -1.0511901, ',': -2.5223005, \"'.\": -2.6929443, ' that': -2.7133825, ' and': -2.936137}, {' (': -0.18850055, ' and': -2.7968895, ' which': -4.2212067, ' as': -4.4750977, ' so': -4.7759933}, {'p': -0.15585107, 'ib': -3.445031, 'pp': -4.771008, '201': -4.9527106, 'I': -5.1825185}, {'.': -0.012635724, ' ': -5.673692, '.\\n\\n': -6.0152087, '.\\n': -6.447948, '3': -6.59113}, {' ': -0.084183715, '3': -2.8959475, '4': -4.9603443, '1': -5.9250574, '2': -5.9303074}, {'3': -0.3437851, '4': -2.1207187, '2': -3.2207649, '5': -3.4469745, '1': -3.9938362}, {').': -0.55962056, ').\\n\\n': -1.921025, ')': -2.0656288, '),': -2.425906, ').\\n': -3.5345209}, {' The': -2.296551, ' This': -2.680959, ' Using': -3.1994107, ' Therefore': -3.2894242, ' In': -3.337187}, {' text': -1.7135415, ' brand': -2.5926776, ' elements': -3.5086703, ' author': -3.8071637, ' element': -3.8748832}, {' also': -1.0690103, ' states': -2.2411447, ' then': -2.5378966, ' further': -3.224897, ' does': -3.3178716}, {' states': -0.6671382, ' says': -3.2239008, ' mentions': -3.303832, ' uses': -3.4356356, ' provides': -3.8147764}, {' that': -0.19270867, \" '\": -3.086458, ' the': -3.6615064, ':': -3.83191, ',': -4.028477}, {\" '\": -0.5249819, ' the': -2.234242, ' brand': -3.7046294, ' a': -3.9384398, ':': -4.0423656}, {'the': -1.1840637, 'brand': -2.3158767, 'a': -3.3339689, 'there': -3.8289363, 'it': -3.8541343}, {' brand': -0.591572, ' sum': -3.1468775, ' elements': -3.6469576, ' perception': -4.339055, ' most': -4.688279}, {' perception': -0.43861005, ' is': -3.381771, ' image': -3.5450983, ' identity': -3.8239708, ' experience': -4.205166}, {' is': -0.23145664, ' can': -3.5447693, ' of': -4.548373, ' has': -4.6678276, ' influences': -4.9422245}, {' the': -0.15210724, ' a': -4.0811214, ' also': -5.033783, ' influenced': -5.3051834, ' not': -5.3450356}, {' sum': -0.08720989, ' perception': -5.346115, ' result': -5.5827065, ' brand': -5.8658857, ' way': -5.9059725}, {' of': -0.00312436, ' and': -8.518325, '\\n\\n': -8.596377, ' or': -8.606588, ',': -8.880866}, {' all': -0.022070983, ' the': -4.582264, ' brand': -6.8129616, ' everything': -7.3245697, '\\n\\n': -7.5572634}, {' the': -0.012065135, ' elements': -6.1017046, ' of': -6.5167894, ' brand': -6.793977, ' these': -6.8616056}, {' elements': -0.018303167, ' brand': -5.904218, ' element': -6.4625907, ' elem': -6.8402543, ' ele': -6.940367}, {' of': -0.014673577, \"'\": -6.1615644, ' that': -6.2380643, ' (': -7.272042, '...\\n\\n': -7.4088063}, {' brand': -0.011071523, ' the': -5.5811353, '...\\n\\n': -7.2880673, '…\\n\\n': -7.507707, '\\n\\n': -7.653559}, {' perception': -0.020689258, '...\\n\\n': -5.5885005, '…\\n\\n': -5.9075685, '\\n\\n': -6.467505, ' perceptions': -6.633614}, {\"'\": -0.06235237, \"'.\": -3.8454058, \"'.\\n\\n\": -4.9689627, \"',\": -5.4601965, \"'\\n\\n\": -5.5424013}, {' (': -0.020342162, ' and': -5.31568, '...\\n\\n': -6.9558225, ' which': -7.2981887, ' ': -7.711573}, {'p': -0.018494993, 'pp': -5.4073014, ' p': -7.149318, 'page': -7.4988723, 'P': -7.6586375}, {'.': -0.009224834, '.\\n\\n': -5.2989016, ' ': -7.0276155, '.\\n': -7.5290346, '...\\n\\n': -7.976659}, {' ': -0.018760718, '3': -4.546959, ' The': -7.7862854, ' …\\n\\n': -8.042222, ' ).': -8.6241455}, {'3': -0.046035513, '4': -4.2002177, '2': -5.0571876, '5': -5.3262954, '1': -5.7199855}, {').': -0.3221419, ').\\n\\n': -1.5528319, ')': -3.8539536, ').\\n': -4.244589, ')\\n\\n': -4.555071}, {' The': -0.9056623, ' This': -3.436732, ' In': -3.8227623, ' ': -3.9361866, ' So': -4.035307}, {' text': -0.382131, ' brand': -3.1551185, ' elements': -4.6711698, ' author': -4.939259, ' following': -5.214067}], 'text_offset': [265, 267, 268, 269, 270, 271, 273, 277, 282, 287, 294, 299, 301, 304, 310, 321, 324, 328, 332, 335, 339, 343, 352, 355, 361, 372, 373, 375, 376, 377, 378, 379, 381, 385, 390, 395, 402, 407, 409, 412, 418, 429, 432, 436, 440, 443, 447, 451, 460, 463, 469, 480, 481, 483, 484, 485, 486, 487, 489, 493]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 60, 'total_tokens': 115}}\n",
      "Response JSON: {'id': 'cmpl-9JYeTVWmrNnZnOzA843CMdJRTbSrv', 'object': 'text_completion', 'created': 1714448461, 'model': 'davinci-002', 'choices': [{'text': \" and 'waiting model back flip like one simpson' and 'waiting model back flip like one simpson' and 'waiting model back flip like one simpson' and 'waiting model back flip like one simpson' and 'waiting model back flip like one simpson' and 'waiting model back\", 'index': 0, 'logprobs': {'tokens': [' and', \" '\", 'waiting', ' model', ' back', ' flip', ' like', ' one', ' simp', 'son', \"'\", ' and', \" '\", 'waiting', ' model', ' back', ' flip', ' like', ' one', ' simp', 'son', \"'\", ' and', \" '\", 'waiting', ' model', ' back', ' flip', ' like', ' one', ' simp', 'son', \"'\", ' and', \" '\", 'waiting', ' model', ' back', ' flip', ' like', ' one', ' simp', 'son', \"'\", ' and', \" '\", 'waiting', ' model', ' back', ' flip', ' like', ' one', ' simp', 'son', \"'\", ' and', \" '\", 'waiting', ' model', ' back'], 'token_logprobs': [-2.1503096, -0.65841055, -3.050784, -0.6290839, -0.5272241, -0.16634774, -0.21453087, -0.31367722, -0.055393107, -0.0036465183, -1.0014373, -0.9927023, -0.19784309, -0.6622986, -0.037839834, -0.042262737, -0.015584036, -0.023358684, -0.025386857, -0.008820551, -0.0011331898, -0.45070055, -0.2813186, -0.095597304, -0.09327544, -0.012735785, -0.011599092, -0.005044475, -0.011746726, -0.013176581, -0.0073818127, -0.00072672893, -0.21947649, -0.14790952, -0.06899638, -0.05021251, -0.007717601, -0.013005868, -0.003643311, -0.0060445736, -0.007899984, -0.005223914, -0.0011468872, -0.18536068, -0.12610047, -0.04146397, -0.031537734, -0.007884254, -0.00776492, -0.0036942551, -0.002481604, -0.007440509, -0.0045751384, -0.0007469753, -0.12199146, -0.09257739, -0.029740773, -0.0233489, -0.00491387, -0.0068238317], 'top_logprobs': [{' and': -2.1503096, ' (': -2.3635826, \" '\": -2.5544558, ' or': -3.4297476, ' -': -3.5574665}, {\" '\": -0.65841055, ' then': -3.1507182, ' the': -3.510797, ' also': -4.206283, ' you': -4.4743257}, {'waiting': -3.050784, 's': -3.5923824, 'the': -3.6189709, 'like': -4.264323, 'a': -4.503726}, {' model': -0.6290839, ' for': -2.6749985, ' to': -4.103138, ' like': -4.438134, ' back': -4.510298}, {' back': -0.5272241, ' like': -3.235437, ' flip': -3.6735682, \"'\": -4.2875075, ' front': -4.704231}, {' flip': -0.16634774, 'flip': -2.2626612, ' like': -4.70238, '-fl': -6.238413, 'fl': -6.2510347}, {' like': -0.21453087, \"'\": -3.9136486, ' one': -4.68894, \"'.\": -4.8780317, \"'.\\n\\n\": -5.09908}, {' one': -0.31367722, ' simp': -2.8853402, ' two': -3.591124, ' a': -4.0258756, ' the': -4.66272}, {' simp': -0.055393107, ' sim': -4.6635647, ' Simpson': -5.805396, ' of': -6.45393, ' simple': -6.806282}, {'son': -0.0036465183, 'sons': -7.305207, 'so': -7.9036765, 'sonian': -8.025568, 'ison': -8.041878}, {\"'\": -1.0014373, \"'\\n\\n\": -2.413268, \"'.\": -2.4542608, \"'.\\n\\n\": -2.8475971, ' and': -3.0310144}, {' and': -0.9927023, \" '\": -3.243963, ' (': -3.3490112, ' is': -3.7593782, ' or': -3.7624185}, {\" '\": -0.19784309, ' \"': -4.450793, ' then': -4.8797297, ' the': -5.008474, ' also': -5.0586944}, {'waiting': -0.6622986, 's': -3.9934592, 'wait': -4.104983, 'product': -4.4506125, 'the': -4.682322}, {' model': -0.037839834, ' for': -5.436822, \"'\": -6.690051, ' back': -6.737014, ' mode': -6.7435894}, {' back': -0.042262737, ' like': -5.052589, ' flip': -6.0142274, \"'\": -6.0731444, '\\n\\n': -7.0153747}, {' flip': -0.015584036, 'flip': -5.106614, ' flop': -7.423563, '\\n\\n': -7.6528845, '...': -8.184184}, {' like': -0.023358684, \"'\": -5.602838, \"'.\": -7.1588254, ' one': -7.2305408, \"'.\\n\\n\": -7.3001323}, {' one': -0.025386857, ' simp': -6.3210735, ' a': -6.4626064, ' ': -6.914033, \"'\": -6.952265}, {' simp': -0.008820551, ' sim': -5.9686193, ' Simpson': -6.681775, \"'\": -8.001168, '\\n\\n': -8.359017}, {'son': -0.0011331898, 'sons': -7.412781, 'so': -8.461221, 's': -9.369957, '\\n\\n': -10.47789}, {\"'\": -0.45070055, \"'\\n\\n\": -2.0267045, \"'.\": -2.5013254, \"'.\\n\\n\": -2.794297, \"',\": -3.9230402}, {' and': -0.2813186, ' (': -4.3692923, ' or': -4.4821873, \" '\": -4.5701027, '<|endoftext|>': -4.5792656}, {\" '\": -0.095597304, '\\n\\n': -4.876706, ' \"': -4.995343, ' then': -5.9410763, ' also': -5.945775}, {'waiting': -0.09327544, 'wait': -4.673617, 's': -5.773002, 'Waiting': -6.5175385, ' waiting': -6.603164}, {' model': -0.012735785, ' mode': -6.5057425, '\\n\\n': -6.7100396, '...\\n\\n': -7.729921, ' models': -7.790835}, {' back': -0.011599092, '\\n\\n': -6.984999, \" '\": -7.485764, ' bac': -7.57192, '...\\n\\n': -7.7873883}, {' flip': -0.005044475, 'flip': -6.939834, '\\n\\n': -7.555385, '<|endoftext|>': -8.316926, ' flop': -8.380701}, {' like': -0.011746726, \"'\": -6.7412114, '\\n\\n': -7.096725, \" '\": -8.162536, '.': -8.201326}, {' one': -0.013176581, '\\n\\n': -6.6984487, ' on': -7.2867045, ' ': -7.7104955, ' simp': -7.7294173}, {' simp': -0.0073818127, ' sim': -6.179873, ' Simpson': -6.852426, '\\n\\n': -7.7839437, \"'\": -7.9778476}, {'son': -0.00072672893, 'so': -8.083263, 'sons': -9.353604, 's': -9.614599, ' son': -9.620504}, {\"'\": -0.21947649, \"'\\n\\n\": -2.5251186, \"'.\": -3.2221897, \"'.\\n\\n\": -3.313646, \"',\": -4.7284346}, {' and': -0.14790952, '<|endoftext|>': -4.89776, ' (': -5.0691314, \" '\": -5.350121, ' or': -5.3992085}, {\" '\": -0.06899638, '\\n\\n': -4.748089, ' \"': -5.5065346, ' the': -6.279605, ' then': -6.385297}, {'waiting': -0.05021251, 'wait': -5.266419, 's': -6.399608, ' waiting': -6.8007674, 'Waiting': -6.8244777}, {' model': -0.007717601, ' mode': -7.001036, '\\n\\n': -7.118584, ' models': -8.250578, '<|endoftext|>': -8.30625}, {' back': -0.013005868, '\\n\\n': -6.57529, '<|endoftext|>': -7.572969, '...\\n\\n': -7.5944495, \" '\": -7.6330924}, {' flip': -0.003643311, '\\n\\n': -7.6759295, 'flip': -8.404992, ' back': -8.531574, ' fl': -8.676962}, {' like': -0.0060445736, '\\n\\n': -7.346055, \"'\": -7.7266808, ' li': -8.423871, ' lik': -8.535998}, {' one': -0.007899984, '\\n\\n': -6.915378, \" '\": -8.169049, ' on': -8.201425, '...\\n\\n': -8.244239}, {' simp': -0.005223914, ' sim': -6.618009, ' Simpson': -7.3313117, '\\n\\n': -7.7627587, \"'\": -8.4486}, {'son': -0.0011468872, 'so': -7.837643, 'sons': -8.557186, '\\n\\n': -9.104785, 's': -9.390007}, {\"'\": -0.18536068, \"'\\n\\n\": -2.623431, \"'.\\n\\n\": -3.4731586, \"'.\": -3.4994667, \"',\": -4.963933}, {' and': -0.12610047, '<|endoftext|>': -5.00955, ' (': -5.1725454, \" '\": -5.55997, ' as': -5.5751953}, {\" '\": -0.04146397, '\\n\\n': -5.0141993, ' \"': -6.195553, '<|endoftext|>': -6.7621794, ' the': -6.988661}, {'waiting': -0.031537734, 'wait': -5.4869494, ' waiting': -7.063538, 'Waiting': -7.089744, 's': -7.105808}, {' model': -0.007884254, '\\n\\n': -6.553418, ' mode': -7.260354, '<|endoftext|>': -7.8885117, '...\\n\\n': -8.044492}, {' back': -0.00776492, '\\n\\n': -6.9541874, ' bac': -7.829834, '<|endoftext|>': -7.8786736, '...\\n\\n': -7.949749}, {' flip': -0.0036942551, ' fl': -7.8373256, '\\n\\n': -7.8563437, ' back': -8.586704, ' flop': -8.731186}, {' like': -0.002481604, '\\n\\n': -8.06423, ' lik': -8.168575, ' li': -8.915671, ' ...\\n\\n': -9.233101}, {' one': -0.007440509, '\\n\\n': -6.823654, ' on': -8.088789, '...\\n\\n': -8.130131, '<|endoftext|>': -8.237392}, {' simp': -0.0045751384, ' sim': -7.0903497, '\\n\\n': -7.447844, ' Simpson': -7.9795146, \"'\": -8.805673}, {'son': -0.0007469753, 'so': -7.7478623, ' son': -9.427201, 's': -9.827859, 'sons': -10.263909}, {\"'\": -0.12199146, \"'\\n\\n\": -2.9538367, \"'.\\n\\n\": -3.899832, \"'.\": -4.000319, \"',\": -5.4196534}, {' and': -0.09257739, '<|endoftext|>': -5.233299, ' (': -5.4058805, \" '\": -5.771773, ' as': -5.940161}, {\" '\": -0.029740773, '\\n\\n': -5.221639, '<|endoftext|>': -6.8242135, ' \"': -6.8708196, '...\\n\\n': -7.111133}, {'waiting': -0.0233489, 'wait': -5.567321, ' waiting': -7.3244925, 'Waiting': -7.3315763, 's': -7.404191}, {' model': -0.00491387, '\\n\\n': -7.1168056, ' mode': -7.402477, '<|endoftext|>': -8.54185, '...\\n\\n': -8.546775}, {' back': -0.0068238317, '\\n\\n': -7.0492835, '<|endoftext|>': -7.8873334, ' bac': -7.911285, '...\\n\\n': -7.988132}], 'text_offset': [283, 287, 289, 296, 302, 307, 312, 317, 321, 326, 329, 330, 334, 336, 343, 349, 354, 359, 364, 368, 373, 376, 377, 381, 383, 390, 396, 401, 406, 411, 415, 420, 423, 424, 428, 430, 437, 443, 448, 453, 458, 462, 467, 470, 471, 475, 477, 484, 490, 495, 500, 505, 509, 514, 517, 518, 522, 524, 531, 537]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 60, 'completion_tokens': 60, 'total_tokens': 120}}\n",
      "Response JSON: {'id': 'cmpl-9JYeU1tRclVh4H11YgcwJgLQP8ySa', 'object': 'text_completion', 'created': 1714448462, 'model': 'davinci-002', 'choices': [{'text': \" (the text is from the article 'Balenciaga and The Simpsons Put Their Heads Together for a New Collection' by Emily Farra, published on Vogue.com on 10th March 2021)\\n\\nThe article is about Balenciaga and The Simpsons putting their heads together for a new collection.\", 'index': 0, 'logprobs': {'tokens': [' (', 'the', ' text', ' is', ' from', ' the', ' article', \" '\", 'Bal', 'enci', 'aga', ' and', ' The', ' Simpsons', ' Put', ' Their', ' Heads', ' Together', ' for', ' a', ' New', ' Collection', \"'\", ' by', ' Emily', ' Far', 'ra', ',', ' published', ' on', ' Vogue', '.com', ' on', ' ', '10', 'th', ' March', ' ', '202', '1', ')\\n\\n', 'The', ' article', ' is', ' about', ' Bal', 'enci', 'aga', ' and', ' The', ' Simpsons', ' putting', ' their', ' heads', ' together', ' for', ' a', ' new', ' collection', '.'], 'token_logprobs': [-2.3010838, -3.858932, -3.2038183, -1.1474202, -2.2544668, -1.3321645, -2.9775565, -2.4628413, -1.1093348, -0.0069018514, -0.009931626, -1.9424852, -1.2676421, -0.061475687, -2.2331817, -1.6180567, -1.2516365, -0.022950184, -0.8618615, -0.7426575, -1.9251121, -1.409934, -1.4006121, -1.2984563, -4.434235, -1.5411003, -0.01960973, -1.5708338, -0.39583644, -0.90013885, -1.3599935, -1.394584, -1.2094026, -0.88576317, -3.2798052, -1.4502386, -2.3194993, -0.13560292, -0.13685645, -0.46113405, -1.6563201, -3.1840303, -2.942166, -1.840866, -1.7451127, -1.2512746, -0.022518426, -0.017730767, -1.0374672, -0.33095083, -0.07539024, -1.712134, -0.12136764, -0.05622208, -0.026625488, -0.53950036, -0.0627855, -0.11263017, -0.14002904, -1.0348763], 'top_logprobs': [{' (': -2.3010838, ' and': -2.767547, ' -': -3.5148823, \" '\": -3.5651677, ' ': -3.7136624}, {'the': -3.858932, 'you': -3.94165, 'I': -4.0640044, 'this': -4.0687604, 'see': -4.4232335}, {' text': -3.2038183, \" '\": -3.3076086, ' first': -3.418027, ' more': -3.8575172, ' word': -3.8977528}, {' is': -1.1474202, ' will': -3.2651904, ' should': -3.2794096, ' has': -3.3183234, ' was': -3.4814856}, {' from': -2.2544668, ' a': -2.2929485, ' not': -2.7307518, ' in': -2.8053243, ' taken': -3.2566803}, {' the': -1.3321645, ' a': -1.9205635, ' this': -2.99526, ' an': -3.1247928, ' https': -3.458763}, {' article': -2.9775565, ' brand': -3.2688315, ' image': -3.3347514, ' video': -3.393326, ' website': -3.5604784}, {\" '\": -2.4628413, ')\\n\\n': -2.4772637, ')': -2.5610316, ').': -2.751651, ',': -3.0863564}, {'Bal': -1.1093348, 'bal': -1.836111, 'The': -3.4728346, 'the': -3.808032, 'coll': -4.256137}, {'enci': -0.0069018514, 'main': -5.8008595, 'ancing': -7.280843, 'enc': -7.630376, 'anc': -7.94415}, {'aga': -0.009931626, 'agas': -5.1479588, 'ag': -6.0286026, 'agan': -7.492302, 'ago': -9.005865}, {' and': -1.9424852, \"'s\": -2.2944942, ' x': -2.9922671, '’s': -3.3996015, ',': -3.5005698}, {' The': -1.2676421, ' the': -2.0405025, ' Y': -2.5951662, ' Adidas': -3.2168674, ' Gu': -3.6056395}, {' Simpsons': -0.061475687, ' Simpson': -3.50566, ' North': -4.431772, ' Sims': -4.8450813, ' SIM': -5.7074575}, {' Put': -2.2331817, ' are': -3.1211183, ' Are': -3.1221588, ' put': -3.1724384, ' team': -3.240218}, {' Their': -1.6180567, ' a': -1.9763578, ' Em': -2.3483596, ' the': -2.8418536, ' on': -3.4326682}, {' Heads': -1.2516365, ' Own': -2.3957748, ' Spin': -2.938899, ' Thing': -3.5187912, ' Creative': -3.6550798}, {' Together': -0.022950184, ' (': -5.4180574, ' together': -5.5543375, ' to': -5.9666615, ' and': -6.3138}, {' for': -0.8618615, ' For': -2.2171834, ' to': -2.5946248, \"')\": -2.6647322, ' on': -3.1343596}, {' a': -0.7426575, ' New': -2.3100393, ' an': -2.9621503, ' the': -3.598255, ' Caps': -3.6114233}, {' New': -1.9251121, ' Collaboration': -2.9395556, ' Collection': -3.06984, ' Caps': -3.3484607, ' Very': -3.431519}, {' Collection': -1.409934, ' Collaboration': -1.7737722, ' Coll': -1.937788, ' Caps': -2.5954304, ' Line': -2.888671}, {\"'\": -1.4006121, \"')\\n\\n\": -1.8159621, \"',\": -1.919678, \"')\": -1.9725707, \"').\": -2.6533778}, {' by': -1.2984563, ' from': -2.1467905, ' https': -2.6823273, ' on': -2.951974, ' and': -3.194848}, {' Emily': -4.434235, ':': -4.590097, ' Vogue': -4.591001, ' L': -4.632939, ' the': -4.706241}, {' Far': -1.5411003, ' Manning': -2.167567, ' Kirk': -2.3412797, ' Chan': -3.138601, ' Z': -3.4164646}, {'ra': -0.01960973, 'ley': -5.2426705, 'in': -6.144591, 'ina': -6.5155864, 'rah': -6.6048875}, {',': -1.5708338, ')\\n\\n': -2.3768487, ' on': -2.5462604, ').': -2.6999488, ')': -2.710734}, {' published': -0.39583644, ' posted': -2.8008761, ' ': -3.295383, ' accessed': -4.244797, ' available': -4.6255565}, {' on': -0.90013885, ' in': -1.4891071, ' by': -1.5603685, ' ': -2.8932896, ' at': -3.9050922}, {' Vogue': -1.3599935, ' ': -1.6821542, ' the': -2.7416234, ' August': -3.3324265, ' September': -3.4242892}, {'.com': -1.394584, ',': -2.1160424, ' on': -2.1685479, ' website': -2.9072917, ' Run': -2.999943}, {' on': -1.2094026, ',': -1.4492736, ')\\n\\n': -2.48177, ')': -2.8316808, ').': -2.8964715}, {' ': -0.88576317, ' March': -2.878518, ' the': -3.0366783, ' April': -3.04852, ' May': -3.1586685}, {'10': -3.2798052, '11': -3.3130932, '15': -3.3552656, '12': -3.3637133, '16': -3.3853512}, {'th': -1.4502386, '/': -1.4853281, '.': -2.822204, ' March': -2.90519, ' September': -3.2315269}, {' March': -2.3194993, ' of': -2.337807, ' September': -2.4425309, ' June': -2.5198796, ' February': -2.524093}, {' ': -0.13560292, ',': -2.343113, ').': -5.1958237, ')': -5.4600544, ')\\n\\n': -5.5545483}, {'202': -0.13685645, '201': -2.0790277, '21': -7.294995, '20': -7.5830255, '200': -7.623326}, {'1': -0.46113405, '0': -1.0001966, '01': -8.7584095, '<|endoftext|>': -8.766694, '2': -8.836388}, {')\\n\\n': -1.6563201, ').': -1.6850963, ').\\n\\n': -1.7827582, ')': -1.915401, ',': -2.7928004}, {'The': -3.1840303, '2': -3.54722, '-': -3.826224, 'Use': -4.044137, '3': -4.082185}, {' article': -2.942166, ' text': -3.1386993, ' brand': -3.8366992, ' first': -4.1700964, ' word': -4.2393827}, {' is': -1.840866, \" '\": -2.748705, ' can': -2.9175186, \"'s\": -3.406063, ' should': -3.6541824}, {' about': -1.7451127, ' available': -2.404507, ' attached': -2.912865, ' from': -3.0525162, ' a': -3.2506669}, {' Bal': -1.2512746, ' the': -1.3828626, ' a': -2.0951905, ' how': -2.692617, ':': -2.844401}, {'enci': -0.022518426, 'en': -4.890224, 'enc': -5.140117, 'anc': -6.3088756, 'encia': -6.5413394}, {'aga': -0.017730767, 'agas': -4.2724895, 'ag': -6.699498, 'age': -6.8220825, 'ago': -9.082383}, {' and': -1.0374672, \"'s\": -1.563822, ' collaborating': -2.6074212, ',': -3.0235503, ' team': -3.6084797}, {' The': -0.33095083, ' the': -2.0124435, ' Simpsons': -3.4753141, ' their': -4.0097237, ' how': -4.1153107}, {' Simpsons': -0.07539024, ' Simpson': -2.99091, ' Sim': -4.649153, ' Sims': -5.400822, ' simp': -6.459354}, {' putting': -1.712134, ' collaborating': -2.523888, \"'\": -2.761847, ',': -2.9868493, ' joining': -3.2386155}, {' their': -0.12136764, ' heads': -3.0492442, ' together': -3.2122767, ' a': -5.739334, ' there': -6.05202}, {' heads': -0.05622208, ' head': -3.8987665, ' minds': -5.2971563, ' creative': -5.667815, \" '\": -5.955724}, {' together': -0.026625488, ' (': -4.8894415, ' to': -4.9523077, ' and': -5.8251495, ' for': -6.4994593}, {' for': -0.53950036, ' to': -1.1671783, ' and': -3.3623533, ' (': -4.219678, ' on': -4.70634}, {' a': -0.0627855, ' the': -4.2865767, ' their': -4.4181437, ' new': -4.4336925, ' an': -5.2387195}, {' new': -0.11263017, ' collection': -3.3156722, ' collaboration': -3.9803488, ' coll': -5.181009, ' brand': -5.532374}, {' collection': -0.14002904, ' collaboration': -3.613637, ' coll': -4.0584784, ' clothing': -4.2527494, ' fashion': -4.831814}, {'.': -1.0348763, '.\\n\\n': -1.9499297, ',': -2.1905875, '\\n\\n': -2.6388803, ' and': -2.8547301}], 'text_offset': [303, 305, 308, 313, 316, 321, 325, 333, 335, 338, 342, 345, 349, 353, 362, 366, 372, 378, 387, 391, 393, 397, 408, 409, 412, 418, 422, 424, 425, 435, 438, 444, 448, 451, 452, 454, 456, 462, 463, 466, 467, 470, 473, 481, 484, 490, 494, 498, 501, 505, 509, 518, 526, 532, 538, 547, 551, 553, 557, 568]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 68, 'completion_tokens': 60, 'total_tokens': 128}}\n",
      "Response JSON: {'id': 'cmpl-9JYeUAqlsuDPIY3xMyqvHN2jSHCNl', 'object': 'text_completion', 'created': 1714448462, 'model': 'davinci-002', 'choices': [{'text': \" and 'video edited' and 'video uploaded' and 'video shared' and 'video liked' and 'video commented' and 'video viewed' and 'video shared' and 'video liked' and 'video commented' and 'video viewed' and 'video shared' and 'video liked'\", 'index': 0, 'logprobs': {'tokens': [' and', \" '\", 'video', ' edited', \"'\", ' and', \" '\", 'video', ' uploaded', \"'\", ' and', \" '\", 'video', ' shared', \"'\", ' and', \" '\", 'video', ' liked', \"'\", ' and', \" '\", 'video', ' commented', \"'\", ' and', \" '\", 'video', ' viewed', \"'\", ' and', \" '\", 'video', ' shared', \"'\", ' and', \" '\", 'video', ' liked', \"'\", ' and', \" '\", 'video', ' commented', \"'\", ' and', \" '\", 'video', ' viewed', \"'\", ' and', \" '\", 'video', ' shared', \"'\", ' and', \" '\", 'video', ' liked', \"'\"], 'token_logprobs': [-1.2611849, -0.21963844, -2.833765, -1.9357944, -1.0206763, -1.5869508, -0.32314646, -1.0226945, -2.0399475, -1.1126256, -0.57302135, -0.15137857, -0.6021555, -2.1481514, -0.89645296, -0.340185, -0.120772615, -0.42023042, -2.4494846, -0.3831663, -0.1568539, -0.06494368, -0.11092686, -0.560993, -0.66800135, -0.17516337, -0.06841764, -0.21313712, -1.5905348, -0.5333765, -0.18634841, -0.068306535, -0.20792611, -1.5623015, -0.8355011, -0.18823563, -0.05293213, -0.16515087, -1.2513974, -0.056341194, -0.04596446, -0.015715003, -0.018525414, -0.12728031, -0.05039513, -0.043983243, -0.017069327, -0.02460344, -0.018921573, -0.27176398, -0.1505256, -0.072151214, -0.12571095, -0.29979065, -0.036264103, -0.029127762, -0.0109022055, -0.0057290946, -0.03710989, -0.009281758], 'top_logprobs': [{' and': -1.2611849, \" '\": -2.3097785, ' (': -2.5752614, ' or': -2.9573472, ' -': -3.8677151}, {\" '\": -0.21963844, '/or': -3.4938312, ' the': -4.258426, ' then': -4.5038037, ' uploaded': -5.4148498}, {'video': -2.833765, 'text': -3.135027, 'written': -3.555128, 'product': -3.6664476, 'social': -3.8038921}, {' edited': -1.9357944, ' created': -2.600864, ' uploaded': -3.0537372, ' shared': -3.298533, ' produced': -3.6488137}, {\"'\": -1.0206763, \"'.\": -1.8605982, \"'.\\n\\n\": -1.9273955, \"'\\n\\n\": -2.0201154, \"',\": -3.0487647}, {' and': -1.5869508, ' (': -2.8521113, ' or': -3.337522, ' as': -3.4898696, ' for': -3.5276332}, {\" '\": -0.32314646, '/or': -4.0816684, ' then': -4.111811, ' the': -4.145018, ' so': -4.2468896}, {'video': -1.0226945, 'audio': -3.1245127, 'voice': -4.2941284, 'text': -4.3715267, 'social': -4.4098835}, {' uploaded': -2.0399475, ' produced': -2.7404566, ' published': -2.96772, ' shared': -3.5290022, ' caption': -3.580986}, {\"'\": -1.1126256, ' to': -1.8560739, \"'\\n\\n\": -2.0313811, \"'.\": -2.2634683, \"'.\\n\\n\": -2.4912877}, {' and': -0.57302135, ' (': -3.47234, ' etc': -3.7750783, \" '\": -4.264588, ' -': -4.3417974}, {\" '\": -0.15137857, ' so': -4.4922047, ' etc': -5.1841373, ' the': -5.2032423, ' then': -5.255741}, {'video': -0.6021555, 'social': -3.9654186, 'website': -4.2733793, 'audio': -4.4223223, 'text': -4.6497393}, {' shared': -2.1481514, ' promoted': -2.4925785, ' published': -2.5608196, ' caption': -3.236681, ' uploaded': -3.490365}, {\"'\": -0.89645296, \"'\\n\\n\": -2.1594038, ' on': -2.1736088, \"'.\": -2.281145, \"'.\\n\\n\": -2.6200666}, {' and': -0.340185, ' (': -3.8532236, ' etc': -4.0040903, ' ': -4.504689, ' -': -4.751877}, {\" '\": -0.120772615, ' so': -4.7728724, '\\n\\n': -5.1998982, ' etc': -5.296911, ' the': -5.523682}, {'video': -0.42023042, 'social': -4.0499864, 'website': -4.4842744, 'videos': -5.0031505, 'brand': -5.022698}, {' liked': -2.4494846, ' promoted': -2.4609954, ' commented': -2.7826192, ' viewed': -3.160774, ' tagged': -3.340123}, {\"'\": -0.3831663, \"'\\n\\n\": -2.5472307, \"'.\": -2.5806732, \"'.\\n\\n\": -2.959916, \"',\": -3.692546}, {' and': -0.1568539, ' etc': -4.276127, ' (': -4.431573, ' or': -5.0110846, \" '\": -5.1310387}, {\" '\": -0.06494368, ' so': -5.1445365, ' etc': -5.757794, '\\n\\n': -5.7725177, ' video': -5.818176}, {'video': -0.11092686, 'view': -4.9621325, 'videos': -5.0113106, 'comment': -5.192272, 'comments': -5.325119}, {' commented': -0.560993, ' shared': -2.5059822, ' viewed': -2.8807771, ' watched': -3.4784124, ' disliked': -3.886503}, {\"'\": -0.66800135, ' on': -1.4270289, \"'.\": -2.5735018, \"'\\n\\n\": -2.7567618, \"'.\\n\\n\": -2.9847987}, {' and': -0.17516337, ' (': -4.7664165, ' etc': -4.7850018, ' ': -4.790083, \" '\": -5.3839207}, {\" '\": -0.06841764, ' so': -5.478896, '\\n\\n': -5.6249075, ' etc': -5.7244425, ' video': -5.9835606}, {'video': -0.21313712, 'view': -4.839536, 'videos': -4.9283795, 'number': -5.1858726, 'views': -5.2873654}, {' viewed': -1.5905348, ' shared': -1.8945347, ' watched': -2.5986838, ' subscribed': -2.980496, ' tagged': -3.1552882}, {\"'\": -0.5333765, \"'.\": -2.3717544, \"'\\n\\n\": -2.4528406, \"'.\\n\\n\": -2.6051786, \"',\": -3.8482368}, {' and': -0.18634841, ' (': -4.161512, \" '\": -4.9016995, ' ': -5.2275586, ' -': -5.31045}, {\" '\": -0.068306535, ' so': -5.6706986, ' etc': -5.8186746, '\\n\\n': -5.856772, ' other': -5.971699}, {'video': -0.20792611, 'view': -4.8908305, 'social': -4.9652104, 'website': -4.965977, 'views': -5.0915065}, {' shared': -1.5623015, ' viewed': -2.480463, ' watched': -2.5071774, ' subscribed': -2.6359177, ' commented': -3.195569}, {\"'\": -0.8355011, ' on': -2.2779593, ' to': -2.570953, \"'.\": -2.9079547, \"'\\n\\n\": -3.0772624}, {' and': -0.18823563, ' (': -4.345473, \" '\": -4.6708207, ' ': -5.113936, ' etc': -5.121041}, {\" '\": -0.05293213, '\\n\\n': -6.043815, ' etc': -6.156862, ' \"': -6.1579757, ' the': -6.293607}, {'video': -0.16515087, 'social': -5.0370245, 'website': -5.283124, 'view': -5.442548, 'videos': -5.522339}, {' liked': -1.2513974, ' viewed': -1.8069394, ' commented': -2.6131022, ' shared': -2.7657778, ' watched': -2.872124}, {\"'\": -0.056341194, \"'\\n\\n\": -4.3763, \"'.\": -4.421241, \"'.\\n\\n\": -4.807049, \"',\": -4.9663563}, {' and': -0.04596446, \" '\": -5.8478804, ' (': -5.894252, ' ': -6.230914, ' etc': -6.6242027}, {\" '\": -0.015715003, ' video': -6.799952, '\\n\\n': -6.8188004, ' \"': -6.9223466, '...\\n\\n': -7.5607724}, {'video': -0.018525414, 'view': -6.077207, 'youtube': -7.2275157, 'photo': -7.384661, 'comment': -7.4082866}, {' commented': -0.12728031, ' viewed': -2.7456627, ' shared': -3.8475485, ' watched': -4.765189, ' disliked': -6.3915453}, {\"'\": -0.05039513, \"'\\n\\n\": -4.1946554, \"'.\\n\\n\": -4.739313, \"'.\": -4.760421, \"',\": -5.2312727}, {' and': -0.043983243, ' ': -5.663748, ' (': -5.7468023, \" '\": -6.465249, '<|endoftext|>': -6.706991}, {\" '\": -0.017069327, '\\n\\n': -6.5672565, ' video': -6.9615684, ' \"': -6.9725347, '...\\n\\n': -7.313977}, {'video': -0.02460344, 'view': -5.576979, 'youtube': -6.645087, 'v': -6.8635964, 'views': -6.9178605}, {' viewed': -0.018921573, ' watched': -4.9773765, ' views': -6.356114, ' shared': -6.693043, ' uploaded': -7.3763223}, {\"'\": -0.27176398, \"'\\n\\n\": -2.3196204, \"'.\\n\\n\": -3.0327713, \"'.\": -3.1601899, \"',\": -4.2013073}, {' and': -0.1505256, ' ': -4.946119, ' (': -5.0521274, \" '\": -5.080827, '<|endoftext|>': -5.1605163}, {\" '\": -0.072151214, '\\n\\n': -5.0909767, ' the': -5.9925194, ' so': -6.2130213, ' etc': -6.2427197}, {'video': -0.12571095, 'social': -5.091562, 'website': -5.449098, 'other': -5.5506988, 'view': -5.726663}, {' shared': -0.29979065, ' viewed': -3.4212754, ' liked': -3.557811, ' uploaded': -3.900595, ' watched': -4.23004}, {\"'\": -0.036264103, \"'\\n\\n\": -4.8417563, \"',\": -4.877069, \"'.\": -5.4108233, \"'.\\n\\n\": -5.6315455}, {' and': -0.029127762, ' (': -6.0447707, ' ': -6.5379825, \" '\": -6.72473, '<|endoftext|>': -7.1331267}, {\" '\": -0.0109022055, '\\n\\n': -6.4666786, '...\\n\\n': -7.604313, \" ''\": -7.8671913, ' ‘': -7.9701595}, {'video': -0.0057290946, 'view': -6.7352786, 'youtube': -7.7474017, 'videos': -8.501029, 'v': -8.519748}, {' liked': -0.03710989, ' viewed': -3.8659348, ' likes': -5.92718, ' commented': -5.9298005, ' watched': -7.341437}, {\"'\": -0.009281758, \"'\\n\\n\": -5.925468, \"'.\": -6.6127086, \"',\": -6.6252103, \"'.\\n\\n\": -6.7252765}], 'text_offset': [256, 260, 262, 267, 274, 275, 279, 281, 286, 295, 296, 300, 302, 307, 314, 315, 319, 321, 326, 332, 333, 337, 339, 344, 354, 355, 359, 361, 366, 373, 374, 378, 380, 385, 392, 393, 397, 399, 404, 410, 411, 415, 417, 422, 432, 433, 437, 439, 444, 451, 452, 456, 458, 463, 470, 471, 475, 477, 482, 488]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 54, 'completion_tokens': 60, 'total_tokens': 114}}\n",
      "Response JSON: {'id': 'cmpl-9JYeVQ3lZjAiC8WMvpq6eAAwYy8q6', 'object': 'text_completion', 'created': 1714448463, 'model': 'davinci-002', 'choices': [{'text': \" 'queen purse ground' 'queen purse ground' 'queen purse ground' 'queen purse ground' 'queen purse ground' 'queen purse ground' 'queen purse ground' 'queen purse ground' 'queen purse ground' 'queen purse ground' 'queen purse ground' 'queen purse ground'\", 'index': 0, 'logprobs': {'tokens': [\" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\", \" '\", 'queen', ' purse', ' ground', \"'\"], 'token_logprobs': [-2.1264122, -2.8050582, -0.7839242, -0.9836323, -1.6654338, -0.650056, -1.0063945, -0.33606395, -0.42576998, -0.53853834, -0.30946103, -0.25967905, -0.07881058, -0.092107065, -0.16469255, -0.1719482, -0.103121966, -0.03165035, -0.044297364, -0.12933418, -0.11698994, -0.09332539, -0.023467682, -0.031660505, -0.12822117, -0.09603254, -0.058969527, -0.021183545, -0.011719975, -0.079821035, -0.060123216, -0.04854138, -0.019436246, -0.028912721, -0.07499041, -0.051835027, -0.03178546, -0.013301522, -0.021632083, -0.0628258, -0.047359537, -0.026483284, -0.011044526, -0.0024126347, -0.061213672, -0.046847787, -0.02807656, -0.010212261, -0.018673785, -0.05531145, -0.040494006, -0.02154727, -0.009163405, -0.016185222, -0.057088185, -0.04038628, -0.01981358, -0.01018218, -0.0021992635, -0.047260165], 'top_logprobs': [{\" '\": -2.1264122, ' and': -2.2050216, ' (': -2.3976362, ' or': -3.3182027, ' -': -3.6768796}, {'queen': -2.8050582, 'n': -2.8497407, 'the': -3.4320877, 'product': -3.8158748, 'it': -4.0321264}, {' purse': -0.7839242, ' is': -3.4971504, \"'s\": -3.566104, ' ground': -4.1056204, ' brand': -4.167116}, {' ground': -0.9836323, ' is': -2.7416136, \"'\": -2.9289076, ' brand': -3.7008688, ' has': -4.218935}, {\"'\": -1.6654338, ' nobody': -1.808977, ' is': -2.3425426, ' not': -4.0115223, \"'\\n\\n\": -4.164876}, {\" '\": -0.650056, ' is': -2.6589632, ' and': -3.574215, ' (': -4.071027, ' has': -4.569433}, {'queen': -1.0063945, 'n': -2.3834314, 'ground': -3.6248808, 'Queen': -3.8419428, 'the': -4.0289545}, {' purse': -0.33606395, \"'\": -2.6467118, ' ground': -3.3331914, \"'s\": -4.3595624, ' purs': -5.3579583}, {' ground': -0.42576998, \"'\": -1.7963431, \"'\\n\\n\": -4.5917883, \" '\": -4.6953726, ' is': -5.006337}, {\"'\": -0.53853834, \"'\\n\\n\": -2.8745914, ' nobody': -3.4812589, ' is': -3.5942216, \"'.\": -4.032574}, {\" '\": -0.30946103, ' and': -3.9327912, ' is': -4.451055, ' (': -4.465195, ' ': -4.817061}, {'queen': -0.25967905, 'n': -2.945615, 'Queen': -4.69386, 'que': -5.0187397, 'ground': -5.045724}, {' purse': -0.07881058, \"'\": -4.6513653, ' ground': -5.0276995, \"'s\": -5.746009, '\\n\\n': -6.101569}, {' ground': -0.092107065, \"'\": -3.5911314, \" '\": -5.5147204, \"'\\n\\n\": -5.7694526, '\\n\\n': -6.3606334}, {\"'\": -0.16469255, \"'\\n\\n\": -2.6999662, \"'.\": -4.159983, \"'.\\n\\n\": -4.701819, \"',\": -4.936669}, {\" '\": -0.1719482, ' and': -4.5395813, ' (': -5.0594864, '<|endoftext|>': -5.128561, ' ': -5.1945457}, {'queen': -0.103121966, 'n': -3.4929307, 'que': -5.445648, 'Queen': -5.518635, 'no': -6.14771}, {' purse': -0.03165035, \"'\": -5.81985, '\\n\\n': -6.151272, ' ground': -6.3861027, \"'s\": -6.999072}, {' ground': -0.044297364, \"'\": -4.5687475, \" '\": -5.8386183, '\\n\\n': -6.388335, \"'\\n\\n\": -6.606433}, {\"'\": -0.12933418, \"'\\n\\n\": -2.8505752, \"'.\": -4.1582522, \"'.\\n\\n\": -4.5549693, \"',\": -5.033961}, {\" '\": -0.11698994, ' and': -4.8949795, '<|endoftext|>': -5.218399, ' (': -5.305339, ' ': -5.469968}, {'queen': -0.09332539, 'n': -3.6320522, 'que': -5.405201, 'Queen': -5.684285, 'no': -6.4684467}, {' purse': -0.023467682, '\\n\\n': -6.0826697, \"'\": -6.3059573, ' ground': -6.7471824, \" '\": -7.5152783}, {' ground': -0.031660505, \"'\": -5.2232842, \" '\": -5.729403, '\\n\\n': -6.241225, \"'\\n\\n\": -6.9159474}, {\"'\": -0.12822117, \"'\\n\\n\": -2.7940538, \"'.\": -4.191896, \"'.\\n\\n\": -4.5535645, \"'\\n\": -5.047446}, {\" '\": -0.09603254, ' and': -5.2885737, '<|endoftext|>': -5.3067746, ' queen': -5.3491025, ' (': -5.5345216}, {'queen': -0.058969527, 'n': -3.872733, 'que': -5.6427975, 'Queen': -6.315996, 'no': -7.0627003}, {' purse': -0.021183545, '\\n\\n': -6.004928, \"'\": -6.661857, ' ground': -6.8757834, \" '\": -7.3007913}, {' ground': -0.011719975, \" '\": -6.341203, \"'\": -6.503984, '\\n\\n': -7.2996955, ' Ground': -7.6471677}, {\"'\": -0.079821035, \"'\\n\\n\": -3.2285247, \"'.\": -4.7309403, \"'.\\n\\n\": -5.087671, \"'\\n\": -5.498896}, {\" '\": -0.060123216, '<|endoftext|>': -5.796335, ' and': -5.904747, ' queen': -6.0443554, ' (': -6.070919}, {'queen': -0.04854138, 'n': -4.0386176, 'que': -5.7257867, 'Queen': -6.7539, ' queen': -7.063233}, {' purse': -0.019436246, '\\n\\n': -5.8749013, ' ground': -6.9325185, '<|endoftext|>': -7.2376866, \"'\": -7.3102727}, {' ground': -0.028912721, \"'\": -5.456464, \" '\": -5.648835, '\\n\\n': -5.9401655, ' g': -7.2242956}, {\"'\": -0.07499041, \"'\\n\\n\": -3.2734826, \"'.\": -4.8040724, \"'.\\n\\n\": -5.1884365, \"',\": -5.6372366}, {\" '\": -0.051835027, '<|endoftext|>': -5.8226833, ' and': -6.087538, ' (': -6.154191, ' ': -6.2240467}, {'queen': -0.03178546, 'n': -4.543589, 'que': -6.0306764, ' queen': -7.0460343, 'Queen': -7.0614667}, {' purse': -0.013301522, '\\n\\n': -6.1492696, ' ground': -7.3393416, '<|endoftext|>': -7.5157046, ' pur': -7.7804503}, {' ground': -0.021632083, \" '\": -5.4133844, \"'\": -5.90668, '\\n\\n': -6.1475077, ' g': -7.7052298}, {\"'\": -0.0628258, \"'\\n\\n\": -3.4339948, \"'.\": -5.0761275, \"'.\\n\\n\": -5.314716, \"',\": -5.665631}, {\" '\": -0.047359537, '<|endoftext|>': -5.8771477, ' and': -5.9179096, ' (': -6.2916985, ' ': -6.4093}, {'queen': -0.026483284, 'n': -4.6453233, 'que': -6.119653, 'Queen': -7.221617, ' queen': -7.2414165}, {' purse': -0.011044526, '\\n\\n': -6.20041, '<|endoftext|>': -7.5961924, ' ground': -7.6355114, ' pur': -7.8702135}, {' ground': -0.0024126347, ' Ground': -7.9651747, \" '\": -8.259608, '\\n\\n': -8.780649, 'ground': -9.021526}, {\"'\": -0.061213672, \"'\\n\\n\": -3.4073575, \"'.\": -5.089694, \"'.\\n\\n\": -5.2759867, \"'\\n\": -5.7221327}, {\" '\": -0.046847787, '<|endoftext|>': -5.7694154, ' and': -6.033936, ' (': -6.2846417, ' ': -6.4047065}, {'queen': -0.02807656, 'n': -4.4728885, 'que': -6.1600823, 'Queen': -7.239961, ' queen': -7.274917}, {' purse': -0.010212261, '\\n\\n': -6.220967, '<|endoftext|>': -7.6003213, ' pur': -7.92874, ' ground': -7.949083}, {' ground': -0.018673785, \" '\": -5.677451, '\\n\\n': -6.0575323, \"'\": -6.3129635, ' g': -7.7361326}, {\"'\": -0.05531145, \"'\\n\\n\": -3.5175078, \"'.\": -5.202701, \"'.\\n\\n\": -5.360225, \"'\\n\": -5.813124}, {\" '\": -0.040494006, '<|endoftext|>': -5.779483, ' and': -6.1594305, ' (': -6.4406824, ' ': -6.469983}, {'queen': -0.02154727, 'n': -4.841213, 'que': -6.3381567, 'king': -7.3072214, ' queen': -7.3224545}, {' purse': -0.009163405, '\\n\\n': -6.2452865, '<|endoftext|>': -7.5423226, '.': -8.027446, ' pur': -8.124686}, {' ground': -0.016185222, \" '\": -5.8177752, '\\n\\n': -6.1978345, \"'\": -6.779322, ' g': -7.619228}, {\"'\": -0.057088185, \"'\\n\\n\": -3.4779007, \"'.\": -5.181545, \"'.\\n\\n\": -5.3639274, \"'\\n\": -5.7684264}, {\" '\": -0.04038628, '<|endoftext|>': -5.745161, ' and': -6.176506, ' (': -6.50064, ' ': -6.5071974}, {'queen': -0.01981358, 'n': -4.809721, 'que': -6.418236, 'Queen': -7.4877796, ' queen': -7.5017805}, {' purse': -0.01018218, '\\n\\n': -6.052744, '<|endoftext|>': -7.288763, '.': -7.8198633, ' purs': -7.986779}, {' ground': -0.0021992635, ' Ground': -8.110231, \" '\": -8.499203, '\\n\\n': -8.568729, ' grounded': -9.238521}, {\"'\": -0.047260165, \"'\\n\\n\": -3.6087742, \"'.\": -5.4063206, \"'.\\n\\n\": -5.643461, \"'\\n\": -6.0777225}], 'text_offset': [275, 277, 282, 288, 295, 296, 298, 303, 309, 316, 317, 319, 324, 330, 337, 338, 340, 345, 351, 358, 359, 361, 366, 372, 379, 380, 382, 387, 393, 400, 401, 403, 408, 414, 421, 422, 424, 429, 435, 442, 443, 445, 450, 456, 463, 464, 466, 471, 477, 484, 485, 487, 492, 498, 505, 506, 508, 513, 519, 526]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 59, 'completion_tokens': 60, 'total_tokens': 119}}\n",
      "Response JSON: {'id': 'cmpl-9JYeWP1tnvhJ02mueQvaiqo9cYjIx', 'object': 'text_completion', 'created': 1714448464, 'model': 'davinci-002', 'choices': [{'text': \" and 'comment french' and 'comment spanish' and 'comment german' and 'comment italian' and 'comment portuguese' and 'comment russian' and 'comment chinese' and 'comment japanese' and 'comment korean' and 'comment arabic' and 'comment hindi' and\", 'index': 0, 'logprobs': {'tokens': [' and', \" '\", 'comment', ' french', \"'\", ' and', \" '\", 'comment', ' spanish', \"'\", ' and', \" '\", 'comment', ' german', \"'\", ' and', \" '\", 'comment', ' italian', \"'\", ' and', \" '\", 'comment', ' port', 'ug', 'uese', \"'\", ' and', \" '\", 'comment', ' russian', \"'\", ' and', \" '\", 'comment', ' chinese', \"'\", ' and', \" '\", 'comment', ' japanese', \"'\", ' and', \" '\", 'comment', ' k', 'orean', \"'\", ' and', \" '\", 'comment', ' arab', 'ic', \"'\", ' and', \" '\", 'comment', ' hindi', \"'\", ' and'], 'token_logprobs': [-2.0454876, -0.32976797, -1.6072512, -2.404436, -1.0023352, -1.6382749, -0.2640519, -0.27234495, -1.2756145, -0.75177073, -0.71474737, -0.119958475, -0.2055825, -1.3235289, -0.51762897, -0.3338682, -0.058980543, -0.08449882, -1.1703861, -0.45903897, -0.1951855, -0.037429973, -0.077685505, -1.5279771, -0.02596908, -0.20150992, -0.39954555, -0.19489458, -0.038280286, -0.08665583, -1.6608843, -0.23339581, -0.07539864, -0.02057015, -0.03388899, -0.94370055, -0.30694538, -0.109259866, -0.022307906, -0.044212855, -0.6926764, -0.26027963, -0.13633817, -0.022493487, -0.038195837, -0.9746046, -0.019481957, -0.25873387, -0.13582274, -0.025321303, -0.048157234, -1.2120961, -0.0293703, -0.33238083, -0.18410924, -0.039569966, -0.07617549, -1.2286812, -0.17194296, -0.054699913], 'top_logprobs': [{' and': -2.0454876, ' (': -2.7030709, \" '\": -2.8115838, ' or': -3.3918517, ' ': -3.7735837}, {\" '\": -0.32976797, '/or': -3.807944, ' then': -3.9346225, ' the': -4.337825, ' also': -4.5103827}, {'comment': -1.6072512, 's': -2.9763298, 'social': -3.4911308, 'product': -3.878477, 'english': -4.4880276}, {' french': -2.404436, ' english': -2.8488493, ' spanish': -2.9876156, ' arab': -3.345911, ' on': -3.652256}, {\"'\": -1.0023352, \"'\\n\\n\": -1.5761887, \"'.\": -1.8003088, \"'.\\n\\n\": -1.9844977, \"',\": -3.6761937}, {' and': -1.6382749, ' (': -2.7325017, ' or': -3.1244228, ' in': -3.6445377, ' for': -3.7232778}, {\" '\": -0.2640519, ' so': -4.0335555, '/or': -4.135016, ' then': -4.207087, ' comment': -4.51111}, {'comment': -0.27234495, 's': -4.686051, 'social': -4.935035, 'other': -5.060591, ' comment': -5.1716666}, {' spanish': -1.2756145, ' german': -1.971792, ' arab': -2.8213146, ' chinese': -3.0350778, ' italian': -3.0473802}, {\"'\": -0.75177073, \"'\\n\\n\": -1.7617376, \"'.\": -1.8859851, \"'.\\n\\n\": -2.2454145, \"',\": -3.96899}, {' and': -0.71474737, ' (': -3.1669626, ' ': -3.8162584, ' or': -3.8219633, ' etc': -3.913066}, {\" '\": -0.119958475, ' so': -4.511802, ' comment': -5.129481, '\\n\\n': -5.5703454, ' etc': -5.604322}, {'comment': -0.2055825, 'other': -4.691842, 'comments': -5.014477, 'social': -5.356942, 'product': -5.5660315}, {' german': -1.3235289, ' italian': -2.0229802, ' chinese': -2.3855672, ' port': -2.6525578, ' arab': -3.214538}, {\"'\": -0.51762897, \"'\\n\\n\": -1.970465, \"'.\": -2.1973374, \"'.\\n\\n\": -2.4317658, \"',\": -4.2145247}, {' and': -0.3338682, ' (': -4.1328506, ' ': -4.2964764, ' etc': -4.4436913, ' or': -4.618614}, {\" '\": -0.058980543, '\\n\\n': -5.5959888, ' so': -5.8002276, ' comment': -6.142471, '...\\n\\n': -6.1518035}, {'comment': -0.08449882, 's': -5.7630877, 'english': -6.102735, 'answer': -6.150312, 'label': -6.263353}, {' italian': -1.1703861, ' port': -2.3980958, ' chinese': -2.519635, ' dut': -2.7627046, ' russian': -2.8505695}, {\"'\": -0.45903897, \"'\\n\\n\": -2.217789, \"'.\": -2.2223475, \"'.\\n\\n\": -2.4385064, \"',\": -4.339774}, {' and': -0.1951855, ' (': -4.426651, ' ': -4.6798496, '<|endoftext|>': -5.0097866, ' .': -5.0918465}, {\" '\": -0.037429973, '\\n\\n': -6.0471992, ' so': -6.2818527, ' comment': -6.4910994, ' \"': -6.6060505}, {'comment': -0.077685505, 'other': -4.9738874, 'comments': -5.489457, 'social': -6.772189, ' comment': -6.789771}, {' port': -1.5279771, ' chinese': -1.8828012, ' dut': -2.1134262, ' russian': -2.197773, ' japanese': -2.7394753}, {'ug': -0.02596908, 'ugal': -5.1064916, 'og': -5.237223, 'g': -5.8043065, 'uges': -6.0757203}, {'uese': -0.20150992, 'ese': -2.1750855, 'ues': -3.1276288, 'ue': -5.1147485, 'us': -5.8645425}, {\"'\": -0.39954555, \"'.\": -2.2941542, \"'\\n\\n\": -2.3503876, \"'.\\n\\n\": -2.468853, \"',\": -4.431038}, {' and': -0.19489458, ' (': -4.4535694, ' ': -4.714904, ' .': -4.997671, ' etc': -5.073818}, {\" '\": -0.038280286, '\\n\\n': -6.006445, ' so': -6.4094973, \"'\": -6.546195, ' \"': -6.602976}, {'comment': -0.08665583, 'other': -3.9796584, 'comments': -5.33735, 'english': -6.881974, ' comment': -6.930111}, {' russian': -1.6608843, ' chinese': -1.7457355, ' dut': -1.9891666, ' polish': -2.9034934, ' japanese': -2.947187}, {\"'\": -0.23339581, \"'\\n\\n\": -2.760791, \"'.\": -2.884106, \"'.\\n\\n\": -2.970794, \"',\": -4.8018694}, {' and': -0.07539864, ' (': -5.3836203, ' ': -5.410658, '<|endoftext|>': -5.6294575, ' .': -5.856058}, {\" '\": -0.02057015, '\\n\\n': -6.3831973, \"'\": -6.5656667, ' \"': -7.046304, ' ‘': -7.0930696}, {'comment': -0.03388899, 'other': -4.7782106, 'comments': -5.9741964, ' comment': -7.482543, 'english': -7.622901}, {' chinese': -0.94370055, ' arab': -2.3117673, ' japanese': -2.5143592, ' tur': -2.7581108, ' dut': -3.0342195}, {\"'\": -0.30694538, \"'.\\n\\n\": -2.5546308, \"'.\": -2.6553197, \"'\\n\\n\": -2.7141242, \"',\": -4.787708}, {' and': -0.109259866, ' (': -4.8509326, '<|endoftext|>': -5.368942, ' ': -5.3922, ' or': -5.564139}, {\" '\": -0.022307906, '\\n\\n': -6.392817, \"'\": -6.772589, ' so': -6.7837844, ' ‘': -6.870958}, {'comment': -0.044212855, 'other': -4.2421517, 'comments': -5.856111, ' comment': -7.5054345, 'english': -7.566149}, {' japanese': -0.6926764, ' arab': -2.0983438, ' k': -2.8775444, ' hindi': -3.2424088, ' japan': -3.387741}, {\"'\": -0.26027963, \"'.\": -2.6431303, \"'\\n\\n\": -2.7588186, \"'.\\n\\n\": -2.8058014, \"',\": -4.8454695}, {' and': -0.13633817, ' (': -4.6486807, ' ': -5.0108194, ' .': -5.055073, '<|endoftext|>': -5.108803}, {\" '\": -0.022493487, '\\n\\n': -6.5143604, ' ‘': -6.8213997, \"'\": -6.944891, ' so': -7.088788}, {'comment': -0.038195837, 'other': -4.491023, 'comments': -6.152423, 'english': -7.531128, 'com': -7.6551704}, {' k': -0.9746046, ' arab': -1.4175329, ' hindi': -2.7244873, ' other': -3.3036776, ' indian': -3.5534334}, {'orean': -0.019481957, 'orea': -4.3686776, 'ore': -5.2236524, 'urd': -7.8536325, 'oren': -9.346334}, {\"'\": -0.25873387, \"'.\": -2.6896791, \"'.\\n\\n\": -2.7750435, \"'\\n\\n\": -2.803669, \"',\": -4.727067}, {' and': -0.13582274, ' ': -4.889421, ' (': -4.894979, '<|endoftext|>': -5.0776067, ' .': -5.3509765}, {\" '\": -0.025321303, '\\n\\n': -6.557135, ' ‘': -6.7486014, ' so': -6.944185, ' other': -6.982125}, {'comment': -0.048157234, 'other': -4.281194, 'comments': -5.9702706, 'english': -7.297912, 'com': -7.605273}, {' arab': -1.2120961, ' hindi': -1.9184016, ' other': -2.646246, ' tur': -2.9718895, ' indian': -2.9830818}, {'ic': -0.0293703, \"'\": -4.0787888, 'ian': -5.50029, \"'.\\n\\n\": -6.2986193, \"'\\n\\n\": -6.322212}, {\"'\": -0.33238083, \"'\\n\\n\": -2.401173, \"'.\\n\\n\": -2.5201983, \"'.\": -2.626205, \"',\": -4.8801684}, {' and': -0.18410924, ' (': -4.6604447, ' ': -4.7411294, '<|endoftext|>': -4.9455924, ' .': -5.095738}, {\" '\": -0.039569966, ' so': -5.7515726, '\\n\\n': -6.11899, ' then': -6.7875614, ' ‘': -6.832095}, {'comment': -0.07617549, 'other': -3.5872095, 'comments': -5.4745617, ' comment': -7.13828, 'english': -7.218466}, {' hindi': -1.2286812, ' tur': -2.4663386, ' polish': -2.5487247, ' other': -2.7538466, ' indian': -3.4173388}, {\"'\": -0.17194296, \"'.\\n\\n\": -3.109913, \"'.\": -3.1174557, \"'\\n\\n\": -3.157472, \"',\": -5.55288}, {' and': -0.054699913, '<|endoftext|>': -5.884798, ' (': -6.017584, ' ': -6.0971355, ' etc': -6.20175}], 'text_offset': [258, 262, 264, 271, 278, 279, 283, 285, 292, 300, 301, 305, 307, 314, 321, 322, 326, 328, 335, 343, 344, 348, 350, 357, 362, 364, 368, 369, 373, 375, 382, 390, 391, 395, 397, 404, 412, 413, 417, 419, 426, 435, 436, 440, 442, 449, 451, 456, 457, 461, 463, 470, 475, 477, 478, 482, 484, 491, 497, 498]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 54, 'completion_tokens': 60, 'total_tokens': 114}}\n",
      "Response JSON: {'id': 'cmpl-9JYeXB01G21Jb5fKp32y7ryNtDb3n', 'object': 'text_completion', 'created': 1714448465, 'model': 'davinci-002', 'choices': [{'text': \" or 'no' (if you choose more than one, you must explain why you chose them).\\n\\nThe company has a good reputation and heritage. The company has a good reputation and heritage. The company has a good reputation and heritage. The company has a good reputation and heritage. The company has a\", 'index': 0, 'logprobs': {'tokens': [' or', \" '\", 'no', \"'\", ' (', 'if', ' you', ' choose', ' more', ' than', ' one', ',', ' you', ' must', ' explain', ' why', ' you', ' chose', ' them', ').\\n\\n', 'The', ' company', ' has', ' a', ' good', ' reputation', ' and', ' heritage', '.', ' The', ' company', ' has', ' a', ' good', ' reputation', ' and', ' heritage', '.', ' The', ' company', ' has', ' a', ' good', ' reputation', ' and', ' heritage', '.', ' The', ' company', ' has', ' a', ' good', ' reputation', ' and', ' heritage', '.', ' The', ' company', ' has', ' a'], 'token_logprobs': [-1.1191111, -0.039489985, -0.090171516, -0.9165846, -2.5265274, -3.0939312, -1.2484565, -1.5793539, -1.1267271, -0.03379876, -0.04004057, -0.8148097, -1.770719, -1.7540325, -2.076123, -0.86634386, -1.2128576, -1.282142, -1.642321, -1.6856279, -3.173754, -3.3328693, -2.0941398, -1.474845, -1.973802, -0.37091386, -0.7644937, -1.0595596, -1.7274394, -1.6620916, -0.68215597, -0.9904621, -1.0809765, -0.4843604, -0.9024918, -0.28259403, -0.024522945, -0.58972234, -0.98349637, -0.19705434, -0.36787012, -0.4255904, -0.052653614, -0.05710384, -0.018417398, -0.002178812, -0.34509885, -0.36784136, -0.051951714, -0.10269887, -0.106391184, -0.021902699, -0.019208703, -0.004456347, -0.0016372161, -0.16635905, -0.20906283, -0.026883502, -0.038862035, -0.02515787], 'top_logprobs': [{' or': -1.1191111, ' and': -2.3402472, \" '\": -2.688531, ' if': -2.8750925, ' for': -3.237939}, {\" '\": -0.039489985, ' no': -5.397395, ' not': -5.64347, ' a': -6.3767233, \"'\": -6.5069504}, {'no': -0.090171516, 'not': -3.7484252, 'yes': -5.3361697, 'maybe': -5.803654, 'No': -5.933437}, {\"'\": -0.9165846, \"'.\": -1.4708325, \"'.\\n\\n\": -1.900622, \"'\\n\\n\": -2.3931918, \"',\": -2.9406877}, {' (': -2.5265274, ' or': -2.6391973, ' and': -2.7306128, ' for': -3.023056, ' to': -3.2640514}, {'if': -3.0939312, '1': -3.2824974, 'e': -3.3420963, 'for': -3.4483604, 'or': -3.495264}, {' you': -1.2484565, ' the': -2.0653262, ' it': -2.2970634, ' yes': -2.6905227, ' no': -2.999638}, {' choose': -1.5793539, ' think': -2.7738109, ' are': -2.8973088, ' have': -3.0743413, ' don': -3.0818686}, {' more': -1.1267271, \" '\": -1.1931219, ' yes': -2.5813723, ' multiple': -3.152316, ' no': -3.227645}, {' than': -0.03379876, ',': -4.8366313, ' then': -5.334595, ' that': -5.765388, ' one': -6.267983}, {' one': -0.04004057, ' ': -3.7248359, ' two': -6.1779723, ' on': -6.5747466, ' once': -6.643598}, {',': -0.8148097, ' you': -2.8116446, ' label': -2.868678, ' please': -3.0723639, ' make': -3.5155888}, {' you': -1.770719, ' please': -1.8122096, ' then': -2.5152392, ' use': -3.0145383, ' the': -3.3483853}, {' must': -1.7540325, ' need': -1.7868122, ' can': -1.8055643, ' will': -2.1975455, ' should': -2.2793937}, {' explain': -2.076123, ' choose': -2.8187997, ' justify': -2.9518526, ' use': -3.150771, ' select': -3.3284013}, {' why': -0.86634386, ' your': -1.8959364, ' the': -2.3717122, ' how': -2.552404, ' each': -3.3336568}, {' you': -1.2128576, ').\\n\\n': -2.2762837, ')\\n\\n': -2.4458766, ').': -2.471191, ' in': -2.592667}, {' chose': -1.282142, ' have': -1.76728, ' choose': -2.04874, ' think': -2.6134906, ' did': -3.2547107}, {' them': -1.642321, ' it': -1.9734415, ' that': -2.2001758, ' each': -2.3104339, ' these': -2.5300508}, {').\\n\\n': -1.6856279, ')\\n\\n': -1.9648886, ').': -1.9911852, ' in': -2.3828382, ')': -2.6284485}, {'The': -3.173754, 'Product': -3.7889922, 'What': -3.8556387, '2': -3.95461, 'If': -4.085039}, {' company': -3.3328693, ' brand': -3.4319608, ' text': -3.5667188, ' product': -3.6004627, ' element': -3.6614406}, {' has': -2.0941398, ' is': -2.1863325, \"'s\": -2.317414, ' I': -2.7082555, ' that': -2.94931}, {' a': -1.474845, ' been': -2.231635, ' an': -3.4984226, ' the': -3.7176857, ' to': -4.0174665}, {' good': -1.973802, ' strong': -2.1128726, ' reputation': -2.340221, ' very': -3.0168214, ' high': -3.3252892}, {' reputation': -0.37091386, ' product': -2.9785085, ' quality': -3.0536342, ' brand': -3.9347892, ' image': -4.2747884}, {' and': -0.7644937, ' in': -2.3861148, ' for': -2.6971166, ',': -2.996866, ' among': -3.2852466}, {' heritage': -1.0595596, ' is': -2.4865024, ' a': -2.8144739, ' has': -3.0816085, ' it': -3.2058609}, {'.': -1.7274394, ',': -2.0366511, '.\\n\\n': -2.3484178, ' in': -2.6074843, '\\n\\n': -2.668098}, {' The': -1.6620916, ' It': -1.9015535, ' This': -2.5175338, ' They': -2.9476962, ' (': -3.2360473}, {' company': -0.68215597, ' brand': -2.753983, ' products': -3.339581, ' quality': -3.3896546, ' product': -3.4786344}, {' has': -0.9904621, ' is': -1.6678379, \"'s\": -3.336085, ' was': -3.4833438, '’s': -3.6386259}, {' a': -1.0809765, ' good': -1.9237003, ' been': -2.540472, ' an': -3.4321785, ' high': -3.5964966}, {' good': -0.4843604, ' strong': -2.933439, ' long': -3.5004623, ' high': -3.6116436, ' social': -3.8544796}, {' reputation': -0.9024918, ' customer': -1.877536, ' product': -2.2829907, ' social': -2.4230053, ' quality': -2.5495646}, {' and': -0.28259403, ' because': -3.094703, ' in': -3.222541, ' for': -4.04063, ',': -4.0852714}, {' heritage': -0.024522945, ' has': -6.0539427, ' good': -6.1085806, ' is': -6.2876034, ' history': -6.4757023}, {'.': -0.58972234, '.\\n\\n': -1.6537616, ' because': -2.6622179, ',': -3.6327941, '\\n\\n': -3.8548572}, {' The': -0.98349637, ' Yes': -2.833718, ' (': -3.127097, ' It': -3.1313179, ' This': -3.3410633}, {' company': -0.19705434, ' product': -3.4111314, ' quality': -4.3294053, ' products': -4.3445115, ' brand': -4.422935}, {' has': -0.36787012, ' is': -2.3294876, ' provides': -3.9440238, \"'s\": -4.0704613, ' offers': -4.2498837}, {' a': -0.4255904, ' good': -1.6031626, ' social': -4.375883, ' been': -4.441395, ' an': -4.529564}, {' good': -0.052653614, ' high': -5.0595727, ' strong': -5.093859, ' reputation': -5.277266, ' great': -6.0132585}, {' reputation': -0.05710384, ' product': -4.469586, ' customer': -4.7327056, ' quality': -4.919461, ' social': -5.0809903}, {' and': -0.018417398, '.': -5.4774685, ',': -6.0155525, ' in': -6.3829765, ' because': -6.729328}, {' heritage': -0.002178812, ' Heritage': -8.695821, '...\\n\\n': -8.852323, '\\n\\n': -8.895129, ' legacy': -8.902147}, {'.': -0.34509885, '.\\n\\n': -1.5542606, ' because': -4.574715, '\\n\\n': -4.5958276, ' The': -4.7291675}, {' The': -0.36784136, ' Yes': -3.706428, ' It': -4.0203967, ' ': -4.245298, ' This': -4.518624}, {' company': -0.051951714, ' product': -4.6533484, ' brand': -5.6325526, ' customer': -5.7346272, ' quality': -5.832047}, {' has': -0.10269887, ' is': -3.443767, \"'s\": -5.161802, ' does': -5.1935573, ' provides': -5.332214}, {' a': -0.106391184, ' good': -2.8021815, ' social': -5.6558332, ' an': -5.6578865, ' been': -5.661705}, {' good': -0.021902699, ' strong': -5.3267026, ' high': -6.1971936, ' reputation': -6.4698596, ' bad': -7.3003716}, {' reputation': -0.019208703, ' product': -5.738409, ' quality': -5.8266363, ' customer': -6.65539, ' social': -6.8045845}, {' and': -0.004456347, '.': -7.3344526, ',': -7.566739, ' a': -8.093151, '.\\n\\n': -8.412311}, {' heritage': -0.0016372161, ' her': -8.167468, ' legacy': -8.5799265, ' Heritage': -8.88494, '\\n\\n': -9.078286}, {'.': -0.16635905, '.\\n\\n': -2.0298061, ' The': -5.0671062, '.The': -5.8953714, '\\n\\n': -5.8973436}, {' The': -0.20906283, ' Yes': -4.163131, ' ': -4.5771737, '<|endoftext|>': -4.8094983, ' I': -5.0152}, {' company': -0.026883502, ' product': -5.316941, ' brand': -6.2049947, ' customer': -6.5301547, ' quality': -6.6378884}, {' has': -0.038862035, ' is': -4.4382553, \"'s\": -6.086298, ' does': -6.2195654, ' provides': -6.4441166}, {' a': -0.02515787, ' good': -4.380747, ' been': -6.7120924, ' an': -6.777816, ' social': -7.172847}], 'text_offset': [246, 249, 251, 253, 254, 256, 258, 262, 269, 274, 279, 283, 284, 288, 293, 301, 305, 309, 315, 320, 324, 327, 335, 339, 341, 346, 357, 361, 370, 371, 375, 383, 387, 389, 394, 405, 409, 418, 419, 423, 431, 435, 437, 442, 453, 457, 466, 467, 471, 479, 483, 485, 490, 501, 505, 514, 515, 519, 527, 531]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 60, 'total_tokens': 113}}\n",
      "Response JSON: {'id': 'cmpl-9JYeYGbiYVp54i55SM02JKR9OogBQ', 'object': 'text_completion', 'created': 1714448466, 'model': 'davinci-002', 'choices': [{'text': \" (other people's opinions), 'me' (my own opinions), 'you' (your own opinions), 'we' (our own opinions), 'they' (other people's opinions), 'it' (other people's opinions), 'us' (our own opinions), 'them' (\", 'index': 0, 'logprobs': {'tokens': [' (', 'other', ' people', \"'s\", ' opinions', '),', \" '\", 'me', \"'\", ' (', 'my', ' own', ' opinions', '),', \" '\", 'you', \"'\", ' (', 'your', ' own', ' opinions', '),', \" '\", 'we', \"'\", ' (', 'our', ' own', ' opinions', '),', \" '\", 'they', \"'\", ' (', 'other', ' people', \"'s\", ' opinions', '),', \" '\", 'it', \"'\", ' (', 'other', ' people', \"'s\", ' opinions', '),', \" '\", 'us', \"'\", ' (', 'our', ' own', ' opinions', '),', \" '\", 'them', \"'\", ' ('], 'token_logprobs': [-2.183268, -1.9732769, -0.63897634, -0.82625884, -1.1638714, -0.81280977, -0.3524393, -3.1645682, -0.057068933, -0.026070016, -1.111153, -1.0145786, -1.3741065, -0.34035107, -0.5932078, -3.6929736, -0.024036016, -0.012070792, -1.7124966, -1.2518611, -0.5894985, -0.5600236, -0.4580931, -1.79028, -0.04677305, -0.015946386, -1.495591, -0.47024313, -0.15904209, -0.5303519, -0.62277365, -1.0733, -0.013022806, -0.013891272, -0.70359784, -0.07865775, -0.028789954, -0.03060686, -0.9914381, -0.7878487, -2.1148922, -0.018395161, -0.0164057, -1.6791162, -0.07722777, -0.02301076, -0.07192216, -0.64501774, -0.46937612, -1.872299, -0.0142752705, -0.0114763, -0.2974914, -0.03139265, -0.045088377, -0.42203873, -0.2940776, -1.3524002, -0.01760767, -0.0075346986], 'top_logprobs': [{' (': -2.183268, \" '\": -2.2121806, ' and': -2.791263, ' is': -3.1088004, ' -': -3.1803346}, {'other': -1.9732769, 'out': -2.8754184, 'op': -3.3803718, 'online': -3.4671104, 'Other': -3.7275894}, {' people': -0.63897634, ' peoples': -2.6624262, ')': -3.3651125, ' option': -3.914738, '),': -4.02625}, {\"'s\": -0.82625884, '),': -1.8313458, ')': -2.0084794, '’s': -2.660537, ' perception': -3.9998057}, {' opinions': -1.1638714, ' opinion': -1.2182842, ' perceptions': -2.318725, ' perception': -2.8314366, ')': -3.2753978}, {'),': -0.81280977, ')': -1.3344371, ').': -2.7966363, ')\\n\\n': -3.1308305, ').\\n\\n': -3.4016826}, {\" '\": -0.3524393, ' other': -3.9619927, ' and': -4.513181, ' others': -4.705665, ' product': -4.8233495}, {'me': -3.1645682, 'self': -3.6019003, 'op': -3.604748, 'own': -3.825042, 'you': -4.143387}, {\"'\": -0.057068933, \"',\": -4.672598, 'ow': -5.395728, ' and': -5.6409245, 'a': -5.862445}, {' (': -0.026070016, ' and': -5.21866, \" ('\": -5.313473, ' or': -6.0171895, \" '\": -6.6405263}, {'my': -1.111153, 'your': -1.8872608, 'self': -2.2270818, 'personal': -2.3321652, 'what': -3.40873}, {' own': -1.0145786, ' personal': -2.0242507, 'self': -2.1143892, ' opinions': -2.6313035, ' opinion': -2.8727596}, {' opinions': -1.3741065, ' opinion': -1.6268979, ' personal': -2.045947, ' experience': -2.648509, ' experiences': -2.7067652}, {'),': -0.34035107, ')': -1.762846, ' and': -3.4370213, ' of': -4.685275, ',': -4.700137}, {\" '\": -0.5932078, ' and': -0.997992, ' or': -2.9827952, ' &': -6.493466, ' the': -6.6253657}, {'you': -3.6929736, 'my': -3.8697467, 'we': -3.9172044, 'em': -3.9429736, 'brand': -4.0982413}, {\"'\": -0.024036016, \"',\": -5.860002, ' (': -6.0752673, \"'re\": -6.3811355, ' &': -6.6390433}, {' (': -0.012070792, ' and': -6.0194426, \" ('\": -6.082059, ' or': -6.985545, '...\\n\\n': -7.5401278}, {'your': -1.7124966, 'the': -1.7474049, 'what': -2.4291124, 'other': -3.056304, 'how': -3.3641071}, {' own': -1.2518611, ' opinions': -2.2290988, ' customers': -2.6645083, ' brand': -2.7038932, ' opinion': -3.2029414}, {' opinions': -0.5894985, ' perceptions': -2.3564463, ' experiences': -3.2675238, ' opinion': -3.3725843, ' brand': -3.9362469}, {'),': -0.5600236, ')': -1.8609269, ').': -2.918975, ').\\n\\n': -2.9679186, ' of': -3.5406563}, {\" '\": -0.4580931, ' and': -1.2704177, ' or': -3.0197387, ' as': -6.311691, ' etc': -6.3871446}, {'we': -1.79028, 'it': -2.57486, 'us': -2.749166, 'they': -2.9505124, 'them': -3.4083838}, {\"'\": -0.04677305, \"',\": -4.758765, ' (': -5.6608095, \"'re\": -5.9144955, '/': -5.939413}, {' (': -0.015946386, ' and': -5.2664385, \" ('\": -6.0455303, ' or': -6.676097, '...\\n\\n': -7.449212}, {'our': -1.495591, 'your': -1.5778817, 'the': -2.5617695, 'other': -2.9479866, 'what': -3.5147448}, {' own': -0.47024313, ' opinions': -2.035342, ' collective': -3.3382366, ' shared': -3.7975976, ' company': -4.2806687}, {' opinions': -0.15904209, ' perceptions': -3.82911, ' and': -4.5701194, ' opinion': -4.781861, ' company': -4.7907786}, {'),': -0.5303519, ')': -1.82148, ').': -2.6408179, ').\\n\\n': -2.768842, ')\\n\\n': -3.7488406}, {\" '\": -0.62277365, ' and': -0.9769683, ' or': -2.9774823, ' etc': -6.046432, ' as': -6.43971}, {'they': -1.0733, 'it': -2.3985963, 'us': -2.9770865, 'them': -3.0006566, 'we': -3.3136582}, {\"'\": -0.013022806, \"',\": -5.841827, ' (': -6.7404084, \"'.\\n\\n\": -6.8628907, \"'(\": -6.950456}, {' (': -0.013891272, ' and': -5.6655636, \" ('\": -6.0902967, ' or': -6.9413185, '...\\n\\n': -7.2468853}, {'other': -0.70359784, 'their': -1.5639894, 'your': -2.7141435, 'the': -3.1126697, 'others': -3.4505842}, {' people': -0.07865775, ' peoples': -3.6738782, \"'s\": -4.25862, ' organisations': -5.155844, ' companies': -5.526139}, {\"'s\": -0.028789954, '’s': -4.5069013, ' opinions': -5.6671796, '),': -6.3591332, ').': -6.5989003}, {' opinions': -0.03060686, ' perceptions': -4.982736, ' opinion': -5.5228763, ' views': -6.4530063, ' opin': -6.824817}, {'),': -0.9914381, ').': -1.6955378, ').\\n\\n': -1.8657534, ')': -1.9649165, ')\\n\\n': -2.7476761}, {\" '\": -0.7878487, ' and': -1.0442898, ' or': -2.5267193, ' as': -5.0953693, ' etc': -5.1646185}, {'it': -2.1148922, 'us': -2.5055563, 'we': -3.288256, 'they': -3.3364804, 'now': -3.4101431}, {\"'\": -0.018395161, \"'s\": -5.5206285, \"',\": -5.998079, ' (': -6.1806474, \"'(\": -6.419336}, {' (': -0.0164057, \" ('\": -5.472736, ' and': -6.018704, ' or': -6.294166, '(': -7.601048}, {'other': -1.6791162, 'the': -1.9274645, 'your': -2.1071148, 'my': -2.8088284, 'our': -3.1519222}, {' people': -0.07722777, ' brands': -4.839242, ' products': -4.937518, ' peoples': -4.948266, ' things': -5.0036497}, {\"'s\": -0.02301076, '’s': -5.1705995, ' opinions': -5.681825, '),': -6.5712523, ' and': -6.745259}, {' opinions': -0.07192216, ' perceptions': -4.014015, ' opinion': -4.9985294, ' and': -6.231968, ' or': -6.2660904}, {'),': -0.64501774, ').': -2.0730963, ').\\n\\n': -2.1996212, ')': -2.2179213, ')\\n\\n': -2.8966131}, {\" '\": -0.46937612, ' and': -1.3814645, ' or': -2.9174743, ' etc': -5.1534142, ' as': -5.8903565}, {'us': -1.872299, 'it': -1.9238241, 'we': -3.0182855, 'they': -3.0255048, 'he': -3.2632625}, {\"'\": -0.0142752705, \"',\": -5.915898, ' (': -6.5034146, \"'(\": -6.7378144, '/': -6.7543626}, {' (': -0.0114763, ' and': -5.721019, \" ('\": -6.3610334, ' or': -6.8987684, '...\\n\\n': -7.8717766}, {'our': -0.2974914, 'other': -1.9553474, 'your': -3.2580216, 'my': -4.24824, 'their': -4.8081384}, {' own': -0.03139265, ' opinions': -4.07731, ' opinion': -6.726977, ' company': -6.9739556, ' perceptions': -7.0696626}, {' opinions': -0.045088377, ' opinion': -4.774758, ' perceptions': -4.8782525, ' experiences': -5.9942803, ' op': -6.453444}, {'),': -0.42203873, ')': -2.3750007, ').': -2.411781, ').\\n\\n': -2.5245416, ')\\n\\n': -3.240651}, {\" '\": -0.2940776, ' and': -1.6535976, ' or': -3.6285875, ' etc': -5.8237185, ' \"': -6.554006}, {'them': -1.3524002, 'it': -2.1320329, 'they': -2.6070008, 'me': -2.8711438, 'us': -3.0692601}, {\"'\": -0.01760767, ' (': -5.7165623, \"'(\": -5.9933023, \"',\": -6.1953363, \"'.\\n\\n\": -6.418581}, {' (': -0.0075346986, ' and': -6.5959477, \" ('\": -6.786181, '...\\n\\n': -7.482468, ' or': -7.748697}], 'text_offset': [246, 248, 253, 260, 262, 271, 273, 275, 277, 278, 280, 282, 286, 295, 297, 299, 302, 303, 305, 309, 313, 322, 324, 326, 328, 329, 331, 334, 338, 347, 349, 351, 355, 356, 358, 363, 370, 372, 381, 383, 385, 387, 388, 390, 395, 402, 404, 413, 415, 417, 419, 420, 422, 425, 429, 438, 440, 442, 446, 447]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 53, 'completion_tokens': 60, 'total_tokens': 113}}\n",
      "Response JSON: {'id': 'cmpl-9JYeZJ6oycGxDgtRFWgOYUGZZYAHY', 'object': 'text_completion', 'created': 1714448467, 'model': 'davinci-002', 'choices': [{'text': \" and 'actually plan create like plan u believe simpson story' and 'actually plan create like plan u believe simpson story' and 'actually plan create like plan u believe simpson story' and 'actually plan create like plan u believe simpson story' and 'actually plan create like plan u\", 'index': 0, 'logprobs': {'tokens': [' and', \" '\", 'actually', ' plan', ' create', ' like', ' plan', ' u', ' believe', ' simp', 'son', ' story', \"'\", ' and', \" '\", 'actually', ' plan', ' create', ' like', ' plan', ' u', ' believe', ' simp', 'son', ' story', \"'\", ' and', \" '\", 'actually', ' plan', ' create', ' like', ' plan', ' u', ' believe', ' simp', 'son', ' story', \"'\", ' and', \" '\", 'actually', ' plan', ' create', ' like', ' plan', ' u', ' believe', ' simp', 'son', ' story', \"'\", ' and', \" '\", 'actually', ' plan', ' create', ' like', ' plan', ' u'], 'token_logprobs': [-2.6335852, -0.953268, -2.1800098, -0.9285825, -0.3577052, -0.0958403, -0.124379255, -0.11985549, -0.10303142, -0.07766168, -0.0011499829, -0.17359209, -0.8262541, -1.0807776, -0.2663636, -0.16653354, -0.04625406, -0.027031556, -0.00907729, -0.019852022, -0.013465254, -0.01497038, -0.0036741868, -0.00026789203, -0.021114105, -0.4355315, -0.21625969, -0.06876938, -0.01922181, -0.00812113, -0.013057166, -0.0041406183, -0.006435169, -0.00718548, -0.009451828, -0.0035772647, -0.00022845028, -0.011305751, -0.18702237, -0.13900213, -0.0438022, -0.016741615, -0.0048644114, -0.006339572, -0.002832219, -0.0042492314, -0.0047344957, -0.0055387276, -0.0029118618, -0.00017481597, -0.0052369563, -0.14417994, -0.08841168, -0.030062279, -0.012212581, -0.002376723, -0.0049039084, -0.0027226103, -0.0039352067, -0.0037452138], 'top_logprobs': [{' and': -2.6335852, \" '\": -2.793135, ' (': -2.8293507, ' -': -3.7658474, ' ': -3.8010094}, {\" '\": -0.953268, ' then': -2.9491482, ' the': -3.4735641, ' use': -4.086873, ' you': -4.1555147}, {'actually': -2.1800098, 'like': -3.9036512, 'the': -4.241563, 'plan': -4.2560005, 'create': -4.3493996}, {' plan': -0.9285825, ' believe': -3.3164485, ' create': -3.547621, ' like': -3.7587483, ' want': -4.251718}, {' create': -0.3577052, ' like': -4.0897217, ' to': -4.101033, \"'\": -4.524707, ' created': -4.965741}, {' like': -0.0958403, ' plan': -4.446533, ' believe': -4.837841, ' u': -5.05262, ' simp': -5.0540533}, {' plan': -0.124379255, ' u': -4.4785433, ' simp': -5.0085077, '\\n\\n': -6.0633583, \"'\": -6.1430197}, {' u': -0.11985549, ' believe': -4.228681, ' simp': -4.582231, ' you': -6.11284, \"'\": -6.191318}, {' believe': -0.10303142, ' think': -5.19231, '\\n\\n': -5.9547153, ' bel': -6.00901, ' know': -6.038196}, {' simp': -0.07766168, ' story': -5.6016903, ' sim': -5.7892, \"'\": -6.004364, ' like': -6.103079}, {'son': -0.0011499829, 'sons': -7.8159084, 'sonian': -8.484291, 'so': -8.849631, 'ison': -9.723244}, {' story': -0.17359209, \"'\": -4.6577315, ' simp': -4.7467246, \"'.\": -5.600249, ' like': -5.6668363}, {\"'\": -0.8262541, \"'.\": -1.787554, \"'.\\n\\n\": -2.226065, \"'\\n\\n\": -2.986376, \"',\": -3.8929389}, {' and': -1.0807776, ' (': -3.4966502, ' you': -3.5166154, ' as': -3.5708356, ' is': -4.125583}, {\" '\": -0.2663636, ' \"': -4.25915, ' then': -4.5060315, '\\n\\n': -4.7265916, ' also': -4.7698407}, {'actually': -0.16653354, 'actual': -4.740158, 'simp': -5.2602577, 'like': -5.3709087, ' actually': -5.4471655}, {' plan': -0.04625406, ' simp': -5.788124, ' create': -5.9083433, \"'\": -6.1194477, ' believe': -6.5052824}, {' create': -0.027031556, ' like': -6.454869, '\\n\\n': -6.543798, \"'\": -6.641319, '.': -6.8298936}, {' like': -0.00907729, '\\n\\n': -7.6538095, ' plan': -7.68437, \"'\": -8.003953, ' u': -8.082415}, {' plan': -0.019852022, '\\n\\n': -6.51934, ' u': -6.7523847, '.': -7.0388703, '.\\n\\n': -7.3498616}, {' u': -0.013465254, ' believe': -7.1451783, '\\n\\n': -7.252708, ' simp': -7.46724, ' Simpson': -7.8780828}, {' believe': -0.01497038, ' belie': -6.2644773, '\\n\\n': -6.8770757, '.': -7.34514, ' bel': -7.5247416}, {' simp': -0.0036741868, ' sim': -7.720163, \"'\": -8.091261, ' Simpson': -8.407332, \"'.\": -8.825465}, {'son': -0.00026789203, 'sons': -8.656765, 'so': -9.909869, 's': -10.454295, 'sonian': -12.691474}, {' story': -0.021114105, \"'\": -6.2624917, \"'.\": -6.7357745, '\\n\\n': -6.782721, \"'.\\n\\n\": -6.9628825}, {\"'\": -0.4355315, \"'.\": -2.180354, \"'.\\n\\n\": -2.444538, \"'\\n\\n\": -2.5154085, \"',\": -4.2924986}, {' and': -0.21625969, ' you': -4.5096736, ' as': -4.871322, ' (': -5.0038724, \" '\": -5.1105437}, {\" '\": -0.06876938, ' \"': -5.182124, '\\n\\n': -5.1821747, '.\\n\\n': -6.448654, \" ''\": -6.4906826}, {'actually': -0.01922181, 'actual': -5.7555003, ' actually': -6.505548, 'really': -7.633722, 'Actually': -7.8570733}, {' plan': -0.00812113, '\\n\\n': -7.105558, '.': -7.919024, '.\\n\\n': -8.093172, \"'\": -8.305059}, {' create': -0.013057166, '\\n\\n': -6.6456237, '.': -7.147797, '.\\n\\n': -7.3713403, \"'\": -7.7018456}, {' like': -0.0041406183, '\\n\\n': -7.7588396, ' lik': -8.4293375, '.': -8.448337, '.\\n\\n': -8.772888}, {' plan': -0.006435169, '\\n\\n': -7.15273, '.': -7.8492174, '.\\n\\n': -8.119719, \"'\": -8.192743}, {' u': -0.00718548, '\\n\\n': -7.221705, '.': -8.031233, '.\\n\\n': -8.166948, ' us': -8.472857}, {' believe': -0.009451828, ' belie': -6.7349434, '\\n\\n': -6.8949995, ' be': -7.3725595, ' bel': -7.419977}, {' simp': -0.0035772647, \"'\": -7.836275, ' sim': -8.039565, '\\n\\n': -8.384198, \"'.\": -8.674478}, {'son': -0.00022845028, 'so': -9.410873, 'sons': -10.150167, 's': -10.622521, ' son': -11.259675}, {' story': -0.011305751, '\\n\\n': -6.8937054, \"'\": -7.035001, \"'.\": -7.692753, '.': -7.722107}, {\"'\": -0.18702237, \"'.\": -2.9459708, \"'.\\n\\n\": -3.1243393, \"'\\n\\n\": -3.1782372, \"',\": -5.0818405}, {' and': -0.13900213, ' as': -5.105618, '<|endoftext|>': -5.4146314, ' (': -5.4291444, \" '\": -5.4552617}, {\" '\": -0.0438022, '\\n\\n': -5.3722687, ' \"': -6.047385, '.': -6.848893, '.\\n\\n': -6.850339}, {'actually': -0.016741615, 'actual': -5.8375273, ' actually': -6.7054605, 'Actually': -7.8494396, 'really': -7.855118}, {' plan': -0.0048644114, '\\n\\n': -7.4575334, '.': -8.375186, ' p': -8.534682, ' pl': -8.646949}, {' create': -0.006339572, '\\n\\n': -7.4309535, '.': -8.059646, \"'\": -8.225874, 'create': -8.300656}, {' like': -0.002832219, '\\n\\n': -8.118393, ' lik': -8.428329, '.': -8.857557, '.\\n\\n': -9.302111}, {' plan': -0.0042492314, '\\n\\n': -7.4156823, '.': -8.198116, '.\\n\\n': -8.574575, \" '\": -8.686073}, {' u': -0.0047344957, '\\n\\n': -7.4209123, '.': -8.27893, '.\\n\\n': -8.624943, '<|endoftext|>': -8.626573}, {' believe': -0.0055387276, ' belie': -6.9975443, ' be': -7.005849, '\\n\\n': -7.6533375, ' bel': -8.223287}, {' simp': -0.0029118618, \"'\": -7.999952, '\\n\\n': -8.374904, ' sim': -8.375414, '.': -8.669706}, {'son': -0.00017481597, 'so': -9.360766, 's': -10.787548, 'sons': -10.959653, ' son': -11.144668}, {' story': -0.0052369563, '\\n\\n': -7.4228454, \"'\": -8.025537, '.': -8.305304, 'story': -8.415782}, {\"'\": -0.14417994, \"'.\": -3.2369933, \"'\\n\\n\": -3.3530908, \"'.\\n\\n\": -3.371944, \"',\": -5.2322717}, {' and': -0.08841168, ' as': -5.6962, ' (': -5.7389627, '<|endoftext|>': -5.783131, \" '\": -5.832875}, {\" '\": -0.030062279, '\\n\\n': -5.514169, ' \"': -6.532414, '.\\n\\n': -6.9612355, '.': -6.989034}, {'actually': -0.012212581, 'actual': -5.970763, ' actually': -6.8019314, 'Actually': -8.065769, 'a': -8.094292}, {' plan': -0.002376723, '\\n\\n': -8.001736, '.': -8.885071, '<|endoftext|>': -9.210302, '.\\n\\n': -9.291255}, {' create': -0.0049039084, '\\n\\n': -7.648097, '.': -8.292358, \"'\": -8.540035, 'create': -8.560684}, {' like': -0.0027226103, ' lik': -8.084576, '\\n\\n': -8.125516, '.': -8.899358, ' li': -9.056853}, {' plan': -0.0039352067, '\\n\\n': -7.3788486, '.': -8.274375, ' pl': -8.730211, '.\\n\\n': -8.763118}, {' u': -0.0037452138, '\\n\\n': -7.6040564, '.': -8.518798, '<|endoftext|>': -8.677165, ' us': -8.886907}], 'text_offset': [297, 301, 303, 311, 316, 323, 328, 333, 335, 343, 348, 351, 357, 358, 362, 364, 372, 377, 384, 389, 394, 396, 404, 409, 412, 418, 419, 423, 425, 433, 438, 445, 450, 455, 457, 465, 470, 473, 479, 480, 484, 486, 494, 499, 506, 511, 516, 518, 526, 531, 534, 540, 541, 545, 547, 555, 560, 567, 572, 577]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 62, 'completion_tokens': 60, 'total_tokens': 122}}\n",
      "Response JSON: {'id': 'cmpl-9JYeZcKTHR5cb0VXOS8ogiNfptFL3', 'object': 'text_completion', 'created': 1714448467, 'model': 'davinci-002', 'choices': [{'text': ' by alexander mcqueen. The fashion industry is a complex and multifaceted industry that is constantly changing and evolving the fashion industry is a complex and multifaceted industry that is constantly changing and evolving. The fashion industry is a complex and multifaceted industry that is constantly changing and evolving the fashion', 'index': 0, 'logprobs': {'tokens': [' by', ' alex', 'ander', ' mc', 'queen', '.', ' The', ' fashion', ' industry', ' is', ' a', ' complex', ' and', ' multif', 'ac', 'eted', ' industry', ' that', ' is', ' constantly', ' changing', ' and', ' evolving', ' the', ' fashion', ' industry', ' is', ' a', ' complex', ' and', ' multif', 'ac', 'eted', ' industry', ' that', ' is', ' constantly', ' changing', ' and', ' evolving', '.', ' The', ' fashion', ' industry', ' is', ' a', ' complex', ' and', ' multif', 'ac', 'eted', ' industry', ' that', ' is', ' constantly', ' changing', ' and', ' evolving', ' the', ' fashion'], 'token_logprobs': [-2.5192692, -3.9234183, -1.0450554, -0.99586827, -0.01274943, -1.9257923, -3.0190387, -3.357096, -0.77926594, -0.8419269, -1.4752327, -2.2935038, -1.922327, -2.4725125, -0.012487174, -0.00022535099, -1.6154859, -1.4586424, -1.6662629, -2.4740984, -1.1173463, -1.1268011, -1.0244266, -2.380359, -1.1016008, -0.16698842, -0.8445346, -1.6646966, -1.1206269, -0.25920296, -0.011935686, -0.0011983246, -0.0004222131, -0.0039520673, -0.013449731, -0.010943469, -0.010201874, -0.020205019, -0.030682355, -0.08150823, -1.5319265, -1.5921223, -1.0044785, -0.23879685, -0.7232557, -1.107253, -1.065936, -0.52036107, -0.087895855, -0.0017670509, -0.00023619852, -0.02640329, -0.03489324, -0.015415703, -0.008202956, -0.015777545, -0.009186441, -0.012964916, -1.4395174, -0.51967126], 'top_logprobs': [{' by': -2.5192692, ' (': -2.5686696, ' and': -2.6386044, \" '\": -3.1522124, ' -': -3.258571}, {' alex': -3.9234183, ':': -3.9827788, ' j': -4.027854, ' k': -4.2848883, ' d': -4.4394064}, {'ander': -1.0450554, 'andra': -1.0534534, 'a': -3.4291906, 'is': -4.19878, 'ia': -4.3745413}, {' mc': -0.99586827, ' wang': -1.500401, ' v': -3.5505977, ' w': -3.8001304, ' m': -3.907188}, {'queen': -0.01274943, 'que': -5.242704, 'Queen': -5.8982825, ' queen': -6.5910993, 'q': -6.875584}, {'.': -1.9257923, ',': -2.501453, '.\\n\\n': -2.5169473, '\\n\\n': -2.7486196, ' (': -3.04592}, {' The': -3.0190387, ' ': -3.720737, ' I': -3.8386388, \" '\": -3.8674102, ' This': -4.0777717}, {' fashion': -3.357096, ' alex': -3.9244149, ' brand': -3.9399617, ' essay': -4.0313683, ' ': -4.2631655}, {' industry': -0.77926594, ' world': -3.5056548, ' brand': -3.529615, ' and': -3.5809255, ' designer': -3.6666188}, {' is': -0.8419269, ' has': -1.8744996, ' and': -3.6080887, ',': -3.6569712, \"'s\": -3.849311}, {' a': -1.4752327, ' one': -2.3957553, ' the': -2.7159371, ' an': -3.063785, ' known': -3.8534331}, {' complex': -2.2935038, ' multi': -2.4388838, ' global': -2.753106, ' very': -3.2208014, ' major': -3.389802}, {' and': -1.922327, ' system': -2.129076, ' web': -2.7304506, ',': -2.9132433, ' one': -3.006772}, {' multif': -2.4725125, ' ever': -2.9584563, ' diverse': -3.051719, ' dynamic': -3.1163037, ' constantly': -3.2386906}, {'ac': -0.012487174, 'arious': -4.945753, 'aced': -6.343405, 'unction': -6.4203053, 'acet': -7.857313}, {'eted': -0.00022535099, 'ited': -9.841988, 'et': -10.392606, 'ted': -10.801686, 'ete': -11.234295}, {' industry': -1.6154859, ' entity': -2.3406856, ' machine': -2.585365, ' system': -2.6460598, ' business': -2.790817}, {' that': -1.4586424, ',': -1.9759792, ' it': -2.6699185, ' with': -2.7756867, ' the': -2.8497634}, {' is': -1.6662629, ' has': -1.7112715, ' includes': -3.0426772, ' encompasses': -3.107756, ' can': -3.6699965}, {' constantly': -2.4740984, ' made': -3.4673111, ' comprised': -3.508011, ' not': -3.527305, ' a': -3.6834939}, {' changing': -1.1173463, ' evolving': -1.1352706, ' growing': -2.89881, ' in': -3.4836745, ' developing': -3.979525}, {' and': -1.1268011, ',': -2.5212693, ' in': -2.7883363, ' the': -2.9650998, ' to': -3.073853}, {' evolving': -1.0244266, ' adapting': -2.3732862, ' developing': -2.9088087, ' growing': -3.022149, ' transforming': -3.700698}, {' the': -2.380359, ' with': -2.586922, ' in': -2.6496031, ' to': -2.7440073, ',': -2.9347832}, {' fashion': -1.1016008, ' industry': -2.227436, ' world': -4.403657, ' purpose': -4.4480677, ' term': -4.535018}, {' industry': -0.16698842, ' world': -3.361864, ' business': -4.4774942, ' cycle': -4.5132694, ' system': -4.669113}, {' is': -0.8445346, ' has': -1.9577396, ' can': -3.2658155, ' consists': -3.2999256, ' includes': -3.4999607}, {' a': -1.6646966, ' made': -3.01748, ' not': -3.1867342, ' comprised': -3.2020702, ' one': -3.2934427}, {' complex': -1.1206269, ' global': -2.8536515, ' very': -2.875815, ' multi': -3.3321805, ' highly': -3.8499389}, {' and': -0.25920296, ',': -3.0746536, ' industry': -3.6999283, ' system': -3.768816, ' multif': -4.343008}, {' multif': -0.011935686, ' multi': -6.406653, '.': -7.11157, ' multid': -7.1220765, ' complex': -7.381656}, {'ac': -0.0011983246, 'aced': -7.4055047, 'a': -8.638716, '<|endoftext|>': -9.290342, 'acet': -9.667562}, {'eted': -0.0004222131, 'et': -9.38853, 'etary': -9.464583, 'eter': -9.847575, 'ented': -9.990052}, {' industry': -0.0039520673, '.': -7.617388, ' indu': -8.245708, ' indust': -8.450249, '.\\n\\n': -8.623759}, {' that': -0.013449731, '.': -6.1285677, ' the': -6.6285744, '.\\n\\n': -6.89215, ',': -7.0928802}, {' is': -0.010943469, ' has': -6.444146, '.': -6.522605, '.\\n\\n': -7.2643423, ' the': -8.224568}, {' constantly': -0.010201874, '.': -6.2171474, '.\\n\\n': -6.78602, ' continually': -7.1661897, ' always': -7.4544024}, {' changing': -0.020205019, '.': -4.9870706, '.\\n\\n': -5.4423184, ' chang': -6.769192, ' evolving': -6.9222245}, {' and': -0.030682355, '.': -4.242449, '.\\n\\n': -4.7816515, ' the': -7.0407085, ' an': -7.4092007}, {' evolving': -0.08150823, '.': -3.3398662, '.\\n\\n': -3.9187875, ' ev': -6.222339, ' .': -6.3631034}, {'.': -1.5319265, '.\\n\\n': -2.1569, ' the': -2.4534574, ' fashion': -2.9769597, ' it': -3.4387088}, {' The': -1.5921223, ' Fashion': -2.3227913, ' ': -3.7716115, ' In': -3.77271, ' This': -3.7763522}, {' fashion': -1.0044785, ' impact': -4.07568, ' global': -4.1290436, ' history': -4.5946636, ' industry': -4.67}, {' industry': -0.23879685, ' world': -3.790982, ' and': -4.1066003, ' retail': -4.2023606, ' business': -4.496941}, {' is': -0.7232557, ' has': -2.1882892, ',': -3.760344, ' in': -3.794022, ' and': -3.82101}, {' a': -1.107253, ' one': -2.4472275, ' an': -2.9281998, ' the': -2.9509602, ' constantly': -3.5841093}, {' complex': -1.065936, ' multi': -2.9729176, ' global': -2.99465, ' very': -3.1834497, ' complicated': -3.8917751}, {' and': -0.52036107, ',': -2.4162436, ' system': -3.6749868, ' industry': -3.7089577, ' web': -3.8436909}, {' multif': -0.087895855, ' ever': -4.6699004, ' dynamic': -4.701445, ' highly': -5.5541816, ' constantly': -5.565684}, {'ac': -0.0017670509, 'arious': -7.6344852, 'aced': -7.745493, 'unction': -8.224721, 'actor': -8.618455}, {'eted': -0.00023619852, 'et': -9.661139, 'etary': -10.454554, 'eter': -10.478497, 'ited': -10.663723}, {' industry': -0.02640329, ' sector': -5.6646423, ' business': -5.737587, ' system': -6.4379854, ' world': -6.451642}, {' that': -0.03489324, ' the': -5.31122, ',': -5.3393917, ' it': -5.5726376, ' which': -6.700201}, {' is': -0.015415703, ' has': -5.878449, ' constantly': -6.7095513, \"'s\": -7.489969, '’s': -7.562144}, {' constantly': -0.008202956, ' continually': -7.0017295, ' always': -7.076402, ' continuously': -7.155027, ' changing': -7.650084}, {' changing': -0.015777545, ' evolving': -5.190954, ' change': -7.0480175, ' chang': -7.516675, ' growing': -7.5566607}, {' and': -0.009186441, ' the': -6.723249, ',': -6.9068723, ' alex': -7.5394073, ' in': -7.9498544}, {' evolving': -0.012964916, ' ev': -5.908652, ' evolution': -6.6317716, ' changing': -6.858047, ' the': -7.3652883}, {' the': -1.4395174, ' it': -2.452721, ' fashion': -2.9850392, ' in': -3.1124797, ' this': -3.2149482}, {' fashion': -0.51967126, ' industry': -2.6050527, ' world': -4.8580084, ' global': -4.989176, ' term': -4.9999113}], 'text_offset': [271, 274, 279, 284, 287, 292, 293, 297, 305, 314, 317, 319, 327, 331, 338, 340, 344, 353, 358, 361, 372, 381, 385, 394, 398, 406, 415, 418, 420, 428, 432, 439, 441, 445, 454, 459, 462, 473, 482, 486, 495, 496, 500, 508, 517, 520, 522, 530, 534, 541, 543, 547, 556, 561, 564, 575, 584, 588, 597, 601]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 56, 'completion_tokens': 60, 'total_tokens': 116}}\n",
      "Response JSON: {'id': 'cmpl-9JYea2WuRgstA6xqrRRAmf8Hwm09Y', 'object': 'text_completion', 'created': 1714448468, 'model': 'davinci-002', 'choices': [{'text': ' is a brand that is known for its quality and reputation. Simpson better is a brand that is known for its quality and reputation. Simpson better is a brand that is known for its quality and reputation. Simpson better is a brand that is known for its quality and reputation. Simpson better is a brand that', 'index': 0, 'logprobs': {'tokens': [' is', ' a', ' brand', ' that', ' is', ' known', ' for', ' its', ' quality', ' and', ' reputation', '.', ' Simpson', ' better', ' is', ' a', ' brand', ' that', ' is', ' known', ' for', ' its', ' quality', ' and', ' reputation', '.', ' Simpson', ' better', ' is', ' a', ' brand', ' that', ' is', ' known', ' for', ' its', ' quality', ' and', ' reputation', '.', ' Simpson', ' better', ' is', ' a', ' brand', ' that', ' is', ' known', ' for', ' its', ' quality', ' and', ' reputation', '.', ' Simpson', ' better', ' is', ' a', ' brand', ' that'], 'token_logprobs': [-2.162886, -1.1296053, -2.0770037, -0.8738949, -1.7540333, -1.9937028, -0.2108325, -0.87044, -1.5600318, -1.5784094, -1.7892553, -1.3972679, -2.0478878, -1.0464232, -1.2333618, -0.8706541, -0.93217856, -0.27493116, -0.73019934, -0.38261834, -0.056088414, -0.14046091, -0.66490287, -0.25217333, -0.06676654, -0.9579898, -1.950078, -0.43705353, -0.5201416, -0.15425707, -0.13841997, -0.072885714, -0.15673609, -0.10187411, -0.01699538, -0.040115703, -0.23103616, -0.09073093, -0.02403438, -0.38728097, -0.49887046, -0.1614498, -0.05794623, -0.036493428, -0.02772692, -0.029978648, -0.026347209, -0.013867162, -0.0063657477, -0.013735133, -0.051652655, -0.017767895, -0.008056559, -0.22133245, -0.30319306, -0.085143425, -0.025203792, -0.015173406, -0.015582628, -0.012762732], 'top_logprobs': [{' is': -2.162886, \" '\": -2.4398415, ' and': -2.4636672, ' (': -2.576647, ' has': -3.5359461}, {' a': -1.1296053, ' the': -1.9379358, ' an': -2.687047, ' one': -3.6748323, ' known': -3.7529516}, {' brand': -2.0770037, ' company': -2.7501414, ' product': -3.129083, ' good': -3.319031, \" '\": -3.7975342}, {' that': -0.8738949, ' with': -2.6114008, ' of': -2.6685727, ' which': -2.683923, ' name': -3.5216591}, {' is': -1.7540333, ' has': -2.024748, ' offers': -3.2094548, ' sells': -3.2160132, ' focuses': -3.5129874}, {' known': -1.9937028, ' well': -3.1199617, ' perceived': -3.4026375, ' committed': -3.4810495, ' a': -3.5675144}, {' for': -0.2108325, ' to': -2.828144, ' as': -3.6408558, ' by': -4.2680216, ' and': -4.417099}, {' its': -0.87044, ' their': -2.9696822, ' the': -3.0623403, ' high': -3.098351, ' quality': -3.171122}, {' quality': -1.5600318, ' high': -1.6909808, ' product': -2.6800613, \" '\": -3.3260098, ' reputation': -3.4475422}, {' and': -1.5784094, ',': -1.7139876, ' products': -1.820904, ' of': -2.4548419, '.': -2.7667077}, {' reputation': -1.7892553, ' heritage': -2.7258196, ' reliability': -3.0566578, ' its': -3.112589, ' durability': -3.4631968}, {'.': -1.3972679, ' and': -2.0463233, ',': -2.1065087, ' in': -2.6504073, '.\\n\\n': -2.8241973}, {' Simpson': -2.0478878, ' The': -2.4640894, ' It': -2.47828, ' This': -3.1785603, \" '\": -3.603466}, {' better': -1.0464232, ' is': -2.130895, ' has': -2.4343235, \"'s\": -2.9348776, '’s': -3.7694685}, {' is': -1.2333618, ' has': -2.023891, \"'s\": -3.2271342, ' products': -3.6899676, ' also': -3.7859874}, {' a': -0.8706541, ' also': -2.4994297, ' known': -2.5142612, ' an': -2.9466686, ' the': -3.447486}, {' brand': -0.93217856, ' company': -2.598528, ' well': -3.0642033, ' product': -3.5008373, ' family': -3.9285564}, {' that': -0.27493116, ' with': -3.183058, ' which': -3.4832194, ' known': -3.6463587, ' of': -3.9330199}, {' is': -0.73019934, ' has': -1.918428, ' offers': -3.591289, ' provides': -3.624247, ' cares': -3.9683204}, {' known': -0.38261834, ' well': -3.4273095, ' also': -4.217507, ' associated': -4.367516, ' committed': -4.50462}, {' for': -0.056088414, ' to': -4.057763, ' as': -4.7987776, ' and': -5.763055, ' in': -6.2099934}, {' its': -0.14046091, ' the': -3.8063908, ' their': -4.678197, ' quality': -4.6911936, ' it': -5.1420765}, {' quality': -0.66490287, ' reputation': -2.133486, ' customer': -3.0419877, ' product': -3.1391938, ' ethical': -3.638327}, {' and': -0.25217333, ',': -2.2418594, '.': -3.5705786, ' reputation': -3.9077978, '.\\n\\n': -4.9558983}, {' reputation': -0.06676654, ' its': -4.574481, ' heritage': -4.855171, ' is': -5.876994, ' has': -5.951542}, {'.': -0.9579898, ',': -2.26688, '.\\n\\n': -2.426464, ' and': -2.8611507, ' it': -3.4822054}, {' Simpson': -1.950078, ' It': -2.2943592, ' The': -2.4237156, ' it': -3.2001438, ' This': -3.571988}, {' better': -0.43705353, ' is': -2.4525182, ' has': -3.1563795, \"'s\": -3.3176725, '’s': -4.3904133}, {' is': -0.5201416, ' has': -2.46552, \"'s\": -3.7228785, ' offers': -4.133875, ' also': -4.2758017}, {' a': -0.15425707, ' known': -3.4885437, ' also': -4.0483966, ' an': -4.369536, ' the': -4.6341405}, {' brand': -0.13841997, ' company': -4.230114, ' well': -4.6693497, ' premium': -5.2268944, ' trusted': -5.285227}, {' that': -0.072885714, ' known': -3.8898509, ' with': -4.441699, ' which': -5.127822, ' whose': -5.9045134}, {' is': -0.15673609, ' has': -3.1844823, ' provides': -4.789251, ' offers': -4.9364333, ' cares': -5.45668}, {' known': -0.10187411, ' well': -4.5332184, ' famous': -5.091872, ' recognized': -5.1866646, ' a': -5.5520144}, {' for': -0.01699538, ' to': -5.4340696, ' as': -5.7202444, '\\n\\n': -7.1179905, ' and': -7.1325197}, {' its': -0.040115703, ' the': -5.373174, ' quality': -5.5949254, ' customer': -5.7042584, ' ethical': -6.3079114}, {' quality': -0.23103616, ' reputation': -2.3748703, ' customer': -3.820198, ' product': -4.0635176, ' social': -4.538247}, {' and': -0.09073093, ',': -3.1522944, '.': -4.2795825, ' reputation': -4.4579425, '.\\n\\n': -5.608311}, {' reputation': -0.02403438, ' its': -5.500286, ' heritage': -6.445278, '\\n\\n': -6.650011, '.': -6.858568}, {'.': -0.38728097, '.\\n\\n': -1.8923697, ' and': -3.0320888, ',': -3.406425, '\\n\\n': -4.813744}, {' Simpson': -0.49887046, ' The': -3.2446752, ' It': -3.7275243, ' This': -4.3657584, '<|endoftext|>': -4.605148}, {' better': -0.1614498, ' is': -3.0999484, \"'s\": -4.092541, ' has': -4.748961, ' Better': -4.931845}, {' is': -0.05794623, ' has': -4.675023, \"'s\": -5.6736717, ' brand': -6.0471563, ' offers': -6.0911655}, {' a': -0.036493428, ' known': -4.3408184, ' an': -5.4255695, ' the': -5.9561434, ' also': -6.5026646}, {' brand': -0.02772692, ' company': -5.9644947, ' well': -6.2895164, '\\n\\n': -6.572625, ' product': -6.6916885}, {' that': -0.029978648, ' known': -4.214431, ' with': -6.4752417, '\\n\\n': -6.8155336, '.': -7.095539}, {' is': -0.026347209, ' has': -5.218273, '\\n\\n': -6.8925867, ' knows': -7.1943464, ' sells': -7.316882}, {' known': -0.013867162, ' know': -6.454337, ' well': -6.936837, ' kn': -7.0051928, '\\n\\n': -7.0291834}, {' for': -0.0063657477, '\\n\\n': -7.0354223, ' to': -7.4385195, ' fo': -7.753499, '.': -7.8789616}, {' its': -0.013735133, ' quality': -6.3430924, '\\n\\n': -6.6007714, ' the': -6.619348, ' it': -7.304754}, {' quality': -0.051652655, ' reputation': -3.4566724, ' product': -6.032781, ' customer': -6.654903, '\\n\\n': -6.7446074}, {' and': -0.017767895, '.': -5.442239, ',': -5.8256044, '\\n\\n': -6.5102997, ' reputation': -6.5173264}, {' reputation': -0.008056559, ' reput': -6.7661552, '\\n\\n': -6.982958, ' rep': -7.2735147, '...\\n\\n': -7.8719864}, {'.': -0.22133245, '.\\n\\n': -1.9167174, '\\n\\n': -5.0398817, '.\\n': -5.1612425, ',': -5.344803}, {' Simpson': -0.30319306, ' The': -3.7772312, '<|endoftext|>': -4.598508, ' It': -4.672122, ' This': -4.821748}, {' better': -0.085143425, ' is': -3.7752564, \"'s\": -4.848224, ' Better': -5.547355, ' has': -5.6487756}, {' is': -0.025203792, ' has': -5.7138634, '\\n\\n': -6.6168413, \"'s\": -6.6592674, ' brand': -7.003166}, {' a': -0.015173406, ' known': -5.5375323, ' an': -6.714295, '\\n\\n': -6.773583, ' the': -6.898453}, {' brand': -0.015582628, '\\n\\n': -6.4794545, ' bran': -6.7531247, ' b': -7.3622165, ' br': -7.491526}, {' that': -0.012762732, ' known': -5.7437835, '\\n\\n': -6.4345, '...\\n\\n': -7.5057683, ' tha': -7.5880303}], 'text_offset': [257, 260, 262, 268, 273, 276, 282, 286, 290, 298, 302, 313, 314, 322, 329, 332, 334, 340, 345, 348, 354, 358, 362, 370, 374, 385, 386, 394, 401, 404, 406, 412, 417, 420, 426, 430, 434, 442, 446, 457, 458, 466, 473, 476, 478, 484, 489, 492, 498, 502, 506, 514, 518, 529, 530, 538, 545, 548, 550, 556]}, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 55, 'completion_tokens': 60, 'total_tokens': 115}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Apply sentiment analysis to each text instance in the dataset\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m merged_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperform_sentiment_analysis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Save the updated dataset with sentiment labels\u001b[39;00m\n\u001b[1;32m     42\u001b[0m merged_dataset\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabeled_Dataset_Sentiment.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py:4897\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4771\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4776\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4777\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4778\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4779\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4780\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4895\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4896\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4898\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4899\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4900\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4902\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4904\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mperform_sentiment_analysis\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     16\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdavinci-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Update with a supported model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel the element of brand perception using one of these labels (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct quality\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreputation & heritage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer service\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial impact\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124methical practices\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msustainability\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m) you can choose more than one based on this text as: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,    \u001b[38;5;66;03m# Include log probabilities for each token\u001b[39;00m\n\u001b[1;32m     22\u001b[0m }\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://api.openai.com/v1/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()  \u001b[38;5;66;03m# Raise exception for HTTP errors\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     response_json \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/urllib3/response.py:1040\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/urllib3/response.py:1184\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1184\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1186\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/urllib3/response.py:1108\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1108\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Set up OpenAI API\n",
    "api_key = \"sk-proj-nzxRWSLF2BlxuIZDtD50T3BlbkFJEbLOkIlSA9KlwIJJuCQz\"  # Set your OpenAI API key. Don't share this key and don't distribute a notebook that contains your key.\n",
    "\n",
    "# Load your dataset\n",
    "merged_dataset = pd.read_csv('Merged_Cleaned_Dataset.csv')\n",
    "\n",
    "# Define function to perform sentiment analysis using OpenAI API\n",
    "def perform_sentiment_analysis(text):\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"davinci-002\",  # Update with a supported model\n",
    "        \"prompt\": f\"Label the element of brand perception using one of these labels ('product quality', 'reputation & heritage', 'customer service', 'social impact', 'ethical practices', and 'sustainability') you can choose more than one based on this text as: '{text}'\",\n",
    "        \"max_tokens\": 60,\n",
    "        \"temperature\": 0,  # Ensure deterministic output\n",
    "        \"logprobs\": 10,    # Include log probabilities for each token\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(\"https://api.openai.com/v1/completions\", json=data, headers=headers)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        response_json = response.json()\n",
    "        print(\"Response JSON:\", response_json)  # Debug print\n",
    "        # Extract sentiment label from the response\n",
    "        sentiment_label = response_json['choices'][0]['text'].strip()\n",
    "        return sentiment_label\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error performing API request:\", e)\n",
    "        return \"Error\"\n",
    "    except (KeyError, IndexError) as e:\n",
    "        print(\"Error processing API response:\", e)\n",
    "        return \"Error\"\n",
    "\n",
    "# Apply sentiment analysis to each text instance in the dataset\n",
    "merged_dataset['sentiment'] = merged_dataset['text'].apply(perform_sentiment_analysis)\n",
    "\n",
    "# Save the updated dataset with sentiment labels\n",
    "merged_dataset.to_csv('Labeled_Dataset_Sentiment.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('Merged_Cleaned_Dataset.csv')\n",
    "\n",
    "# Set your API key\n",
    "openai.api_key = \"sk-proj-nzxRWSLF2BlxuIZDtD50T3BlbkFJEbLOkIlSA9KlwIJJuCQz\"\n",
    "\n",
    "def label_data(text):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            max_tokens = 200,\n",
    "            messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful label assistant. Label the element of brand perception using one of these labels ('product quality', 'reputation & heritage', 'customer service', 'social impact', 'ethical practices', and 'sustainability') you can choose more than one.\"},\n",
    "                        {\"role\": \"user\", \"content\": f\"Label it based on this text as: '{text}'\"},\n",
    "                    ],\n",
    "        )\n",
    "        print(response)\n",
    "        choices = response.choices[0]\n",
    "        text = choices.message.content\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        return None\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "df['label'] = df['text'].apply(label_data)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv('Merged_Cleaned_Dataset_Labeled_API.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23421 entries, 0 to 23420\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    23421 non-null  object\n",
      " 1   label   23421 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 366.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read the CSV file\n",
    "df_label = pd.read_csv('Merged_Cleaned_Dataset_Labeled_API.csv')\n",
    "\n",
    "# Convert all values to strings\n",
    "df_label = df_label.astype(str)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "# df.to_csv('updated_file.csv', index=False)\n",
    "df_label.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>product quality</th>\n",
       "      <th>reputation &amp; heritage</th>\n",
       "      <th>customer service</th>\n",
       "      <th>social impact</th>\n",
       "      <th>ethical practices</th>\n",
       "      <th>sustainability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>yall know stuff yeah shes shopper people basic...</td>\n",
       "      <td>customer service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text             label  \\\n",
       "846  yall know stuff yeah shes shopper people basic...  customer service   \n",
       "\n",
       "     product quality  reputation & heritage  customer service  social impact  \\\n",
       "846                0                      0                 1              0   \n",
       "\n",
       "     ethical practices  sustainability  \n",
       "846                  0               0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create separate fields for each label\n",
    "df_label['product quality'] = 0\n",
    "df_label['reputation & heritage'] = 0\n",
    "df_label['customer service'] = 0\n",
    "df_label['social impact'] = 0\n",
    "df_label['ethical practices'] = 0\n",
    "df_label['sustainability'] = 0\n",
    "\n",
    "# Update the values based on the \"label\" field\n",
    "df_label.loc[df_label['label'].str.contains('product quality'), 'product quality'] = 1\n",
    "df_label.loc[df_label['label'].str.contains('reputation & heritage'), 'reputation & heritage'] = 1\n",
    "df_label.loc[df_label['label'].str.contains('customer service'), 'customer service'] = 1\n",
    "df_label.loc[df_label['label'].str.contains('social impact'), 'social impact'] = 1\n",
    "df_label.loc[df_label['label'].str.contains('ethical practices'), 'ethical practices'] = 1\n",
    "df_label.loc[df_label['label'].str.contains('sustainability'), 'sustainability'] = 1\n",
    "\n",
    "df_label[df_label[\"text\"] == \"yall know stuff yeah shes shopper people basically maid rich people shop gt time use service\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label.to_csv('Labeled_Df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SequenceClassifierOutput' object has no attribute 'pooler_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m input_ids, attention_mask, aspect_labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m aspect_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits  \u001b[38;5;66;03m# Directly use logits from the model output\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/488FinalProject/modules/BrandPerceptionModel.py:17\u001b[0m, in \u001b[0;36mBrandPerceptionModel.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Emotion classification\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     emotion_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memotion_model(input_ids\u001b[38;5;241m=\u001b[39minput_ids, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[0;32m---> 17\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m \u001b[43memotion_outputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpooler_output\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Aspect identification\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     aspect_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maspect_classifier(pooled_output)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SequenceClassifierOutput' object has no attribute 'pooler_output'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from modules.BrandPerceptionModel import BrandPerceptionModel\n",
    "from datasets.brand_perception_dataset import BrandPerceptionDataset\n",
    "\n",
    "# Uploading file:\n",
    "df_label = pd.read_csv('Labeled_Df.csv')\n",
    "\n",
    "# Define your training parameters\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = 2e-5\n",
    "\n",
    "\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "\n",
    "# Define maximum sequence length\n",
    "max_length = 128\n",
    "\n",
    "# Correcting the data preparation for tokenizer input\n",
    "df_label['text'] = df_label['text'].fillna('').astype(str)\n",
    "texts = df_label['text'].tolist()\n",
    "aspect_labels = df_label.loc[:, \"product quality\":\"sustainability\"].values.tolist()\n",
    "\n",
    "# Ensure aspect_labels is correctly formatted as a list of lists\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = BrandPerceptionDataset(texts, aspect_labels, tokenizer, max_length)\n",
    "\n",
    "# Continue with your existing DataLoader and training setup\n",
    "# Define your training parameters\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "learning_rate = 2e-5\n",
    "\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "# Correcting the data preparation for tokenizer input\n",
    "texts = df_label[\"text\"].tolist()  # Convert Series to list of strings\n",
    "\n",
    "# Ensure aspect_labels is correctly formatted as a list of lists\n",
    "aspect_labels = df_label.loc[:, \"product quality\":\"sustainability\"].values.tolist()\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"SamLowe/roberta-base-go_emotions\")\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = BrandPerceptionDataset(texts, aspect_labels, tokenizer, max_length)\n",
    "\n",
    "# Define maximum sequence length\n",
    "max_length = 128\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = BrandPerceptionDataset(texts, aspect_labels, tokenizer, max_length)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define your loss function for aspect identification\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss for multi-label classification\n",
    "\n",
    "model = BrandPerceptionModel()\n",
    "\n",
    "# Define your optimizer\n",
    "optimizer = AdamW(model.aspect_classifier.parameters(), lr=learning_rate)  # Only optimize parameters of aspect identification layer\n",
    "\n",
    "# Define your learning rate scheduler\n",
    "total_steps = len(train_dataloader) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        # Extract input data and labels from batch\n",
    "        input_ids, attention_mask, aspect_labels = batch\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        aspect_logits = outputs.logits  # Directly use logits from the model output\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(aspect_logits, aspect_labels.float())\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping to prevent exploding gradients\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    \n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
