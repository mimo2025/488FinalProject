{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install datasets transformers pandas matplotlib tqdm --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically loads changes in other files in this project\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('validated_labeled_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df['brand_label'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['brand_label', 'Text', 'emotion_label'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_list_of_strings(value):\n",
    "    # Ensure that the input is actually a string\n",
    "    if isinstance(value, str):\n",
    "        # Remove unwanted characters and split\n",
    "        value = value.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    return value\n",
    "\n",
    "# Convert Text to str type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "df['Text'] = df['Text'].str.rstrip(\",\")\n",
    "df.rename(columns={'Text': 'text'}, inplace=True)\n",
    "\n",
    "# Convert brand_label and emotion_label to list of strings\n",
    "df['brand_label'] = df['brand_label'].apply(convert_to_list_of_strings)\n",
    "df['emotion_label'] = df['emotion_label'].apply(convert_to_list_of_strings)\n",
    "\n",
    "# Check the types to verify\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brand_perception_labels_map_to_label = {\n",
    "        0: 'product quality',\n",
    "        1: 'reputation & heritage',\n",
    "        2: 'customer service',\n",
    "        3: 'social impact',\n",
    "        4: 'ethical practices',\n",
    "        5: 'sustainability'\n",
    "    }\n",
    "\n",
    "emotion_labels_map_to_emotion = {0: \"admiration\",\n",
    "    1: \"amusement\",\n",
    "    2: \"anger\",\n",
    "    3: \"annoyance\",\n",
    "    4: \"approval\",\n",
    "    5: \"caring\",\n",
    "    6: \"confusion\",\n",
    "    7: \"curiosity\",\n",
    "    8: \"desire\",\n",
    "    9: \"disappointment\",\n",
    "    10: \"disapproval\",\n",
    "    11: \"disgust\",\n",
    "    12: \"embarrassment\",\n",
    "    13: \"excitement\",\n",
    "    14: \"fear\",\n",
    "    15: \"gratitude\",\n",
    "    16: \"grief\",\n",
    "    17: \"joy\",\n",
    "    18: \"love\",\n",
    "    19: \"nervousness\",\n",
    "    20: \"optimism\",\n",
    "    21: \"pride\",\n",
    "    22: \"realization\",\n",
    "    23: \"relief\",\n",
    "    24: \"remorse\",\n",
    "    25: \"sadness\",\n",
    "    26: \"surprise\",\n",
    "    27: \"neutral\"}\n",
    "\n",
    "brand_perception_labels_map_to_index = {\n",
    "        'product quality': 0,\n",
    "        'reputation & heritage': 1,\n",
    "        'customer service': 2,\n",
    "        'social impact': 3,\n",
    "        'ethical practices': 4,\n",
    "        'sustainability': 5\n",
    "    }\n",
    "\n",
    "emotion_labels_map_to_index = {\n",
    "    \"admiration\": 0,\n",
    "    \"amusement\": 1,\n",
    "    \"anger\": 2,\n",
    "    \"annoyance\": 3,\n",
    "    \"approval\": 4,\n",
    "    \"caring\": 5,\n",
    "    \"confusion\": 6,\n",
    "    \"curiosity\": 7,\n",
    "    \"desire\": 8,\n",
    "    \"disappointment\": 9,\n",
    "    \"disapproval\": 10,\n",
    "    \"disgust\": 11,\n",
    "    \"embarrassment\": 12,\n",
    "    \"excitement\": 13,\n",
    "    \"fear\": 14,\n",
    "    \"gratitude\": 15,\n",
    "    \"grief\": 16,\n",
    "    \"joy\": 17,\n",
    "    \"love\": 18,\n",
    "    \"nervousness\": 19,\n",
    "    \"optimism\": 20,\n",
    "    \"pride\": 21,\n",
    "    \"realization\": 22,\n",
    "    \"relief\": 23,\n",
    "    \"remorse\": 24,\n",
    "    \"sadness\": 25,\n",
    "    \"surprise\": 26,\n",
    "    \"neutral\": 27\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get text from df and put in a list of strings\n",
    "texts = [item for item in df['text'] if isinstance(item, str) and item.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of hot encoded values for brand aspects \n",
    "def hot_encode_brand_perception(row):\n",
    "    result = np.zeros(6)\n",
    "    for label in row['brand_label']:  # iterate through the list of labels in each row\n",
    "        if label in brand_perception_labels_map_to_index:\n",
    "            result[brand_perception_labels_map_to_index[label]] = 1\n",
    "    return result\n",
    "\n",
    "# Apply the function to each row\n",
    "brand_labels = df.apply(hot_encode_brand_perception, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming emotion_labels_map is defined\n",
    "random_emotions = []\n",
    "for emotion_list in df['emotion_label']:\n",
    "    for emotion in emotion_list:\n",
    "        if emotion not in emotion_labels_map_to_index:\n",
    "            random_emotions.append(emotion)\n",
    "random_emotion_dict = {}\n",
    "for emotion in random_emotions:\n",
    "    if emotion in random_emotion_dict:\n",
    "        random_emotion_dict[emotion] += 1\n",
    "    else:\n",
    "        random_emotion_dict[emotion] = 1\n",
    "print(random_emotion_dict)\n",
    "    \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Create the mapping\n",
    "incorrect_to_correct = {\n",
    "    \"horrible\": [\"disgust\", \"sadness\"],\n",
    "    \"love\": [\"admiration\", \"joy\"],\n",
    "    \"neutral\": [\"neutral\"],\n",
    "    \"bad\": [\"annoyance\", \"disapproval\"],\n",
    "    \"hate\": [\"anger\", \"disgust\"],\n",
    "    \"excited\": [\"excitement\"],\n",
    "    \"worse\": [\"disappointment\"],\n",
    "    \"disappointed\": [\"disappointment\"],\n",
    "    \"great\": [\"joy\", \"admiration\"],\n",
    "    \"amazing\": [\"joy\", \"admiration\"],\n",
    "    \"impressed\": [\"admiration\"],\n",
    "    \"thrilled\": [\"joy\", \"excitement\"],\n",
    "    \"terrible\": [\"disgust\", \"sadness\"],\n",
    "    \"amused\": [\"amusement\"],\n",
    "    \"curious\": [\"curiosity\"],\n",
    "    \"worst\": [\"disgust\", \"sadness\"],\n",
    "    \"good\": [\"approval\", \"joy\"],\n",
    "    \"regret\": [\"remorse\"],\n",
    "    \"need\": [\"desire\"],\n",
    "    \"trust\": [\"admiration\"],\n",
    "    \"inspired\": [\"admiration\", \"joy\"],\n",
    "    \"amazed\": [\"surprise\", \"admiration\"],\n",
    "    \"confused\": [\"confusion\"],\n",
    "    \"happy\": [\"joy\"],\n",
    "    \"better\": [\"approval\", \"optimism\"]\n",
    "}\n",
    "\n",
    "# Step 2: Write a function to process the column\n",
    "def map_emotions(emotion_labels):\n",
    "    return [synonym for emotion in emotion_labels for synonym in incorrect_to_correct.get(emotion, [emotion])]\n",
    "\n",
    "# Step 3: Apply the function to the DataFrame\n",
    "df['emotion_label'] = df['emotion_label'].apply(map_emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hot_encode_emotions(row):\n",
    "    result = np.zeros(28)\n",
    "    for label in row['emotion_label']:  # iterate through the list of labels in each row\n",
    "        if label in emotion_labels_map_to_index:\n",
    "            result[emotion_labels_map_to_index[label]] = 1\n",
    "    return result\n",
    "\n",
    "# Apply the function to each row\n",
    "emotion_labels = df.apply(hot_encode_emotions, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df['emotion_label'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming emotion_labels_map is defined\n",
    "random_emotions = []\n",
    "for emotion_list in df['emotion_label']:\n",
    "    for emotion in emotion_list:\n",
    "        if emotion not in emotion_labels_map_to_index:\n",
    "            random_emotions.append(emotion)\n",
    "random_emotion_dict = {}\n",
    "for emotion in random_emotions:\n",
    "    if emotion in random_emotion_dict:\n",
    "        random_emotion_dict[emotion] += 1\n",
    "    else:\n",
    "        random_emotion_dict[emotion] = 1\n",
    "print(random_emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into validation, test, and train splits\n",
    "\n",
    "# First, split into train and temp (either test or validation)\n",
    "texts_train, texts_temp, emotions_train, emotions_temp, brands_train, brands_temp = train_test_split(\n",
    "    texts, emotion_labels, brand_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split the temp data into validation and test sets\n",
    "texts_val, texts_test, emotions_val, emotions_test, brands_val, brands_test = train_test_split(\n",
    "    texts_temp, emotions_temp, brands_temp, test_size=0.5, random_state=42)  # This splits the remaining 20% into two 10% segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CODE I RAN ORIGINALLY BUT DONT RUN IT AGAIN BC I SAVED THE VARIABLES IN A FILE, \n",
    "# I JUST LEFT IT HERE TO DEMONSTRATE WHAT I DID - WE CAN TAKE IT OUT IF NEED BE\n",
    "#from datasetss.brand_perception_dataset import BrandPerceptionDataset\n",
    "\n",
    "#train_dataset = BrandPerceptionDataset(texts_train, emotions_train, brands_train)\n",
    "#val_dataset = BrandPerceptionDataset(texts_val, emotions_val, brands_val)\n",
    "#test_dataset = BrandPerceptionDataset(texts_test, emotions_test, brands_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading datasets \n",
    "import pickle\n",
    "with open('datasetss/train_dataset.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open('datasetss/val_dataset.pkl', 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "\n",
    "with open('datasetss/test_dataset.pkl', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from modules.BrandPerceptionModel import BrandPerceptionModel\n",
    "config = {\n",
    "    'model_name': 'SamLowe/roberta-base-go_emotions',\n",
    "    'n_labels_bp': 6,\n",
    "    'batch_size': 16,\n",
    "    'lr': 1.5e-5,\n",
    "    'warmup': 0.2, \n",
    "    'train_size': len(train_loader),\n",
    "    'weight_decay': 0.001,\n",
    "    'n_epochs': 10\n",
    "}\n",
    "print(\"Config:\", config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # CODE I RAN ORIGINALLY BUT DONT RUN IT AGAIN BC I SAVED THE VARIABLES IN A FILE, \n",
    "# I JUST LEFT IT HERE TO DEMONSTRATE WHAT I DID - WE CAN TAKE IT OUT IF NEED BE\n",
    "#import pytorch_lightning as pl\n",
    "#trainer = pl.Trainer(max_epochs=config['n_epochs'], num_sanity_val_steps=5, accelerator='gpu')\n",
    "# VALIDATION TOOK PLACE HERE:\n",
    "#trainer.fit(model, train_loader, val_loader)\n",
    "#trainer.save_checkpoint(\"models/brand_perception_model_checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = BrandPerceptionModel.load_from_checkpoint(\"models/brand_perception_model_checkpoint.ckpt\", config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(max_epochs=config['n_epochs'], accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainer.test(model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data (data for one specifc brand: Amiri)\n",
    "amiri_df = pd.read_csv('filtered_amiri_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct data set and loader\n",
    "from datasetss.brand_perception_dataset import BrandPerceptionDataset\n",
    "amiri_texts = [item for item in amiri_df['text'] if isinstance(item, str) and item.strip() != '']\n",
    "amiri_dataset = BrandPerceptionDataset(amiri_texts)\n",
    "amiri_loader = DataLoader(amiri_dataset, batch_size=4, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CODE I RAN ORIGINALLY BUT DONT RUN IT AGAIN BC IT REQUIRES A GPU AND WILL TAKE TOO LONG, \n",
    "# I JUST LEFT IT HERE TO DEMONSTRATE WHAT I DID - WE CAN TAKE IT OUT IF NEED BE\n",
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "# Determine device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = GradScaler()\n",
    "\n",
    "all_emotion_probs = []\n",
    "all_brand_probs = []\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)\n",
    "\n",
    "def checkpointed_predict_step(batch):\n",
    "    def forward_func(input_ids, attention_mask):\n",
    "        return model(input_ids, attention_mask)\n",
    "    return checkpoint.checkpoint(forward_func, batch['input_ids'], batch['attention_mask'])\n",
    "\n",
    "for batch_idx, batch in enumerate(amiri_loader):\n",
    "    batch = {\n",
    "        \"input_ids\": batch['input_ids'].to(device),\n",
    "        \"attention_mask\": batch['attention_mask'].to(device),\n",
    "        \"labels_emotion\": batch['labels_emotion'].to(device),\n",
    "        \"labels_brand\": batch['labels_brand'].to(device),\n",
    "    }\n",
    "\n",
    "    with autocast():\n",
    "        # Use checkpointing to manage memory\n",
    "        loss, emotion_probs, brand_probs = checkpointed_predict_step(batch)\n",
    "\n",
    "    emotion_probs = emotion_probs.cpu()\n",
    "    brand_probs = brand_probs.cpu()\n",
    "\n",
    "    all_emotion_probs.append(emotion_probs)\n",
    "    all_brand_probs.append(brand_probs)\n",
    "\n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Clear variables\n",
    "    del batch, loss, emotion_probs, brand_probs\n",
    "\n",
    "# Concatenate all probabilities for final results\n",
    "all_emotion_probs = torch.cat(all_emotion_probs, dim=0)\n",
    "all_brand_probs = torch.cat(all_brand_probs, dim=0)\n",
    "\n",
    "# Display final results\n",
    "print(f\"Emotion probabilities shape: {all_emotion_probs.shape}\")\n",
    "print(f\"Brand probabilities shape: {all_brand_probs.shape}\")\n",
    "\n",
    "# Print memory summary\n",
    "print(torch.cuda.memory_summary(device=device, abbreviated=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # CODE I RAN ORIGINALLY BUT DONT RUN IT AGAIN BC I SAVED THE VARIABLES IN A FILE, \n",
    "# I JUST LEFT IT HERE TO DEMONSTRATE WHAT I DID - WE CAN TAKE IT OUT IF NEED BE\n",
    "with open(\"probs.pkl\", \"wb\") as f:\n",
    "    pickle.dump((all_emotion_probs, all_brand_probs), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the results for Amiri\n",
    "with open(\"probs.pkl\", \"rb\") as f:\n",
    "    all_emotion_probs, all_brand_probs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Apply sigmoid to convert logits to probabilities\n",
    "all_emotion_probs = F.sigmoid(all_emotion_probs)\n",
    "all_brand_perception_probs = F.sigmoid(all_brand_probs)\n",
    "\n",
    "# Calculate the average probabilities for each emotion\n",
    "avg_emotion_probs = all_emotion_probs.mean(dim=0)\n",
    "avg_brand_perception_probs = all_brand_perception_probs.mean(dim=0)\n",
    "\n",
    "print(f\"Average Emotion Probabilities: {avg_emotion_probs}\")\n",
    "print(f\"Average Brand Perception Probabilities: {avg_brand_perception_probs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to map dimensions of tensor to labels\n",
    "def map_to_labels(tensor, labels_map):\n",
    "    labels = []\n",
    "    for i, value in enumerate(tensor):\n",
    "        label = labels_map.get(i, \"Unknown\")\n",
    "        labels.append((label, value.item()))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map indices to labels for brand perception tensor\n",
    "amiri_brand_perception_labels = map_to_labels(avg_brand_perception_probs, brand_perception_labels_map_to_label)\n",
    "print(\"Brand Perception:\")\n",
    "for label, value in amiri_brand_perception_labels:\n",
    "    print(f\"{label}: {value}\")\n",
    "\n",
    "# Map indices to labels for emotion tensor\n",
    "amiri_emotion_labels = map_to_labels(avg_emotion_probs, emotion_labels_map_to_emotion)\n",
    "print(\"\\nEmotion:\")\n",
    "for label, value in amiri_emotion_labels:\n",
    "    print(f\"{label}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
