{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install datasets transformers pandas matplotlib tqdm --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically loads changes in other files in this project\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('../Merged_Cleaned_Dataset_Labeled_API.csv.csv')\n",
    "data = [\n",
    "    {\n",
    "        \"text\": \"love the new collection amazing craftsmanship and attention to detail\",\n",
    "        \"brand_labels\": [\"product quality\", \"reputation & heritage\"],\n",
    "        \"emotion_labels\": [\"love\", \"admiration\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"horrible customer service never shopping there again\",\n",
    "        \"brand_labels\": [\"customer service\"],\n",
    "        \"emotion_labels\": [\"disgust\", \"disapproval\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"thrilled with the ecofriendly initiatives\",\n",
    "        \"brand_labels\": [\"sustainability\"],\n",
    "        \"emotion_labels\": [\"excitement\", \"optimism\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"very disappointed in the quality for the price paid\",\n",
    "        \"brand_labels\": [\"product quality\"],\n",
    "        \"emotion_labels\": [\"disappointment\"]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"impressed by the brand's commitment to ethical practices\",\n",
    "        \"brand_labels\": [\"ethical practices\"],\n",
    "        \"emotion_labels\": [\"approval\", \"pride\"]\n",
    "    }\n",
    "]\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Delete later\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: [x] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "# Delete later\n",
    "df['label'] = df['label'].apply(lambda x: [x] if not isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>brand_labels</th>\n",
       "      <th>emotion_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love the new collection amazing craftsmanship ...</td>\n",
       "      <td>[product quality, reputation &amp; heritage]</td>\n",
       "      <td>[love, admiration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horrible customer service never shopping there...</td>\n",
       "      <td>[customer service]</td>\n",
       "      <td>[disgust, disapproval]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thrilled with the ecofriendly initiatives</td>\n",
       "      <td>[sustainability]</td>\n",
       "      <td>[excitement, optimism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very disappointed in the quality for the price...</td>\n",
       "      <td>[product quality]</td>\n",
       "      <td>[disappointment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>impressed by the brand's commitment to ethical...</td>\n",
       "      <td>[ethical practices]</td>\n",
       "      <td>[approval, pride]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  love the new collection amazing craftsmanship ...   \n",
       "1  horrible customer service never shopping there...   \n",
       "2          thrilled with the ecofriendly initiatives   \n",
       "3  very disappointed in the quality for the price...   \n",
       "4  impressed by the brand's commitment to ethical...   \n",
       "\n",
       "                               brand_labels          emotion_labels  \n",
       "0  [product quality, reputation & heritage]      [love, admiration]  \n",
       "1                        [customer service]  [disgust, disapproval]  \n",
       "2                          [sustainability]  [excitement, optimism]  \n",
       "3                         [product quality]        [disappointment]  \n",
       "4                       [ethical practices]       [approval, pride]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_perception_labels_map = {\n",
    "        0: 'product quality',\n",
    "        1: 'reputation & heritage',\n",
    "        2: 'customer service',\n",
    "        3: 'social impact',\n",
    "        4: 'ethical practices',\n",
    "        5: 'sustainability'\n",
    "    }\n",
    "\n",
    "emotion_labels_map = {0: \"admiration\",\n",
    "    1: \"amusement\",\n",
    "    2: \"anger\",\n",
    "    3: \"annoyance\",\n",
    "    4: \"approval\",\n",
    "    5: \"caring\",\n",
    "    6: \"confusion\",\n",
    "    7: \"curiosity\",\n",
    "    8: \"desire\",\n",
    "    9: \"disappointment\",\n",
    "    10: \"disapproval\",\n",
    "    11: \"disgust\",\n",
    "    12: \"embarrassment\",\n",
    "    13: \"excitement\",\n",
    "    14: \"fear\",\n",
    "    15: \"gratitude\",\n",
    "    16: \"grief\",\n",
    "    17: \"joy\",\n",
    "    18: \"love\",\n",
    "    19: \"nervousness\",\n",
    "    20: \"optimism\",\n",
    "    21: \"pride\",\n",
    "    22: \"realization\",\n",
    "    23: \"relief\",\n",
    "    24: \"remorse\",\n",
    "    25: \"sadness\",\n",
    "    26: \"surprise\",\n",
    "    27: \"neutral\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text from df and put in a list of strings\n",
    "texts = [item for item in df['text'] if isinstance(item, str) and item.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of hot encoded values for brand aspects \n",
    "def hot_encode_brand_perception(row):\n",
    "    labels_map = {\n",
    "        'product quality': 0,\n",
    "        'reputation & heritage': 1,\n",
    "        'customer service': 2,\n",
    "        'social impact': 3,\n",
    "        'ethical practices': 4,\n",
    "        'sustainability': 5\n",
    "    }\n",
    "    result = np.zeros(6)\n",
    "    for label in row['brand_labels']:  # iterate through the list of labels in each row\n",
    "        if label in labels_map:\n",
    "            result[labels_map[label]] = 1\n",
    "    return result\n",
    "\n",
    "# Apply the function to each row\n",
    "brand_labels = df.apply(hot_encode_brand_perception, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_encode_emotions(row):\n",
    "    labels_map = {\n",
    "    \"admiration\": 0,\n",
    "    \"amusement\": 1,\n",
    "    \"anger\": 2,\n",
    "    \"annoyance\": 3,\n",
    "    \"approval\": 4,\n",
    "    \"caring\": 5,\n",
    "    \"confusion\": 6,\n",
    "    \"curiosity\": 7,\n",
    "    \"desire\": 8,\n",
    "    \"disappointment\": 9,\n",
    "    \"disapproval\": 10,\n",
    "    \"disgust\": 11,\n",
    "    \"embarrassment\": 12,\n",
    "    \"excitement\": 13,\n",
    "    \"fear\": 14,\n",
    "    \"gratitude\": 15,\n",
    "    \"grief\": 16,\n",
    "    \"joy\": 17,\n",
    "    \"love\": 18,\n",
    "    \"nervousness\": 19,\n",
    "    \"optimism\": 20,\n",
    "    \"pride\": 21,\n",
    "    \"realization\": 22,\n",
    "    \"relief\": 23,\n",
    "    \"remorse\": 24,\n",
    "    \"sadness\": 25,\n",
    "    \"surprise\": 26,\n",
    "    \"neutral\": 27\n",
    "}\n",
    "\n",
    "    result = np.zeros(28)\n",
    "    for label in row['emotion_labels']:  # iterate through the list of labels in each row\n",
    "        if label in labels_map:\n",
    "            result[labels_map[label]] = 1\n",
    "    return result\n",
    "\n",
    "# Apply the function to each row\n",
    "emotion_labels = df.apply(hot_encode_emotions, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emotion_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into validation, test, and train splits\n",
    "\n",
    "# First, split into train and temp (either test or validation) (change back to 0.2)\n",
    "texts_train, texts_temp, emotions_train, emotions_temp, brands_train, brands_temp = train_test_split(\n",
    "    texts, emotion_labels, brand_labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Then, split the temp data into validation and test sets\n",
    "texts_val, texts_test, emotions_val, emotions_test, brands_val, brands_test = train_test_split(\n",
    "    texts_temp, emotions_temp, brands_temp, test_size=0.5, random_state=42)  # This splits the remaining 20% into two 10% segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetss.brand_perception_dataset import BrandPerceptionDataset\n",
    "\n",
    "train_dataset = BrandPerceptionDataset(texts_train, emotions_train, brands_train)\n",
    "val_dataset = BrandPerceptionDataset(texts_val, emotions_val, brands_val)\n",
    "test_dataset = BrandPerceptionDataset(texts_test, emotions_test, brands_test)\n",
    "\n",
    "# Example usage with DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHANGE EPOCHS BACK TO 100\n",
    "from modules.BrandPerceptionModel import BrandPerceptionModel\n",
    "config = {\n",
    "    'model_name': 'SamLowe/roberta-base-go_emotions',\n",
    "    'n_labels_bp': 6,\n",
    "    'batch_size': 128,\n",
    "    'lr': 1.5e-6,\n",
    "    'warmup': 0.2, \n",
    "    'train_size': len(train_loader),\n",
    "    'weight_decay': 0.001,\n",
    "    'n_epochs': 10\n",
    "}\n",
    "print(\"Config:\", config)\n",
    "model = BrandPerceptionModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(max_epochs=config['n_epochs'], num_sanity_val_steps=5)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions():\n",
    "    # Assuming your model is already initialized and loaded with trained weights\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Iterate through your validation or test dataset\n",
    "    predictions = []\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for batch in val_loader:  # Assuming val_loader is your validation data loader\n",
    "            # Forward pass\n",
    "            outputs = model.predict_step(batch)\n",
    "\n",
    "            # Post-processing if needed\n",
    "            emotion_logits = outputs[\"emotion_logits\"]\n",
    "            brand_logits = outputs[\"brand_logits\"]\n",
    "            \n",
    "            # Example post-processing: convert logits to probabilities\n",
    "            emotion_probs = torch.softmax(emotion_logits, dim=1)\n",
    "            brand_probs = torch.softmax(brand_logits, dim=1)\n",
    "            \n",
    "            # Append the predictions\n",
    "            predictions.append((emotion_probs, brand_probs))\n",
    "        return predictions\n",
    "\n",
    "    # Now predictions contain the predicted probabilities for each batch\n",
    "    # You can further process these predictions as needed for your task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do for a specfic brand\n",
    "# initialize dataset\n",
    "# initialize loader \n",
    "amiri_dataset = BrandPerceptionDataset()\n",
    "amiri_loader = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only do for a specifc brand\n",
    "# Initialize sum_tensor\n",
    "\n",
    "emotion_tensors = predictions[0]\n",
    "brand_perception_tensors = predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg(tensors):\n",
    "    sum_tensor = np.zeros_like(predictions[0])\n",
    "    for tensor in tensors:\n",
    "        sum_tensor += tensor\n",
    "    return sum_tensor / len(tensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregated result across all \n",
    "avg_amiri_emotion = avg(emotion_tensors)\n",
    "avg_amiri_brand_perception = avg(brand_perception_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map indices to labels\n",
    "def map_to_labels(tensor, labels_map):\n",
    "    labels = []\n",
    "    for i, value in enumerate(tensor[0]):\n",
    "        label = labels_map[i] if i in labels_map else \"Unknown\"\n",
    "        labels.append((label, value))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map indices to labels for tensor 1\n",
    "labels_tensor1 = map_to_labels(avg_amiri_brand_perception, brand_perception_labels_map)\n",
    "print(\"Tensor 1:\")\n",
    "for label, value in labels_tensor1:\n",
    "    print(f\"{label}: {value}\")\n",
    "\n",
    "# Map indices to labels for tensor 2\n",
    "labels_tensor2 = map_to_labels(avg_amiri_emotion, emotion_labels_map)\n",
    "print(\"\\nTensor 2:\")\n",
    "for label, value in labels_tensor2:\n",
    "    print(f\"{label}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_proj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
