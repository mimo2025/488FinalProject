{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**BUSI/COMP488-001 Data Science in the Business World.**\n",
    "###**Multi-Label Classification of Luxury Brand Perceptions on TikTok.**\n",
    "###**Team Name:** Team D.\n",
    "###**Team Members:** Carley Wiley, Eldar Utiushev, Bek Tukhtasinov, Mira Mohan, Aryonna Rice, and Tammy Duong.\n",
    "\n",
    "This notebook explores a multi-label classification problem for luxury fashion brands based on TikTok comments and captions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###**Exposition**\n",
    "**1. Focused Stakeholder:** Luxury Fashion Brands. Our model specifically analyzes the real-time public sentiment towards the following luxury clothing brands: The Row, Courrèges, Khaite, Chrome Hearts, Alaïa, Bottega Veneta, Versace, Balenciaga, Gucci, Chanel, Louis Vuitton, Saint Laurent, Christian Dior, Cartier, Celine, Burberry, Rick Owens, Givenchy, Hermès, Fendi, Prada, Valentino, and Armani.\n",
    "\n",
    "**2. Our Question:** How can we leverage web scraping and social media analytics to identify real-time shifts in public sentiment toward designer fashion brands, enabling proactive reputation management and strategic marketing decisions?\n",
    "\n",
    "**3. Data We Used to Answer our Question:**\n",
    "We scraped textual data, using Apify's Tik Tok scrapers, such as hashtags and comments that mention different luxury brands so that we could then use our synthetic expert to perform a sentiment analysis on each brands in terms of the six pillars of brand perception that we defined at the start of our Data Science Pipeline process.\n",
    "\n",
    "**4. Approach and Methods**:\n",
    "- Data Cleaning and Preprocessing:\n",
    "  \n",
    "  - **Initial Setup and Data Loading:** Data is initially loaded from social media platforms and news sources, specifically focusing on comments that provide insights into brand perception. This data is processed using Python libraries such as Pandas for data manipulation. Necessary libraries for language detection and natural language processing, such as NLTK and LangDetect, are installed. Resources like stop words, tokenizers, and lemmatizers from NLTK are also downloaded to assist in text processing.\n",
    "\n",
    "  - **Text Preprocessing:** Text data undergoes several cleaning steps:\n",
    "    - URLs are removed to ensure the text reflects only content related to brand sentiment\n",
    "    - Special characters and punctuation are stripped to simplify the text and focus on meaningful words.\n",
    "    - Text is converted to lowercase to standardize the data and facilitate comparison and analysis.\n",
    "    - Non-English comments are filtered out to maintain consistency in language for sentiment analysis.\n",
    "    - Stop words are removed, and text is tokenized to focus on significant words that contribute to sentiment analysis.\n",
    "\n",
    "- Sentiment Analysis Model Training:\n",
    "\n",
    "  - **Data Preparation:** The cleaned data is split into training, validation, and testing sets using sklearn's train_test_split function. This step ensures the model is tested on unseen data, validating its predictive power.\n",
    "  - **Model Training:** A sentiment analysis model is trained using the OpenAI API, which utilizes large-scale language models to predict sentiment based on text input. The model is fine-tuned to classify sentiment into specific categories relevant to brand perception, such as product quality, customer service, and sustainability.\n",
    "  - **Error Handling and Model Deployment:** The integration with OpenAI's API includes handling potential errors like rate limits and ensuring the model can continuously classify new input by implementing retries and backoff strategies. Predictions from the model are used to assign labels to each text entry, indicating the sentiment towards various aspects of brand perception.\n",
    "\n",
    "- Implementation and Evaluation:\n",
    "\n",
    "  - **Continuous Learning:** The model is designed to update its learning as new data becomes available, ensuring that the sentiment analysis remains relevant over time and reflects current consumer opinions. Regular evaluations are conducted to compare predicted sentiments against actual brand outcomes, allowing adjustments to the model as necessary.\n",
    "  - **Compliance and Ethical Considerations:** The project adheres to privacy laws and data usage policies, ensuring that data collection and analysis respect user privacy and data integrity. Steps are taken to validate data sources and ensure the accuracy and reliability of the information used for training and predictions.\n",
    "\n",
    "**5. Actionable Implications to Luxury Fashion Designers (i.e., how it serves their purpose):**\n",
    "\n",
    "*5.1. Implications.*\n",
    "\n",
    "- We provide brands with detailed insights on public sentiment across multiple dimensions of brand perception, enabling them to tailor their marketing strategies, product development, and customer engagement to better align with current public sentiments.\n",
    "- Our model offers predictive insights based on sentiment trends, aiding brands in anticipating potential shifts in public perception and adjusting their strategies proactively.\n",
    "\n",
    "*5.2. Risks and Mitigations.*\n",
    "\n",
    "As with any new development plan, these decisions come with certain risks:\n",
    "1. **Data Accuracy and Reliability**: We ensure that the data collected is from credible sources and employ robust data validation techniques to maintain accuracy.\n",
    "2. **Privacy and Compliance**: We adhere to data privacy laws and social platform policies during data collection and analysis, ensuring ethical data usage.\n",
    "3. **Rapid Response Requirement**: We prepare brands for quick response strategies as real-time data might indicate the need for swift action to manage emerging brand perception issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install datasets transformers pandas matplotlib tqdm --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically loads changes in other files in this project\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Necessary Libraries.\n",
    "\n",
    "First, we need to import various Python libraries that will help us manipulate data, perform computations, and model our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aryonnarice/488FinalProject\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryonnarice/488FinalProject/final_proj_env/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/aryonnarice/488FinalProject'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to project root\n",
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Loading and Exploration.\n",
    "\n",
    "Next, we will load the dataset containing TikTok comments and captions. This data will be used to train our model to classify brand perceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/validated_labeled_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>brand_label</th>\n",
       "      <th>emotion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opium founding father,</td>\n",
       "      <td>['reputation &amp; heritage']</td>\n",
       "      <td>['horrible']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yall trippin fit clean,</td>\n",
       "      <td>['product quality']</td>\n",
       "      <td>['love']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>might destroy lonely,</td>\n",
       "      <td>['reputation &amp; heritage']</td>\n",
       "      <td>['horrible']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alr show us women,</td>\n",
       "      <td>['reputation &amp; heritage']</td>\n",
       "      <td>['neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad think jeans ripped pull bad,</td>\n",
       "      <td>['product quality']</td>\n",
       "      <td>['bad']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Text                brand_label emotion_label\n",
       "0            opium founding father,  ['reputation & heritage']  ['horrible']\n",
       "1           yall trippin fit clean,        ['product quality']      ['love']\n",
       "2             might destroy lonely,  ['reputation & heritage']  ['horrible']\n",
       "3                alr show us women,  ['reputation & heritage']   ['neutral']\n",
       "4  bad think jeans ripped pull bad,        ['product quality']       ['bad']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Fixing Data Format.\n",
    "\n",
    "We saw that the items in df are not list of strings. They need to be so we must fix the formatting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Text           500 non-null    object\n",
      " 1   brand_label    500 non-null    object\n",
      " 2   emotion_label  500 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with any NaN values\n",
    "df = df.dropna(subset=['brand_label', 'Text', 'emotion_label'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text             object\n",
      "brand_label      object\n",
      "emotion_label    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function that converts the values in the brand_label and emotion_label columns to lists of strings\n",
    "def convert_to_list_of_strings(value):\n",
    "    # Ensure that the input is actually a string\n",
    "    if isinstance(value, str):\n",
    "        # Remove unwanted characters and split\n",
    "        value = value.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    return value\n",
    "\n",
    "# Convert Text to str type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "df['Text'] = df['Text'].str.rstrip(\",\")\n",
    "df.rename(columns={'Text': 'text'}, inplace=True)\n",
    "\n",
    "# Convert brand_label and emotion_label to list of strings\n",
    "df['brand_label'] = df['brand_label'].apply(convert_to_list_of_strings)\n",
    "df['emotion_label'] = df['emotion_label'].apply(convert_to_list_of_strings)\n",
    "\n",
    "# Check the types to verify\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Summary of the Data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic exploration\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing. \n",
    "\n",
    "The data cleaning and preprocessing step is essential for ensuring the quality and consistency of our analysis. We handle missing values, and outliers, and ensure that the data types are correct for each column. This step sets the stage for accurate and reliable insights. We'll remove URLs, and special characters, convert text to lowercase, and remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a mapping for the brand perception labels and emotion labels\n",
    "brand_perception_labels_map_to_label = {\n",
    "        0: 'product quality',\n",
    "        1: 'reputation & heritage',\n",
    "        2: 'customer service',\n",
    "        3: 'social impact',\n",
    "        4: 'ethical practices',\n",
    "        5: 'sustainability'\n",
    "    }\n",
    "\n",
    "emotion_labels_map_to_emotion = {0: \"admiration\",\n",
    "    1: \"amusement\",\n",
    "    2: \"anger\",\n",
    "    3: \"annoyance\",\n",
    "    4: \"approval\",\n",
    "    5: \"caring\",\n",
    "    6: \"confusion\",\n",
    "    7: \"curiosity\",\n",
    "    8: \"desire\",\n",
    "    9: \"disappointment\",\n",
    "    10: \"disapproval\",\n",
    "    11: \"disgust\",\n",
    "    12: \"embarrassment\",\n",
    "    13: \"excitement\",\n",
    "    14: \"fear\",\n",
    "    15: \"gratitude\",\n",
    "    16: \"grief\",\n",
    "    17: \"joy\",\n",
    "    18: \"love\",\n",
    "    19: \"nervousness\",\n",
    "    20: \"optimism\",\n",
    "    21: \"pride\",\n",
    "    22: \"realization\",\n",
    "    23: \"relief\",\n",
    "    24: \"remorse\",\n",
    "    25: \"sadness\",\n",
    "    26: \"surprise\",\n",
    "    27: \"neutral\"}\n",
    "\n",
    "brand_perception_labels_map_to_index = {\n",
    "        'product quality': 0,\n",
    "        'reputation & heritage': 1,\n",
    "        'customer service': 2,\n",
    "        'social impact': 3,\n",
    "        'ethical practices': 4,\n",
    "        'sustainability': 5\n",
    "    }\n",
    "\n",
    "emotion_labels_map_to_index = {\n",
    "    \"admiration\": 0,\n",
    "    \"amusement\": 1,\n",
    "    \"anger\": 2,\n",
    "    \"annoyance\": 3,\n",
    "    \"approval\": 4,\n",
    "    \"caring\": 5,\n",
    "    \"confusion\": 6,\n",
    "    \"curiosity\": 7,\n",
    "    \"desire\": 8,\n",
    "    \"disappointment\": 9,\n",
    "    \"disapproval\": 10,\n",
    "    \"disgust\": 11,\n",
    "    \"embarrassment\": 12,\n",
    "    \"excitement\": 13,\n",
    "    \"fear\": 14,\n",
    "    \"gratitude\": 15,\n",
    "    \"grief\": 16,\n",
    "    \"joy\": 17,\n",
    "    \"love\": 18,\n",
    "    \"nervousness\": 19,\n",
    "    \"optimism\": 20,\n",
    "    \"pride\": 21,\n",
    "    \"realization\": 22,\n",
    "    \"relief\": 23,\n",
    "    \"remorse\": 24,\n",
    "    \"sadness\": 25,\n",
    "    \"surprise\": 26,\n",
    "    \"neutral\": 27\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Create Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn the text column of df to a list of strings to be inserted into the model\n",
    "texts = [item for item in df['text'] if isinstance(item, str) and item.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of hot encoded values for brand aspects (1: aspect found in text, else 0)\n",
    "def hot_encode_brand_perception(row):\n",
    "    result = np.zeros(6)\n",
    "    for label in row['brand_label']:  # iterate through the list of labels in each row\n",
    "        if label in brand_perception_labels_map_to_index:\n",
    "            result[brand_perception_labels_map_to_index[label]] = 1\n",
    "    return result\n",
    "\n",
    "# Apply the function to each row\n",
    "brand_labels = df.apply(hot_encode_brand_perception, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Fixing Labeled Data.\n",
    "\n",
    "Some of the labeled data used emotions that were not of the 28 the pre-trained model was trained to identify. Hence, these values need to be changed to words that are included in the go_emotions dataset but that also closely match the definition of the original word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'horrible': 30, 'bad': 29, 'hate': 36, 'excited': 75, 'worse': 18, 'disappointed': 98, 'great': 21, 'amazing': 19, 'impressed': 16, 'thrilled': 16, 'terrible': 16, 'amused': 3, 'curious': 1, 'worst': 1, 'good': 5, 'regret': 1, 'need': 1, 'trust': 1, 'inspired': 1, 'amazed': 2, 'confused': 1, 'happy': 1, 'better': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary of all emotions that are in the df but that are NOT valid emotions (of the 28)\n",
    "random_emotions = []\n",
    "for emotion_list in df['emotion_label']:\n",
    "    for emotion in emotion_list:\n",
    "        if emotion not in emotion_labels_map_to_index:\n",
    "            random_emotions.append(emotion)\n",
    "random_emotion_dict = {}\n",
    "for emotion in random_emotions:\n",
    "    if emotion in random_emotion_dict:\n",
    "        random_emotion_dict[emotion] += 1\n",
    "    else:\n",
    "        random_emotion_dict[emotion] = 1\n",
    "print(random_emotion_dict)\n",
    "    \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Create a mapping: invalid word -> close match from go_emotions dataset\n",
    "incorrect_to_correct = {\n",
    "    \"horrible\": [\"disgust\", \"sadness\"],\n",
    "    \"love\": [\"admiration\", \"joy\"],\n",
    "    \"neutral\": [\"neutral\"],\n",
    "    \"bad\": [\"annoyance\", \"disapproval\"],\n",
    "    \"hate\": [\"anger\", \"disgust\"],\n",
    "    \"excited\": [\"excitement\"],\n",
    "    \"worse\": [\"disappointment\"],\n",
    "    \"disappointed\": [\"disappointment\"],\n",
    "    \"great\": [\"joy\", \"admiration\"],\n",
    "    \"amazing\": [\"joy\", \"admiration\"],\n",
    "    \"impressed\": [\"admiration\"],\n",
    "    \"thrilled\": [\"joy\", \"excitement\"],\n",
    "    \"terrible\": [\"disgust\", \"sadness\"],\n",
    "    \"amused\": [\"amusement\"],\n",
    "    \"curious\": [\"curiosity\"],\n",
    "    \"worst\": [\"disgust\", \"sadness\"],\n",
    "    \"good\": [\"approval\", \"joy\"],\n",
    "    \"regret\": [\"remorse\"],\n",
    "    \"need\": [\"desire\"],\n",
    "    \"trust\": [\"admiration\"],\n",
    "    \"inspired\": [\"admiration\", \"joy\"],\n",
    "    \"amazed\": [\"surprise\", \"admiration\"],\n",
    "    \"confused\": [\"confusion\"],\n",
    "    \"happy\": [\"joy\"],\n",
    "    \"better\": [\"approval\", \"optimism\"]\n",
    "}\n",
    "\n",
    "# Step 2: Write a function to process the column\n",
    "def map_emotions(emotion_labels):\n",
    "    return [synonym for emotion in emotion_labels for synonym in incorrect_to_correct.get(emotion, [emotion])]\n",
    "\n",
    "# Step 3: Apply the function to the DataFrame\n",
    "df['emotion_label'] = df['emotion_label'].apply(map_emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of hot encoded values for emotions (1: emotion found in text, else 0)\n",
    "def hot_encode_emotions(row):\n",
    "    result = np.zeros(28)\n",
    "    for label in row['emotion_label']:  # iterate through the list of labels in each row\n",
    "        if label in emotion_labels_map_to_index:\n",
    "            result[emotion_labels_map_to_index[label]] = 1\n",
    "    return result\n",
    "\n",
    "# Apply the function to each row\n",
    "emotion_labels = df.apply(hot_encode_emotions, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Examine a random entry in emotion_label column\n",
    "print(df['emotion_label'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: check if there are any invalid emotions in df... dictionary should be empty \n",
    "random_emotions = []\n",
    "for emotion_list in df['emotion_label']:\n",
    "    for emotion in emotion_list:\n",
    "        if emotion not in emotion_labels_map_to_index:\n",
    "            random_emotions.append(emotion)\n",
    "random_emotion_dict = {}\n",
    "for emotion in random_emotions:\n",
    "    if emotion in random_emotion_dict:\n",
    "        random_emotion_dict[emotion] += 1\n",
    "    else:\n",
    "        random_emotion_dict[emotion] = 1\n",
    "print(random_emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into validation, test, and train splits\n",
    "\n",
    "# Step 1: Split into train and temp (either test or validation)\n",
    "texts_train, texts_temp, emotions_train, emotions_temp, brands_train, brands_temp = train_test_split(\n",
    "    texts, emotion_labels, brand_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Then, split the temp data into validation and test sets\n",
    "texts_val, texts_test, emotions_val, emotions_test, brands_val, brands_test = train_test_split(\n",
    "    texts_temp, emotions_temp, brands_temp, test_size=0.5, random_state=42)  # This splits the remaining 20% into two 10% segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "The following code was originally used to create the Datasets. It was ran once and the results have been stored in the datasetss folder. I'm just leaving it here for context.\n",
    "\n",
    "```python\n",
    "from datasetss.brand_perception_dataset import BrandPerceptionDataset\n",
    "\n",
    "train_dataset = BrandPerceptionDataset(texts_train, emotions_train, brands_train)\n",
    "val_dataset = BrandPerceptionDataset(texts_val, emotions_val, brands_val)\n",
    "test_dataset = BrandPerceptionDataset(texts_test, emotions_test, brands_test)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryonnarice/488FinalProject/final_proj_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Loading datasets \n",
    "import pickle\n",
    "with open('datasetss/train_dataset.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open('datasetss/val_dataset.pkl', 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "\n",
    "with open('datasetss/test_dataset.pkl', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating dataloaders\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Initializing the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'model_name': 'SamLowe/roberta-base-go_emotions', 'n_labels_bp': 6, 'batch_size': 16, 'lr': 1.5e-05, 'warmup': 0.2, 'train_size': 25, 'weight_decay': 0.001, 'n_epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "from modules.BrandPerceptionModel import BrandPerceptionModel\n",
    "config = {\n",
    "    'model_name': 'SamLowe/roberta-base-go_emotions',\n",
    "    'n_labels_bp': 6,\n",
    "    'batch_size': 16,\n",
    "    'lr': 1.5e-5,\n",
    "    'warmup': 0.2, \n",
    "    'train_size': len(train_loader),\n",
    "    'weight_decay': 0.001,\n",
    "    'n_epochs': 10\n",
    "}\n",
    "print(\"Config:\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "This is how the model was originally trained. The trained model has been saved so that this doesn't need to be ran again.\n",
    "\n",
    "```python\n",
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(max_epochs=config['n_epochs'], num_sanity_val_steps=5, accelerator='gpu')\n",
    "#VALIDATION TOOK PLACE HERE:\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.save_checkpoint(\"models/brand_perception_model_checkpoint.ckpt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryonnarice/488FinalProject/final_proj_env/lib/python3.11/site-packages/pytorch_lightning/utilities/migration/utils.py:55: The loaded checkpoint was produced with Lightning v2.2.3, which is newer than your current Lightning version: v2.1.1\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = BrandPerceptionModel.load_from_checkpoint(\"models/brand_perception_model_checkpoint.ckpt\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/aryonnarice/488FinalProject/final_proj_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Missing logger folder: /Users/aryonnarice/488FinalProject/lightning_logs\n",
      "/Users/aryonnarice/488FinalProject/final_proj_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Emotion Logits Size: torch.Size([16, 28])\n",
      "Brand Logits Size: torch.Size([16, 6])\n",
      "Labels Emotion Size: torch.Size([16, 28])\n",
      "Labels Brand Size: torch.Size([16, 6])\n",
      "Testing DataLoader 0:  25%|██▌       | 1/4 [00:20<01:00,  0.05it/s]Emotion Logits Size: torch.Size([16, 28])\n",
      "Brand Logits Size: torch.Size([16, 6])\n",
      "Labels Emotion Size: torch.Size([16, 28])\n",
      "Labels Brand Size: torch.Size([16, 6])\n",
      "Testing DataLoader 0:  50%|█████     | 2/4 [00:49<00:49,  0.04it/s]Emotion Logits Size: torch.Size([16, 28])\n",
      "Brand Logits Size: torch.Size([16, 6])\n",
      "Labels Emotion Size: torch.Size([16, 28])\n",
      "Labels Brand Size: torch.Size([16, 6])\n",
      "Testing DataLoader 0:  75%|███████▌  | 3/4 [01:16<00:25,  0.04it/s]Emotion Logits Size: torch.Size([2, 28])\n",
      "Brand Logits Size: torch.Size([2, 6])\n",
      "Labels Emotion Size: torch.Size([2, 28])\n",
      "Labels Brand Size: torch.Size([2, 6])\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [01:19<00:00,  0.05it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_accuracy_brand      0.7866666913032532\n",
      "  test_accuracy_emotion     0.9421428442001343\n",
      "   test_f1_score_brand      0.31708115339279175\n",
      "  test_f1_score_emotion     0.04906122386455536\n",
      "     test_loss_epoch        0.8029792308807373\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.8029792308807373,\n",
       "  'test_accuracy_emotion': 0.9421428442001343,\n",
       "  'test_f1_score_emotion': 0.04906122386455536,\n",
       "  'test_accuracy_brand': 0.7866666913032532,\n",
       "  'test_f1_score_brand': 0.31708115339279175}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(max_epochs=config['n_epochs'], accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainer.test(model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predictions.\n",
    "\n",
    "Now let's use some data pertaining to only one luxury fashion brand, Amiri, to see how the model would behave in a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data (data for one specific brand: Amiri)\n",
    "amiri_df = pd.read_csv('data/filtered_amiri_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct data set and loader\n",
    "from datasets.brand_perception_dataset import BrandPerceptionDataset\n",
    "amiri_texts = [item for item in amiri_df['text'] if isinstance(item, str) and item.strip() != '']\n",
    "amiri_dataset = BrandPerceptionDataset(amiri_texts)\n",
    "amiri_loader = DataLoader(amiri_dataset, batch_size=4, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### This was the code used to predict the brand perception of Amiri. Results have been saved so code doesn't need to be ran again.\n",
    "\n",
    "``` python\n",
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "# Determine device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = GradScaler()\n",
    "\n",
    "all_emotion_probs = []\n",
    "all_brand_probs = []\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)\n",
    "\n",
    "def checkpointed_predict_step(batch):\n",
    "    def forward_func(input_ids, attention_mask):\n",
    "        return model(input_ids, attention_mask)\n",
    "    return checkpoint.checkpoint(forward_func, batch['input_ids'], batch['attention_mask'])\n",
    "\n",
    "for batch_idx, batch in enumerate(amiri_loader):\n",
    "    batch = {\n",
    "        \"input_ids\": batch['input_ids'].to(device),\n",
    "        \"attention_mask\": batch['attention_mask'].to(device),\n",
    "        \"labels_emotion\": batch['labels_emotion'].to(device),\n",
    "        \"labels_brand\": batch['labels_brand'].to(device),\n",
    "    }\n",
    "\n",
    "    with autocast():\n",
    "        # Use checkpointing to manage memory\n",
    "        loss, emotion_probs, brand_probs = checkpointed_predict_step(batch)\n",
    "\n",
    "    emotion_probs = emotion_probs.cpu()\n",
    "    brand_probs = brand_probs.cpu()\n",
    "\n",
    "    all_emotion_probs.append(emotion_probs)\n",
    "    all_brand_probs.append(brand_probs)\n",
    "\n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Clear variables\n",
    "    del batch, loss, emotion_probs, brand_probs\n",
    "\n",
    "# Concatenate all probabilities for final results\n",
    "all_emotion_probs = torch.cat(all_emotion_probs, dim=0)\n",
    "all_brand_probs = torch.cat(all_brand_probs, dim=0)\n",
    "\n",
    "# Display final results\n",
    "print(f\"Emotion probabilities shape: {all_emotion_probs.shape}\")\n",
    "print(f\"Brand probabilities shape: {all_brand_probs.shape}\")\n",
    "\n",
    "# Print memory summary\n",
    "print(torch.cuda.memory_summary(device=device, abbreviated=True))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the results for Amiri\n",
    "with open(\"results/probs.pkl\", \"rb\") as f:\n",
    "    all_emotion_probs, all_brand_probs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Emotion Probabilities: tensor([0.2791, 0.0393, 0.0728, 0.0716, 0.0461, 0.0299, 0.0347, 0.0328, 0.0343,\n",
      "        0.2739, 0.0605, 0.0908, 0.0317, 0.1637, 0.0311, 0.0374, 0.0274, 0.2805,\n",
      "        0.0296, 0.0292, 0.0341, 0.0285, 0.0305, 0.0338, 0.0311, 0.0809, 0.0334,\n",
      "        0.2271], dtype=torch.float16)\n",
      "Average Brand Perception Probabilities: tensor([0.4209, 0.4966, 0.1868, 0.0593, 0.0525, 0.0461], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Convert logits to probabilities and aggregate them to create a summary of the brand's perception\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Apply sigmoid to convert logits to probabilities\n",
    "all_emotion_probs = F.sigmoid(all_emotion_probs)\n",
    "all_brand_perception_probs = F.sigmoid(all_brand_probs)\n",
    "\n",
    "# Calculate the average probabilities for each emotion and brand aspect\n",
    "avg_emotion_probs = all_emotion_probs.mean(dim=0)\n",
    "avg_brand_perception_probs = all_brand_perception_probs.mean(dim=0)\n",
    "\n",
    "print(f\"Average Emotion Probabilities: {avg_emotion_probs}\")\n",
    "print(f\"Average Brand Perception Probabilities: {avg_brand_perception_probs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to map dimensions of tensor to labels (index i of a tensor represents a certain emotion or brand aspect)\n",
    "def map_to_labels(tensor, labels_map):\n",
    "    labels = []\n",
    "    for i, value in enumerate(tensor):\n",
    "        label = labels_map.get(i, \"Unknown\")\n",
    "        labels.append((label, value.item()))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand Perception:\n",
      "product quality: 0.4208984375\n",
      "reputation & heritage: 0.49658203125\n",
      "customer service: 0.186767578125\n",
      "social impact: 0.059295654296875\n",
      "ethical practices: 0.052459716796875\n",
      "sustainability: 0.046112060546875\n",
      "\n",
      "Emotion:\n",
      "admiration: 0.279052734375\n",
      "amusement: 0.039337158203125\n",
      "anger: 0.07275390625\n",
      "annoyance: 0.07159423828125\n",
      "approval: 0.04608154296875\n",
      "caring: 0.0299224853515625\n",
      "confusion: 0.03466796875\n",
      "curiosity: 0.032806396484375\n",
      "desire: 0.0343017578125\n",
      "disappointment: 0.27392578125\n",
      "disapproval: 0.060516357421875\n",
      "disgust: 0.09075927734375\n",
      "embarrassment: 0.03173828125\n",
      "excitement: 0.1636962890625\n",
      "fear: 0.031097412109375\n",
      "gratitude: 0.037384033203125\n",
      "grief: 0.027374267578125\n",
      "joy: 0.280517578125\n",
      "love: 0.0295562744140625\n",
      "nervousness: 0.02923583984375\n",
      "optimism: 0.034088134765625\n",
      "pride: 0.0284881591796875\n",
      "realization: 0.030487060546875\n",
      "relief: 0.033843994140625\n",
      "remorse: 0.0311279296875\n",
      "sadness: 0.0809326171875\n",
      "surprise: 0.033355712890625\n",
      "neutral: 0.22705078125\n"
     ]
    }
   ],
   "source": [
    "# Map indices to labels for brand perception tensor\n",
    "amiri_brand_perception_labels = map_to_labels(avg_brand_perception_probs, brand_perception_labels_map_to_label)\n",
    "print(\"Brand Perception:\")\n",
    "for label, value in amiri_brand_perception_labels:\n",
    "    print(f\"{label}: {value}\")\n",
    "\n",
    "# Map indices to labels for emotion tensor\n",
    "amiri_emotion_labels = map_to_labels(avg_emotion_probs, emotion_labels_map_to_emotion)\n",
    "print(\"\\nEmotion:\")\n",
    "for label, value in amiri_emotion_labels:\n",
    "    print(f\"{label}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Results and Conclusion.\n",
    "\n",
    "- **Product Quality (0.421):** Indicates a moderately positive perception of the brand's product quality.\n",
    "- **Reputation & Heritage (0.497):** This is the highest score, suggesting a strong association of the brand with a reputable heritage.\n",
    "- **Customer Service (0.187):** Shows that there is less conversation or possibly less favorable perception concerning their customer service.\n",
    "- **Social Impact (0.059):** Very low, indicating that the brand is rarely discussed in the context of social impact.\n",
    "- **Ethical Practices (0.052):** Similar to social impact, this low score suggests minimal association with ethical practices in public perception.\n",
    "- **Sustainability (0.046):** The lowest score, indicating minimal recognition of sustainability efforts associated with the brand.\n",
    "\n",
    "\n",
    "The analysis of TikTok data pertaining to the luxury fashion brand Amiri reveals insightful aspects of public perception and emotional responses. The model's predictions on the dataset provide a nuanced understanding of how the brand is viewed across various dimensions and emotions.\n",
    "\n",
    "\n",
    "These insights can guide brand strategies, marketing campaigns, and customer engagement initiatives to enhance brand perception and address areas of concern. Emphasizing strengths like product quality and reputation while addressing areas like customer service and ethical practices could be beneficial for Amiri."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_proj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
