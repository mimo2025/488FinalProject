{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#**BUSI/COMP488-001 Data Science in the Business World.**\n",
    "###**Multi-Label Classification of Luxury Brand Perceptions on TikTok.**\n",
    "###**Team Name:** Team D.\n",
    "###**Team Members:** Carley Wiley, Eldar Utiushev, Bek Tukhtasinov, Mira Mohan, Aryonna Rice, and Tammy Duong.\n",
    "\n",
    "This notebook explores a multi-label classification problem for luxury fashion brands based on TikTok comments and captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install datasets transformers pandas matplotlib tqdm --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Automatically loads changes in other files in this project\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Necessary Libraries.\n",
    "\n",
    "First, we need to import various Python libraries that will help us manipulate data, perform computations, and model our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aryonnarice/488FinalProject\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryonnarice/488FinalProject/final_proj_env/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/aryonnarice/488FinalProject'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change to project root\n",
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Loading and Exploration.\n",
    "\n",
    "Next, we will load the dataset containing TikTok comments and captions. This data will be used to train our model to classify brand perceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/validated_labeled_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>brand_label</th>\n",
       "      <th>emotion_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opium founding father,</td>\n",
       "      <td>['reputation &amp; heritage']</td>\n",
       "      <td>['horrible']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yall trippin fit clean,</td>\n",
       "      <td>['product quality']</td>\n",
       "      <td>['love']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>might destroy lonely,</td>\n",
       "      <td>['reputation &amp; heritage']</td>\n",
       "      <td>['horrible']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alr show us women,</td>\n",
       "      <td>['reputation &amp; heritage']</td>\n",
       "      <td>['neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad think jeans ripped pull bad,</td>\n",
       "      <td>['product quality']</td>\n",
       "      <td>['bad']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Text                brand_label emotion_label\n",
       "0            opium founding father,  ['reputation & heritage']  ['horrible']\n",
       "1           yall trippin fit clean,        ['product quality']      ['love']\n",
       "2             might destroy lonely,  ['reputation & heritage']  ['horrible']\n",
       "3                alr show us women,  ['reputation & heritage']   ['neutral']\n",
       "4  bad think jeans ripped pull bad,        ['product quality']       ['bad']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Fixing Data Format.\n",
    "\n",
    "We saw that the items in df are not list of strings. They need to be so we must fix the formatting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Text           500 non-null    object\n",
      " 1   brand_label    500 non-null    object\n",
      " 2   emotion_label  500 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 11.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with any NaN values\n",
    "df = df.dropna(subset=['brand_label', 'Text', 'emotion_label'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text             object\n",
      "brand_label      object\n",
      "emotion_label    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function that converts the values in the brand_label and emotion_label columns to lists of strings\n",
    "def convert_to_list_of_strings(value):\n",
    "    # Ensure that the input is actually a string\n",
    "    if isinstance(value, str):\n",
    "        # Remove unwanted characters and split\n",
    "        value = value.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
    "    return value\n",
    "\n",
    "# Convert Text to str type\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "df['Text'] = df['Text'].str.rstrip(\",\")\n",
    "df.rename(columns={'Text': 'text'}, inplace=True)\n",
    "\n",
    "# Convert brand_label and emotion_label to list of strings\n",
    "df['brand_label'] = df['brand_label'].apply(convert_to_list_of_strings)\n",
    "df['emotion_label'] = df['emotion_label'].apply(convert_to_list_of_strings)\n",
    "\n",
    "# Check the types to verify\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Summary of the Data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic exploration\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing. \n",
    "\n",
    "The data cleaning and preprocessing step is essential for ensuring the quality and consistency of our analysis. We handle missing values, outliers, and ensure that the data types are correct for each column. This step sets the stage for accurate and reliable insights. We'll remove URLs, special characters, convert text to lowercase, and remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a mapping for the brand perception labels and emotion labels\n",
    "brand_perception_labels_map_to_label = {\n",
    "        0: 'product quality',\n",
    "        1: 'reputation & heritage',\n",
    "        2: 'customer service',\n",
    "        3: 'social impact',\n",
    "        4: 'ethical practices',\n",
    "        5: 'sustainability'\n",
    "    }\n",
    "\n",
    "emotion_labels_map_to_emotion = {0: \"admiration\",\n",
    "    1: \"amusement\",\n",
    "    2: \"anger\",\n",
    "    3: \"annoyance\",\n",
    "    4: \"approval\",\n",
    "    5: \"caring\",\n",
    "    6: \"confusion\",\n",
    "    7: \"curiosity\",\n",
    "    8: \"desire\",\n",
    "    9: \"disappointment\",\n",
    "    10: \"disapproval\",\n",
    "    11: \"disgust\",\n",
    "    12: \"embarrassment\",\n",
    "    13: \"excitement\",\n",
    "    14: \"fear\",\n",
    "    15: \"gratitude\",\n",
    "    16: \"grief\",\n",
    "    17: \"joy\",\n",
    "    18: \"love\",\n",
    "    19: \"nervousness\",\n",
    "    20: \"optimism\",\n",
    "    21: \"pride\",\n",
    "    22: \"realization\",\n",
    "    23: \"relief\",\n",
    "    24: \"remorse\",\n",
    "    25: \"sadness\",\n",
    "    26: \"surprise\",\n",
    "    27: \"neutral\"}\n",
    "\n",
    "brand_perception_labels_map_to_index = {\n",
    "        'product quality': 0,\n",
    "        'reputation & heritage': 1,\n",
    "        'customer service': 2,\n",
    "        'social impact': 3,\n",
    "        'ethical practices': 4,\n",
    "        'sustainability': 5\n",
    "    }\n",
    "\n",
    "emotion_labels_map_to_index = {\n",
    "    \"admiration\": 0,\n",
    "    \"amusement\": 1,\n",
    "    \"anger\": 2,\n",
    "    \"annoyance\": 3,\n",
    "    \"approval\": 4,\n",
    "    \"caring\": 5,\n",
    "    \"confusion\": 6,\n",
    "    \"curiosity\": 7,\n",
    "    \"desire\": 8,\n",
    "    \"disappointment\": 9,\n",
    "    \"disapproval\": 10,\n",
    "    \"disgust\": 11,\n",
    "    \"embarrassment\": 12,\n",
    "    \"excitement\": 13,\n",
    "    \"fear\": 14,\n",
    "    \"gratitude\": 15,\n",
    "    \"grief\": 16,\n",
    "    \"joy\": 17,\n",
    "    \"love\": 18,\n",
    "    \"nervousness\": 19,\n",
    "    \"optimism\": 20,\n",
    "    \"pride\": 21,\n",
    "    \"realization\": 22,\n",
    "    \"relief\": 23,\n",
    "    \"remorse\": 24,\n",
    "    \"sadness\": 25,\n",
    "    \"surprise\": 26,\n",
    "    \"neutral\": 27\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Create Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turn the text column of df to a list of strings to be inserted into the model\n",
    "texts = [item for item in df['text'] if isinstance(item, str) and item.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of hot encoded values for brand aspects (1: aspect found in text, else 0)\n",
    "def hot_encode_brand_perception(row):\n",
    "    result = np.zeros(6)\n",
    "    for label in row['brand_label']:  # iterate through the list of labels in each row\n",
    "        if label in brand_perception_labels_map_to_index:\n",
    "            result[brand_perception_labels_map_to_index[label]] = 1\n",
    "    return result\n",
    "\n",
    "# Apply the function to each row\n",
    "brand_labels = df.apply(hot_encode_brand_perception, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Fixing Labeled Data.\n",
    "\n",
    "Some of the labeled data used emotions that were not of the 28 the pretrained model was trained to identify. Hence, these values need to be changed to words that are included in the go_emotions dataset but that also closely match the definition of the original word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'horrible': 30, 'bad': 29, 'hate': 36, 'excited': 75, 'worse': 18, 'disappointed': 98, 'great': 21, 'amazing': 19, 'impressed': 16, 'thrilled': 16, 'terrible': 16, 'amused': 3, 'curious': 1, 'worst': 1, 'good': 5, 'regret': 1, 'need': 1, 'trust': 1, 'inspired': 1, 'amazed': 2, 'confused': 1, 'happy': 1, 'better': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary off all emotions that are in the df but that are NOT valid emotions (of the 28)\n",
    "random_emotions = []\n",
    "for emotion_list in df['emotion_label']:\n",
    "    for emotion in emotion_list:\n",
    "        if emotion not in emotion_labels_map_to_index:\n",
    "            random_emotions.append(emotion)\n",
    "random_emotion_dict = {}\n",
    "for emotion in random_emotions:\n",
    "    if emotion in random_emotion_dict:\n",
    "        random_emotion_dict[emotion] += 1\n",
    "    else:\n",
    "        random_emotion_dict[emotion] = 1\n",
    "print(random_emotion_dict)\n",
    "    \n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Create a mapping: invalid word -> close match from go_emotions dataset\n",
    "incorrect_to_correct = {\n",
    "    \"horrible\": [\"disgust\", \"sadness\"],\n",
    "    \"love\": [\"admiration\", \"joy\"],\n",
    "    \"neutral\": [\"neutral\"],\n",
    "    \"bad\": [\"annoyance\", \"disapproval\"],\n",
    "    \"hate\": [\"anger\", \"disgust\"],\n",
    "    \"excited\": [\"excitement\"],\n",
    "    \"worse\": [\"disappointment\"],\n",
    "    \"disappointed\": [\"disappointment\"],\n",
    "    \"great\": [\"joy\", \"admiration\"],\n",
    "    \"amazing\": [\"joy\", \"admiration\"],\n",
    "    \"impressed\": [\"admiration\"],\n",
    "    \"thrilled\": [\"joy\", \"excitement\"],\n",
    "    \"terrible\": [\"disgust\", \"sadness\"],\n",
    "    \"amused\": [\"amusement\"],\n",
    "    \"curious\": [\"curiosity\"],\n",
    "    \"worst\": [\"disgust\", \"sadness\"],\n",
    "    \"good\": [\"approval\", \"joy\"],\n",
    "    \"regret\": [\"remorse\"],\n",
    "    \"need\": [\"desire\"],\n",
    "    \"trust\": [\"admiration\"],\n",
    "    \"inspired\": [\"admiration\", \"joy\"],\n",
    "    \"amazed\": [\"surprise\", \"admiration\"],\n",
    "    \"confused\": [\"confusion\"],\n",
    "    \"happy\": [\"joy\"],\n",
    "    \"better\": [\"approval\", \"optimism\"]\n",
    "}\n",
    "\n",
    "# Step 2: Write a function to process the column\n",
    "def map_emotions(emotion_labels):\n",
    "    return [synonym for emotion in emotion_labels for synonym in incorrect_to_correct.get(emotion, [emotion])]\n",
    "\n",
    "# Step 3: Apply the function to the DataFrame\n",
    "df['emotion_label'] = df['emotion_label'].apply(map_emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a list of hot encoded values for emotions (1: emotion found in text, else 0)\n",
    "def hot_encode_emotions(row):\n",
    "    result = np.zeros(28)\n",
    "    for label in row['emotion_label']:  # iterate through the list of labels in each row\n",
    "        if label in emotion_labels_map_to_index:\n",
    "            result[emotion_labels_map_to_index[label]] = 1\n",
    "    return result\n",
    "\n",
    "# Apply the function to each row\n",
    "emotion_labels = df.apply(hot_encode_emotions, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Examine a random entry in emotion_label column\n",
    "print(df['emotion_label'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: check if there are any invalid emotions in df... dictionary should be empty \n",
    "random_emotions = []\n",
    "for emotion_list in df['emotion_label']:\n",
    "    for emotion in emotion_list:\n",
    "        if emotion not in emotion_labels_map_to_index:\n",
    "            random_emotions.append(emotion)\n",
    "random_emotion_dict = {}\n",
    "for emotion in random_emotions:\n",
    "    if emotion in random_emotion_dict:\n",
    "        random_emotion_dict[emotion] += 1\n",
    "    else:\n",
    "        random_emotion_dict[emotion] = 1\n",
    "print(random_emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into validation, test, and train splits\n",
    "\n",
    "# Step 1: Split into train and temp (either test or validation)\n",
    "texts_train, texts_temp, emotions_train, emotions_temp, brands_train, brands_temp = train_test_split(\n",
    "    texts, emotion_labels, brand_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Then, split the temp data into validation and test sets\n",
    "texts_val, texts_test, emotions_val, emotions_test, brands_val, brands_test = train_test_split(\n",
    "    texts_temp, emotions_temp, brands_temp, test_size=0.5, random_state=42)  # This splits the remaining 20% into two 10% segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "The following code was originally used to create the Datasets. It was ran once and the results have been stored in the datasetss folder. I'm just leaving it here for context.\n",
    "\n",
    "```python\n",
    "from datasetss.brand_perception_dataset import BrandPerceptionDataset\n",
    "\n",
    "train_dataset = BrandPerceptionDataset(texts_train, emotions_train, brands_train)\n",
    "val_dataset = BrandPerceptionDataset(texts_val, emotions_val, brands_val)\n",
    "test_dataset = BrandPerceptionDataset(texts_test, emotions_test, brands_test)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryonnarice/488FinalProject/final_proj_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Loading datasets \n",
    "import pickle\n",
    "with open('datasetss/train_dataset.pkl', 'rb') as f:\n",
    "    train_dataset = pickle.load(f)\n",
    "\n",
    "with open('datasetss/val_dataset.pkl', 'rb') as f:\n",
    "    val_dataset = pickle.load(f)\n",
    "\n",
    "with open('datasetss/test_dataset.pkl', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating dataloaders\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Initializing the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: {'model_name': 'SamLowe/roberta-base-go_emotions', 'n_labels_bp': 6, 'batch_size': 16, 'lr': 1.5e-05, 'warmup': 0.2, 'train_size': 25, 'weight_decay': 0.001, 'n_epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "from modules.BrandPerceptionModel import BrandPerceptionModel\n",
    "config = {\n",
    "    'model_name': 'SamLowe/roberta-base-go_emotions',\n",
    "    'n_labels_bp': 6,\n",
    "    'batch_size': 16,\n",
    "    'lr': 1.5e-5,\n",
    "    'warmup': 0.2, \n",
    "    'train_size': len(train_loader),\n",
    "    'weight_decay': 0.001,\n",
    "    'n_epochs': 10\n",
    "}\n",
    "print(\"Config:\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "This is how the model was originally trained. The trained model has been saved so that this doesn't need to be ran again.\n",
    "\n",
    "```python\n",
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(max_epochs=config['n_epochs'], num_sanity_val_steps=5, accelerator='gpu')\n",
    "#VALIDATION TOOK PLACE HERE:\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "trainer.save_checkpoint(\"models/brand_perception_model_checkpoint.ckpt\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aryonnarice/488FinalProject/final_proj_env/lib/python3.11/site-packages/pytorch_lightning/utilities/migration/utils.py:55: The loaded checkpoint was produced with Lightning v2.2.3, which is newer than your current Lightning version: v2.1.1\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at SamLowe/roberta-base-go_emotions and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = BrandPerceptionModel.load_from_checkpoint(\"models/brand_perception_model_checkpoint.ckpt\", config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/aryonnarice/488FinalProject/final_proj_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "Missing logger folder: /Users/aryonnarice/488FinalProject/lightning_logs\n",
      "/Users/aryonnarice/488FinalProject/final_proj_env/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   0%|          | 0/4 [00:00<?, ?it/s]Emotion Logits Size: torch.Size([16, 28])\n",
      "Brand Logits Size: torch.Size([16, 6])\n",
      "Labels Emotion Size: torch.Size([16, 28])\n",
      "Labels Brand Size: torch.Size([16, 6])\n",
      "Testing DataLoader 0:  25%|██▌       | 1/4 [00:20<01:00,  0.05it/s]Emotion Logits Size: torch.Size([16, 28])\n",
      "Brand Logits Size: torch.Size([16, 6])\n",
      "Labels Emotion Size: torch.Size([16, 28])\n",
      "Labels Brand Size: torch.Size([16, 6])\n",
      "Testing DataLoader 0:  50%|█████     | 2/4 [00:49<00:49,  0.04it/s]Emotion Logits Size: torch.Size([16, 28])\n",
      "Brand Logits Size: torch.Size([16, 6])\n",
      "Labels Emotion Size: torch.Size([16, 28])\n",
      "Labels Brand Size: torch.Size([16, 6])\n",
      "Testing DataLoader 0:  75%|███████▌  | 3/4 [01:16<00:25,  0.04it/s]Emotion Logits Size: torch.Size([2, 28])\n",
      "Brand Logits Size: torch.Size([2, 6])\n",
      "Labels Emotion Size: torch.Size([2, 28])\n",
      "Labels Brand Size: torch.Size([2, 6])\n",
      "Testing DataLoader 0: 100%|██████████| 4/4 [01:19<00:00,  0.05it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "   test_accuracy_brand      0.7866666913032532\n",
      "  test_accuracy_emotion     0.9421428442001343\n",
      "   test_f1_score_brand      0.31708115339279175\n",
      "  test_f1_score_emotion     0.04906122386455536\n",
      "     test_loss_epoch        0.8029792308807373\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 0.8029792308807373,\n",
       "  'test_accuracy_emotion': 0.9421428442001343,\n",
       "  'test_f1_score_emotion': 0.04906122386455536,\n",
       "  'test_accuracy_brand': 0.7866666913032532,\n",
       "  'test_f1_score_brand': 0.31708115339279175}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test model\n",
    "import pytorch_lightning as pl\n",
    "trainer = pl.Trainer(max_epochs=config['n_epochs'], accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainer.test(model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predictions.\n",
    "\n",
    "Now let's use the some data pertaining to only one luxary fashion brand, Amiri, to see how the model would behave in a real world sceanrio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data (data for one specifc brand: Amiri)\n",
    "amiri_df = pd.read_csv('data/filtered_amiri_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct data set and loader\n",
    "from datasetss.brand_perception_dataset import BrandPerceptionDataset\n",
    "amiri_texts = [item for item in amiri_df['text'] if isinstance(item, str) and item.strip() != '']\n",
    "amiri_dataset = BrandPerceptionDataset(amiri_texts)\n",
    "amiri_loader = DataLoader(amiri_dataset, batch_size=4, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### This was the code used to predict the brand perception of Amiri. Results have been saved so code doesn't need to be ran again.\n",
    "\n",
    "``` python\n",
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "# Determine device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "scaler = GradScaler()\n",
    "\n",
    "all_emotion_probs = []\n",
    "all_brand_probs = []\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)\n",
    "\n",
    "def checkpointed_predict_step(batch):\n",
    "    def forward_func(input_ids, attention_mask):\n",
    "        return model(input_ids, attention_mask)\n",
    "    return checkpoint.checkpoint(forward_func, batch['input_ids'], batch['attention_mask'])\n",
    "\n",
    "for batch_idx, batch in enumerate(amiri_loader):\n",
    "    batch = {\n",
    "        \"input_ids\": batch['input_ids'].to(device),\n",
    "        \"attention_mask\": batch['attention_mask'].to(device),\n",
    "        \"labels_emotion\": batch['labels_emotion'].to(device),\n",
    "        \"labels_brand\": batch['labels_brand'].to(device),\n",
    "    }\n",
    "\n",
    "    with autocast():\n",
    "        # Use checkpointing to manage memory\n",
    "        loss, emotion_probs, brand_probs = checkpointed_predict_step(batch)\n",
    "\n",
    "    emotion_probs = emotion_probs.cpu()\n",
    "    brand_probs = brand_probs.cpu()\n",
    "\n",
    "    all_emotion_probs.append(emotion_probs)\n",
    "    all_brand_probs.append(brand_probs)\n",
    "\n",
    "    # Clear GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Clear variables\n",
    "    del batch, loss, emotion_probs, brand_probs\n",
    "\n",
    "# Concatenate all probabilities for final results\n",
    "all_emotion_probs = torch.cat(all_emotion_probs, dim=0)\n",
    "all_brand_probs = torch.cat(all_brand_probs, dim=0)\n",
    "\n",
    "# Display final results\n",
    "print(f\"Emotion probabilities shape: {all_emotion_probs.shape}\")\n",
    "print(f\"Brand probabilities shape: {all_brand_probs.shape}\")\n",
    "\n",
    "# Print memory summary\n",
    "print(torch.cuda.memory_summary(device=device, abbreviated=True))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the results for Amiri\n",
    "with open(\"results/probs.pkl\", \"rb\") as f:\n",
    "    all_emotion_probs, all_brand_probs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Emotion Probabilities: tensor([0.2791, 0.0393, 0.0728, 0.0716, 0.0461, 0.0299, 0.0347, 0.0328, 0.0343,\n",
      "        0.2739, 0.0605, 0.0908, 0.0317, 0.1637, 0.0311, 0.0374, 0.0274, 0.2805,\n",
      "        0.0296, 0.0292, 0.0341, 0.0285, 0.0305, 0.0338, 0.0311, 0.0809, 0.0334,\n",
      "        0.2271], dtype=torch.float16)\n",
      "Average Brand Perception Probabilities: tensor([0.4209, 0.4966, 0.1868, 0.0593, 0.0525, 0.0461], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Convert logits to probabilities and aggregate them to create a summary of the brand's perception\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Apply sigmoid to convert logits to probabilities\n",
    "all_emotion_probs = F.sigmoid(all_emotion_probs)\n",
    "all_brand_perception_probs = F.sigmoid(all_brand_probs)\n",
    "\n",
    "# Calculate the average probabilities for each emotion and brand aspect\n",
    "avg_emotion_probs = all_emotion_probs.mean(dim=0)\n",
    "avg_brand_perception_probs = all_brand_perception_probs.mean(dim=0)\n",
    "\n",
    "print(f\"Average Emotion Probabilities: {avg_emotion_probs}\")\n",
    "print(f\"Average Brand Perception Probabilities: {avg_brand_perception_probs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to map dimensions of tensor to labels (index i of a tensor represents a certain emotion or brand aspect)\n",
    "def map_to_labels(tensor, labels_map):\n",
    "    labels = []\n",
    "    for i, value in enumerate(tensor):\n",
    "        label = labels_map.get(i, \"Unknown\")\n",
    "        labels.append((label, value.item()))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand Perception:\n",
      "product quality: 0.4208984375\n",
      "reputation & heritage: 0.49658203125\n",
      "customer service: 0.186767578125\n",
      "social impact: 0.059295654296875\n",
      "ethical practices: 0.052459716796875\n",
      "sustainability: 0.046112060546875\n",
      "\n",
      "Emotion:\n",
      "admiration: 0.279052734375\n",
      "amusement: 0.039337158203125\n",
      "anger: 0.07275390625\n",
      "annoyance: 0.07159423828125\n",
      "approval: 0.04608154296875\n",
      "caring: 0.0299224853515625\n",
      "confusion: 0.03466796875\n",
      "curiosity: 0.032806396484375\n",
      "desire: 0.0343017578125\n",
      "disappointment: 0.27392578125\n",
      "disapproval: 0.060516357421875\n",
      "disgust: 0.09075927734375\n",
      "embarrassment: 0.03173828125\n",
      "excitement: 0.1636962890625\n",
      "fear: 0.031097412109375\n",
      "gratitude: 0.037384033203125\n",
      "grief: 0.027374267578125\n",
      "joy: 0.280517578125\n",
      "love: 0.0295562744140625\n",
      "nervousness: 0.02923583984375\n",
      "optimism: 0.034088134765625\n",
      "pride: 0.0284881591796875\n",
      "realization: 0.030487060546875\n",
      "relief: 0.033843994140625\n",
      "remorse: 0.0311279296875\n",
      "sadness: 0.0809326171875\n",
      "surprise: 0.033355712890625\n",
      "neutral: 0.22705078125\n"
     ]
    }
   ],
   "source": [
    "# Map indices to labels for brand perception tensor\n",
    "amiri_brand_perception_labels = map_to_labels(avg_brand_perception_probs, brand_perception_labels_map_to_label)\n",
    "print(\"Brand Perception:\")\n",
    "for label, value in amiri_brand_perception_labels:\n",
    "    print(f\"{label}: {value}\")\n",
    "\n",
    "# Map indices to labels for emotion tensor\n",
    "amiri_emotion_labels = map_to_labels(avg_emotion_probs, emotion_labels_map_to_emotion)\n",
    "print(\"\\nEmotion:\")\n",
    "for label, value in amiri_emotion_labels:\n",
    "    print(f\"{label}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_proj_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
